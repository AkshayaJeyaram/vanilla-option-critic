=== Logging started at Mon Jul 28 23:29:55 2025 ===
2025/07/28 11:29:55 PM > ep 1 done. total_steps=11 | reward=1.0 | episode_steps=11 | hours=0.000 | epsilon=1.000
  - Option 0: avg len = 2.00, count = 3
  - Option 1: avg len = 1.33, count = 3
2025/07/28 11:29:56 PM > ep 2 done. total_steps=1011 | reward=0.0 | episode_steps=1000 | hours=0.000 | epsilon=0.956
  - Option 0: avg len = 8.02, count = 103
  - Option 1: avg len = 1.47, count = 114
2025/07/28 11:29:56 PM > ep 3 done. total_steps=2011 | reward=0.0 | episode_steps=1000 | hours=0.001 | epsilon=0.914
  - Option 0: avg len = 4.51, count = 142
  - Option 1: avg len = 2.23, count = 160
2025/07/28 11:29:57 PM > ep 4 done. total_steps=2824 | reward=1.0 | episode_steps=813 | hours=0.001 | epsilon=0.882
  - Option 0: avg len = 4.78, count = 68
  - Option 1: avg len = 7.15, count = 68
2025/07/28 11:29:57 PM > ep 5 done. total_steps=2885 | reward=1.0 | episode_steps=61 | hours=0.001 | epsilon=0.879
  - Option 0: avg len = 5.20, count = 5
  - Option 1: avg len = 5.40, count = 5
2025/07/28 11:29:58 PM > ep 6 done. total_steps=3885 | reward=0.0 | episode_steps=1000 | hours=0.001 | epsilon=0.841
  - Option 0: avg len = 9.78, count = 60
  - Option 1: avg len = 5.97, count = 69
2025/07/28 11:29:58 PM > ep 7 done. total_steps=4464 | reward=1.0 | episode_steps=579 | hours=0.001 | epsilon=0.820
  - Option 0: avg len = 44.36, count = 11
  - Option 1: avg len = 7.33, count = 12
2025/07/28 11:29:59 PM > ep 8 done. total_steps=5414 | reward=1.0 | episode_steps=950 | hours=0.002 | epsilon=0.787
  - Option 0: avg len = 1.00, count = 2
  - Option 1: avg len = 57.43, count = 7
2025/07/28 11:29:59 PM > ep 9 done. total_steps=6068 | reward=1.0 | episode_steps=654 | hours=0.002 | epsilon=0.765
  - Option 0: avg len = 31.29, count = 14
  - Option 1: avg len = 22.40, count = 5
2025/07/28 11:30:00 PM > ep 10 done. total_steps=6577 | reward=1.0 | episode_steps=509 | hours=0.002 | epsilon=0.748
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:00 PM > ep 11 done. total_steps=7300 | reward=1.0 | episode_steps=723 | hours=0.002 | epsilon=0.725
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:00 PM > ep 12 done. total_steps=7325 | reward=1.0 | episode_steps=25 | hours=0.002 | epsilon=0.724
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:00 PM > ep 13 done. total_steps=7636 | reward=1.0 | episode_steps=311 | hours=0.002 | epsilon=0.714
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:01 PM > ep 14 done. total_steps=8065 | reward=1.0 | episode_steps=429 | hours=0.002 | epsilon=0.701
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:01 PM > ep 15 done. total_steps=8172 | reward=1.0 | episode_steps=107 | hours=0.002 | epsilon=0.698
  - Option 0: avg len = 16.50, count = 2
  - Option 1: avg len = 4.50, count = 2
2025/07/28 11:30:01 PM > ep 16 done. total_steps=8731 | reward=1.0 | episode_steps=559 | hours=0.002 | epsilon=0.682
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.00, count = 1
2025/07/28 11:30:01 PM > ep 17 done. total_steps=9091 | reward=1.0 | episode_steps=360 | hours=0.003 | epsilon=0.671
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 41.75, count = 4
2025/07/28 11:30:01 PM > ep 18 done. total_steps=9204 | reward=1.0 | episode_steps=113 | hours=0.003 | epsilon=0.668
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 67.00, count = 1
2025/07/28 11:30:02 PM > ep 19 done. total_steps=9468 | reward=1.0 | episode_steps=264 | hours=0.003 | epsilon=0.661
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 124.50, count = 2
2025/07/28 11:30:02 PM > ep 20 done. total_steps=9526 | reward=1.0 | episode_steps=58 | hours=0.003 | epsilon=0.659
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 23.00, count = 2
2025/07/28 11:30:02 PM > ep 21 done. total_steps=9553 | reward=1.0 | episode_steps=27 | hours=0.003 | epsilon=0.658
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 15.00, count = 1
2025/07/28 11:30:02 PM > ep 22 done. total_steps=9800 | reward=1.0 | episode_steps=247 | hours=0.003 | epsilon=0.651
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 17.00, count = 1
2025/07/28 11:30:02 PM > ep 23 done. total_steps=9837 | reward=1.0 | episode_steps=37 | hours=0.003 | epsilon=0.650
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 7.00, count = 1
2025/07/28 11:30:02 PM > ep 24 done. total_steps=10611 | reward=1.0 | episode_steps=774 | hours=0.003 | epsilon=0.629
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:03 PM > ep 25 done. total_steps=10930 | reward=1.0 | episode_steps=319 | hours=0.003 | epsilon=0.621
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:03 PM > ep 26 done. total_steps=11079 | reward=1.0 | episode_steps=149 | hours=0.003 | epsilon=0.617
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:03 PM > ep 27 done. total_steps=11221 | reward=1.0 | episode_steps=142 | hours=0.003 | epsilon=0.614
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 18.00, count = 1
2025/07/28 11:30:03 PM > ep 28 done. total_steps=11354 | reward=1.0 | episode_steps=133 | hours=0.003 | epsilon=0.610
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:03 PM > ep 29 done. total_steps=11549 | reward=1.0 | episode_steps=195 | hours=0.003 | epsilon=0.605
  - Option 0: avg len = 61.00, count = 2
2025/07/28 11:30:03 PM > ep 30 done. total_steps=11608 | reward=1.0 | episode_steps=59 | hours=0.003 | epsilon=0.604
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:03 PM > ep 31 done. total_steps=11702 | reward=1.0 | episode_steps=94 | hours=0.003 | epsilon=0.601
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:03 PM > ep 32 done. total_steps=11743 | reward=1.0 | episode_steps=41 | hours=0.003 | epsilon=0.600
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:03 PM > ep 33 done. total_steps=11998 | reward=1.0 | episode_steps=255 | hours=0.003 | epsilon=0.594
  - Option 0: avg len = 1.00, count = 2
  - Option 1: avg len = 124.00, count = 2
2025/07/28 11:30:03 PM > ep 34 done. total_steps=12019 | reward=1.0 | episode_steps=21 | hours=0.003 | epsilon=0.593
  - Option 0: avg len = 2.50, count = 2
2025/07/28 11:30:04 PM > ep 35 done. total_steps=12389 | reward=1.0 | episode_steps=370 | hours=0.003 | epsilon=0.584
  - Option 0: avg len = 35.50, count = 2
  - Option 1: avg len = 273.00, count = 1
2025/07/28 11:30:04 PM > ep 36 done. total_steps=12399 | reward=1.0 | episode_steps=10 | hours=0.003 | epsilon=0.584
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:04 PM > ep 37 done. total_steps=12640 | reward=1.0 | episode_steps=241 | hours=0.004 | epsilon=0.578
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 193.00, count = 1
2025/07/28 11:30:04 PM > ep 38 done. total_steps=12708 | reward=1.0 | episode_steps=68 | hours=0.004 | epsilon=0.577
  - Option 0: avg len = 22.00, count = 2
2025/07/28 11:30:04 PM > ep 39 done. total_steps=12889 | reward=1.0 | episode_steps=181 | hours=0.004 | epsilon=0.572
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 114.00, count = 1
2025/07/28 11:30:04 PM > ep 40 done. total_steps=12909 | reward=1.0 | episode_steps=20 | hours=0.004 | epsilon=0.572
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:04 PM > ep 41 done. total_steps=13146 | reward=1.0 | episode_steps=237 | hours=0.004 | epsilon=0.566
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:05 PM > ep 42 done. total_steps=14146 | reward=0.0 | episode_steps=1000 | hours=0.004 | epsilon=0.544
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 615.00, count = 1
2025/07/28 11:30:05 PM > ep 43 done. total_steps=14289 | reward=1.0 | episode_steps=143 | hours=0.004 | epsilon=0.541
  - Option 0: avg len = 1.50, count = 2
2025/07/28 11:30:05 PM > ep 44 done. total_steps=14645 | reward=1.0 | episode_steps=356 | hours=0.004 | epsilon=0.533
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 152.00, count = 1
2025/07/28 11:30:06 PM > ep 45 done. total_steps=15345 | reward=1.0 | episode_steps=700 | hours=0.004 | epsilon=0.518
  - Option 0: avg len = 7.30, count = 10
  - Option 1: avg len = 103.33, count = 6
2025/07/28 11:30:06 PM > ep 46 done. total_steps=16345 | reward=0.0 | episode_steps=1000 | hours=0.005 | epsilon=0.497
  - Option 0: avg len = 18.89, count = 19
  - Option 1: avg len = 125.20, count = 5
2025/07/28 11:30:07 PM > ep 47 done. total_steps=16584 | reward=1.0 | episode_steps=239 | hours=0.005 | epsilon=0.493
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:07 PM > ep 48 done. total_steps=16908 | reward=1.0 | episode_steps=324 | hours=0.005 | epsilon=0.486
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 46.00, count = 1
2025/07/28 11:30:07 PM > ep 49 done. total_steps=17005 | reward=1.0 | episode_steps=97 | hours=0.005 | epsilon=0.485
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:07 PM > ep 50 done. total_steps=17519 | reward=1.0 | episode_steps=514 | hours=0.005 | epsilon=0.475
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 111.00, count = 1
2025/07/28 11:30:07 PM > ep 51 done. total_steps=17659 | reward=1.0 | episode_steps=140 | hours=0.005 | epsilon=0.472
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:08 PM > ep 52 done. total_steps=17784 | reward=1.0 | episode_steps=125 | hours=0.005 | epsilon=0.470
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 19.50, count = 2
2025/07/28 11:30:08 PM > ep 53 done. total_steps=17806 | reward=1.0 | episode_steps=22 | hours=0.005 | epsilon=0.469
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:08 PM > ep 54 done. total_steps=18218 | reward=1.0 | episode_steps=412 | hours=0.005 | epsilon=0.462
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:08 PM > ep 55 done. total_steps=18314 | reward=1.0 | episode_steps=96 | hours=0.005 | epsilon=0.460
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:08 PM > ep 56 done. total_steps=18339 | reward=1.0 | episode_steps=25 | hours=0.005 | epsilon=0.460
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:08 PM > ep 57 done. total_steps=18392 | reward=1.0 | episode_steps=53 | hours=0.005 | epsilon=0.459
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:08 PM > ep 58 done. total_steps=18720 | reward=1.0 | episode_steps=328 | hours=0.005 | epsilon=0.453
  - Option 0: avg len = 106.50, count = 2
2025/07/28 11:30:08 PM > ep 59 done. total_steps=18760 | reward=1.0 | episode_steps=40 | hours=0.005 | epsilon=0.452
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:08 PM > ep 60 done. total_steps=18814 | reward=1.0 | episode_steps=54 | hours=0.005 | epsilon=0.451
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:08 PM > ep 61 done. total_steps=18822 | reward=1.0 | episode_steps=8 | hours=0.005 | epsilon=0.451
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:08 PM > ep 62 done. total_steps=18927 | reward=1.0 | episode_steps=105 | hours=0.005 | epsilon=0.449
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 17.00, count = 1
2025/07/28 11:30:08 PM > ep 63 done. total_steps=19073 | reward=1.0 | episode_steps=146 | hours=0.005 | epsilon=0.447
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:08 PM > ep 64 done. total_steps=19118 | reward=1.0 | episode_steps=45 | hours=0.005 | epsilon=0.446
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.00, count = 1
2025/07/28 11:30:08 PM > ep 65 done. total_steps=19185 | reward=1.0 | episode_steps=67 | hours=0.005 | epsilon=0.445
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 14.00, count = 1
2025/07/28 11:30:09 PM > ep 66 done. total_steps=19221 | reward=1.0 | episode_steps=36 | hours=0.005 | epsilon=0.444
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:09 PM > ep 67 done. total_steps=19232 | reward=1.0 | episode_steps=11 | hours=0.005 | epsilon=0.444
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:09 PM > ep 68 done. total_steps=19426 | reward=1.0 | episode_steps=194 | hours=0.005 | epsilon=0.441
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 4.00, count = 1
2025/07/28 11:30:09 PM > ep 69 done. total_steps=19449 | reward=1.0 | episode_steps=23 | hours=0.005 | epsilon=0.440
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:09 PM > ep 70 done. total_steps=19619 | reward=1.0 | episode_steps=170 | hours=0.005 | epsilon=0.437
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 30.00, count = 1
2025/07/28 11:30:09 PM > ep 71 done. total_steps=19634 | reward=1.0 | episode_steps=15 | hours=0.005 | epsilon=0.437
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:09 PM > ep 72 done. total_steps=19655 | reward=1.0 | episode_steps=21 | hours=0.005 | epsilon=0.437
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:09 PM > ep 73 done. total_steps=19699 | reward=1.0 | episode_steps=44 | hours=0.005 | epsilon=0.436
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:09 PM > ep 74 done. total_steps=19856 | reward=1.0 | episode_steps=157 | hours=0.006 | epsilon=0.434
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 43.00, count = 1
2025/07/28 11:30:09 PM > ep 75 done. total_steps=19890 | reward=1.0 | episode_steps=34 | hours=0.006 | epsilon=0.433
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:09 PM > ep 76 done. total_steps=19973 | reward=1.0 | episode_steps=83 | hours=0.006 | epsilon=0.432
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 8.50, count = 2
2025/07/28 11:30:09 PM > ep 77 done. total_steps=19996 | reward=1.0 | episode_steps=23 | hours=0.006 | epsilon=0.431
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:09 PM > ep 78 done. total_steps=20031 | reward=1.0 | episode_steps=35 | hours=0.006 | epsilon=0.431
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:09 PM > ep 79 done. total_steps=20070 | reward=1.0 | episode_steps=39 | hours=0.006 | epsilon=0.430
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:09 PM > ep 80 done. total_steps=20111 | reward=1.0 | episode_steps=41 | hours=0.006 | epsilon=0.429
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:09 PM > ep 81 done. total_steps=20150 | reward=1.0 | episode_steps=39 | hours=0.006 | epsilon=0.429
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:09 PM > ep 82 done. total_steps=20165 | reward=1.0 | episode_steps=15 | hours=0.006 | epsilon=0.428
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:09 PM > ep 83 done. total_steps=20268 | reward=1.0 | episode_steps=103 | hours=0.006 | epsilon=0.427
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:09 PM > ep 84 done. total_steps=20321 | reward=1.0 | episode_steps=53 | hours=0.006 | epsilon=0.426
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:09 PM > ep 85 done. total_steps=20342 | reward=1.0 | episode_steps=21 | hours=0.006 | epsilon=0.425
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:09 PM > ep 86 done. total_steps=20383 | reward=1.0 | episode_steps=41 | hours=0.006 | epsilon=0.425
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:09 PM > ep 87 done. total_steps=20401 | reward=1.0 | episode_steps=18 | hours=0.006 | epsilon=0.425
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:09 PM > ep 88 done. total_steps=20488 | reward=1.0 | episode_steps=87 | hours=0.006 | epsilon=0.423
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:09 PM > ep 89 done. total_steps=20501 | reward=1.0 | episode_steps=13 | hours=0.006 | epsilon=0.423
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:09 PM > ep 90 done. total_steps=20502 | reward=1.0 | episode_steps=1 | hours=0.006 | epsilon=0.423
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:09 PM > ep 91 done. total_steps=20512 | reward=1.0 | episode_steps=10 | hours=0.006 | epsilon=0.423
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:09 PM > ep 92 done. total_steps=20523 | reward=1.0 | episode_steps=11 | hours=0.006 | epsilon=0.423
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 2.00, count = 1
2025/07/28 11:30:10 PM > ep 93 done. total_steps=20606 | reward=1.0 | episode_steps=83 | hours=0.006 | epsilon=0.421
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:10 PM > ep 94 done. total_steps=20641 | reward=1.0 | episode_steps=35 | hours=0.006 | epsilon=0.421
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:10 PM > ep 95 done. total_steps=20660 | reward=1.0 | episode_steps=19 | hours=0.006 | epsilon=0.420
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:10 PM > ep 96 done. total_steps=20671 | reward=1.0 | episode_steps=11 | hours=0.006 | epsilon=0.420
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:10 PM > ep 97 done. total_steps=20696 | reward=1.0 | episode_steps=25 | hours=0.006 | epsilon=0.420
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:10 PM > ep 98 done. total_steps=20761 | reward=1.0 | episode_steps=65 | hours=0.006 | epsilon=0.419
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:10 PM > ep 99 done. total_steps=21038 | reward=1.0 | episode_steps=277 | hours=0.006 | epsilon=0.414
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:10 PM > ep 100 done. total_steps=21068 | reward=1.0 | episode_steps=30 | hours=0.006 | epsilon=0.414
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:10 PM > ep 101 done. total_steps=21120 | reward=1.0 | episode_steps=52 | hours=0.006 | epsilon=0.413
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:10 PM > ep 102 done. total_steps=21169 | reward=1.0 | episode_steps=49 | hours=0.006 | epsilon=0.412
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:10 PM > ep 103 done. total_steps=21177 | reward=1.0 | episode_steps=8 | hours=0.006 | epsilon=0.412
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:10 PM > ep 104 done. total_steps=21187 | reward=1.0 | episode_steps=10 | hours=0.006 | epsilon=0.412
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:10 PM > ep 105 done. total_steps=21196 | reward=1.0 | episode_steps=9 | hours=0.006 | epsilon=0.412
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.50, count = 2
2025/07/28 11:30:10 PM > ep 106 done. total_steps=21281 | reward=1.0 | episode_steps=85 | hours=0.006 | epsilon=0.411
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:10 PM > ep 107 done. total_steps=21320 | reward=1.0 | episode_steps=39 | hours=0.006 | epsilon=0.410
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:10 PM > ep 108 done. total_steps=21351 | reward=1.0 | episode_steps=31 | hours=0.006 | epsilon=0.409
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:10 PM > ep 109 done. total_steps=21374 | reward=1.0 | episode_steps=23 | hours=0.006 | epsilon=0.409
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 6.00, count = 1
2025/07/28 11:30:10 PM > ep 110 done. total_steps=21409 | reward=1.0 | episode_steps=35 | hours=0.006 | epsilon=0.409
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:10 PM > ep 111 done. total_steps=21540 | reward=1.0 | episode_steps=131 | hours=0.006 | epsilon=0.407
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:10 PM > ep 112 done. total_steps=21600 | reward=1.0 | episode_steps=60 | hours=0.006 | epsilon=0.406
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 7.00, count = 1
2025/07/28 11:30:10 PM > ep 113 done. total_steps=21607 | reward=1.0 | episode_steps=7 | hours=0.006 | epsilon=0.406
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:10 PM > ep 114 done. total_steps=21686 | reward=1.0 | episode_steps=79 | hours=0.006 | epsilon=0.404
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 28.50, count = 2
2025/07/28 11:30:10 PM > ep 115 done. total_steps=21761 | reward=1.0 | episode_steps=75 | hours=0.006 | epsilon=0.403
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:10 PM > ep 116 done. total_steps=21786 | reward=1.0 | episode_steps=25 | hours=0.006 | epsilon=0.403
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.00, count = 1
2025/07/28 11:30:10 PM > ep 117 done. total_steps=21793 | reward=1.0 | episode_steps=7 | hours=0.006 | epsilon=0.403
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:10 PM > ep 118 done. total_steps=21807 | reward=1.0 | episode_steps=14 | hours=0.006 | epsilon=0.403
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:10 PM > ep 119 done. total_steps=21811 | reward=1.0 | episode_steps=4 | hours=0.006 | epsilon=0.402
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:10 PM > ep 120 done. total_steps=21814 | reward=1.0 | episode_steps=3 | hours=0.006 | epsilon=0.402
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:10 PM > ep 121 done. total_steps=21824 | reward=1.0 | episode_steps=10 | hours=0.006 | epsilon=0.402
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:10 PM > ep 122 done. total_steps=21836 | reward=1.0 | episode_steps=12 | hours=0.006 | epsilon=0.402
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 2.00, count = 1
2025/07/28 11:30:10 PM > ep 123 done. total_steps=21905 | reward=1.0 | episode_steps=69 | hours=0.006 | epsilon=0.401
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:10 PM > ep 124 done. total_steps=21938 | reward=1.0 | episode_steps=33 | hours=0.006 | epsilon=0.401
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:10 PM > ep 125 done. total_steps=21973 | reward=1.0 | episode_steps=35 | hours=0.006 | epsilon=0.400
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 20.00, count = 1
2025/07/28 11:30:11 PM > ep 126 done. total_steps=22035 | reward=1.0 | episode_steps=62 | hours=0.006 | epsilon=0.399
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 17.00, count = 2
2025/07/28 11:30:11 PM > ep 127 done. total_steps=22070 | reward=1.0 | episode_steps=35 | hours=0.006 | epsilon=0.399
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:11 PM > ep 128 done. total_steps=22103 | reward=1.0 | episode_steps=33 | hours=0.006 | epsilon=0.398
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:11 PM > ep 129 done. total_steps=22171 | reward=1.0 | episode_steps=68 | hours=0.006 | epsilon=0.397
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 24.00, count = 1
2025/07/28 11:30:11 PM > ep 130 done. total_steps=22186 | reward=1.0 | episode_steps=15 | hours=0.006 | epsilon=0.397
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:11 PM > ep 131 done. total_steps=22293 | reward=1.0 | episode_steps=107 | hours=0.006 | epsilon=0.395
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:11 PM > ep 132 done. total_steps=22339 | reward=1.0 | episode_steps=46 | hours=0.006 | epsilon=0.395
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:11 PM > ep 133 done. total_steps=22378 | reward=1.0 | episode_steps=39 | hours=0.006 | epsilon=0.394
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:11 PM > ep 134 done. total_steps=22388 | reward=1.0 | episode_steps=10 | hours=0.006 | epsilon=0.394
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:11 PM > ep 135 done. total_steps=22427 | reward=1.0 | episode_steps=39 | hours=0.006 | epsilon=0.393
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:11 PM > ep 136 done. total_steps=22448 | reward=1.0 | episode_steps=21 | hours=0.006 | epsilon=0.393
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:11 PM > ep 137 done. total_steps=22645 | reward=1.0 | episode_steps=197 | hours=0.006 | epsilon=0.390
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:11 PM > ep 138 done. total_steps=22674 | reward=1.0 | episode_steps=29 | hours=0.006 | epsilon=0.390
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 12.00, count = 1
2025/07/28 11:30:11 PM > ep 139 done. total_steps=22760 | reward=1.0 | episode_steps=86 | hours=0.006 | epsilon=0.388
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:11 PM > ep 140 done. total_steps=22775 | reward=1.0 | episode_steps=15 | hours=0.006 | epsilon=0.388
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:11 PM > ep 141 done. total_steps=22841 | reward=1.0 | episode_steps=66 | hours=0.006 | epsilon=0.387
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 4.00, count = 1
2025/07/28 11:30:11 PM > ep 142 done. total_steps=22930 | reward=1.0 | episode_steps=89 | hours=0.006 | epsilon=0.386
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:11 PM > ep 143 done. total_steps=22958 | reward=1.0 | episode_steps=28 | hours=0.006 | epsilon=0.386
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:11 PM > ep 144 done. total_steps=22967 | reward=1.0 | episode_steps=9 | hours=0.006 | epsilon=0.385
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:11 PM > ep 145 done. total_steps=22999 | reward=1.0 | episode_steps=32 | hours=0.006 | epsilon=0.385
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:11 PM > ep 146 done. total_steps=23033 | reward=1.0 | episode_steps=34 | hours=0.006 | epsilon=0.385
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.00, count = 1
2025/07/28 11:30:11 PM > ep 147 done. total_steps=23036 | reward=1.0 | episode_steps=3 | hours=0.006 | epsilon=0.384
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:11 PM > ep 148 done. total_steps=23038 | reward=1.0 | episode_steps=2 | hours=0.006 | epsilon=0.384
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:11 PM > ep 149 done. total_steps=23062 | reward=1.0 | episode_steps=24 | hours=0.006 | epsilon=0.384
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:11 PM > ep 150 done. total_steps=23080 | reward=1.0 | episode_steps=18 | hours=0.006 | epsilon=0.384
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 5.00, count = 1
2025/07/28 11:30:11 PM > ep 151 done. total_steps=23132 | reward=1.0 | episode_steps=52 | hours=0.006 | epsilon=0.383
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 6.00, count = 1
2025/07/28 11:30:11 PM > ep 152 done. total_steps=23150 | reward=1.0 | episode_steps=18 | hours=0.006 | epsilon=0.383
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:11 PM > ep 153 done. total_steps=23180 | reward=1.0 | episode_steps=30 | hours=0.006 | epsilon=0.382
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 10.00, count = 1
2025/07/28 11:30:11 PM > ep 154 done. total_steps=23225 | reward=1.0 | episode_steps=45 | hours=0.006 | epsilon=0.382
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 6.67, count = 3
2025/07/28 11:30:11 PM > ep 155 done. total_steps=23254 | reward=1.0 | episode_steps=29 | hours=0.006 | epsilon=0.381
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:11 PM > ep 156 done. total_steps=23284 | reward=1.0 | episode_steps=30 | hours=0.006 | epsilon=0.381
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:11 PM > ep 157 done. total_steps=23358 | reward=1.0 | episode_steps=74 | hours=0.006 | epsilon=0.380
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:11 PM > ep 158 done. total_steps=23370 | reward=1.0 | episode_steps=12 | hours=0.006 | epsilon=0.380
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:11 PM > ep 159 done. total_steps=23379 | reward=1.0 | episode_steps=9 | hours=0.006 | epsilon=0.380
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:11 PM > ep 160 done. total_steps=23397 | reward=1.0 | episode_steps=18 | hours=0.006 | epsilon=0.379
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:12 PM > ep 161 done. total_steps=23426 | reward=1.0 | episode_steps=29 | hours=0.007 | epsilon=0.379
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:12 PM > ep 162 done. total_steps=23554 | reward=1.0 | episode_steps=128 | hours=0.007 | epsilon=0.377
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:12 PM > ep 163 done. total_steps=23586 | reward=1.0 | episode_steps=32 | hours=0.007 | epsilon=0.377
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 17.00, count = 1
2025/07/28 11:30:12 PM > ep 164 done. total_steps=23646 | reward=1.0 | episode_steps=60 | hours=0.007 | epsilon=0.376
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 15.50, count = 2
2025/07/28 11:30:12 PM > ep 165 done. total_steps=23692 | reward=1.0 | episode_steps=46 | hours=0.007 | epsilon=0.375
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 5.75, count = 4
2025/07/28 11:30:12 PM > ep 166 done. total_steps=23728 | reward=1.0 | episode_steps=36 | hours=0.007 | epsilon=0.375
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:12 PM > ep 167 done. total_steps=23756 | reward=1.0 | episode_steps=28 | hours=0.007 | epsilon=0.374
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:12 PM > ep 168 done. total_steps=23777 | reward=1.0 | episode_steps=21 | hours=0.007 | epsilon=0.374
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:12 PM > ep 169 done. total_steps=23876 | reward=1.0 | episode_steps=99 | hours=0.007 | epsilon=0.373
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 26.00, count = 1
2025/07/28 11:30:12 PM > ep 170 done. total_steps=23881 | reward=1.0 | episode_steps=5 | hours=0.007 | epsilon=0.373
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:12 PM > ep 171 done. total_steps=23909 | reward=1.0 | episode_steps=28 | hours=0.007 | epsilon=0.372
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:12 PM > ep 172 done. total_steps=23925 | reward=1.0 | episode_steps=16 | hours=0.007 | epsilon=0.372
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.00, count = 1
2025/07/28 11:30:12 PM > ep 173 done. total_steps=23936 | reward=1.0 | episode_steps=11 | hours=0.007 | epsilon=0.372
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:12 PM > ep 174 done. total_steps=23975 | reward=1.0 | episode_steps=39 | hours=0.007 | epsilon=0.371
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 5.00, count = 1
2025/07/28 11:30:12 PM > ep 175 done. total_steps=23989 | reward=1.0 | episode_steps=14 | hours=0.007 | epsilon=0.371
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:12 PM > ep 176 done. total_steps=23995 | reward=1.0 | episode_steps=6 | hours=0.007 | epsilon=0.371
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:12 PM > ep 177 done. total_steps=24000 | reward=1.0 | episode_steps=5 | hours=0.007 | epsilon=0.371
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:12 PM > ep 178 done. total_steps=24019 | reward=1.0 | episode_steps=19 | hours=0.007 | epsilon=0.371
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:12 PM > ep 179 done. total_steps=24054 | reward=1.0 | episode_steps=35 | hours=0.007 | epsilon=0.370
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:12 PM > ep 180 done. total_steps=24091 | reward=1.0 | episode_steps=37 | hours=0.007 | epsilon=0.370
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:12 PM > ep 181 done. total_steps=24099 | reward=1.0 | episode_steps=8 | hours=0.007 | epsilon=0.370
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:12 PM > ep 182 done. total_steps=24107 | reward=1.0 | episode_steps=8 | hours=0.007 | epsilon=0.370
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:12 PM > ep 183 done. total_steps=24110 | reward=1.0 | episode_steps=3 | hours=0.007 | epsilon=0.370
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:12 PM > ep 184 done. total_steps=24116 | reward=1.0 | episode_steps=6 | hours=0.007 | epsilon=0.370
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:12 PM > ep 185 done. total_steps=24121 | reward=1.0 | episode_steps=5 | hours=0.007 | epsilon=0.369
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:12 PM > ep 186 done. total_steps=24145 | reward=1.0 | episode_steps=24 | hours=0.007 | epsilon=0.369
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:12 PM > ep 187 done. total_steps=24157 | reward=1.0 | episode_steps=12 | hours=0.007 | epsilon=0.369
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 4.00, count = 2
2025/07/28 11:30:12 PM > ep 188 done. total_steps=24179 | reward=1.0 | episode_steps=22 | hours=0.007 | epsilon=0.369
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.00, count = 1
2025/07/28 11:30:12 PM > ep 189 done. total_steps=24183 | reward=1.0 | episode_steps=4 | hours=0.007 | epsilon=0.369
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:12 PM > ep 190 done. total_steps=24219 | reward=1.0 | episode_steps=36 | hours=0.007 | epsilon=0.368
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:12 PM > ep 191 done. total_steps=24228 | reward=1.0 | episode_steps=9 | hours=0.007 | epsilon=0.368
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:12 PM > ep 192 done. total_steps=24251 | reward=1.0 | episode_steps=23 | hours=0.007 | epsilon=0.368
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 5.00, count = 2
2025/07/28 11:30:12 PM > ep 193 done. total_steps=24297 | reward=1.0 | episode_steps=46 | hours=0.007 | epsilon=0.367
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 5.83, count = 6
2025/07/28 11:30:12 PM > ep 194 done. total_steps=24301 | reward=1.0 | episode_steps=4 | hours=0.007 | epsilon=0.367
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:12 PM > ep 195 done. total_steps=24314 | reward=1.0 | episode_steps=13 | hours=0.007 | epsilon=0.367
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:12 PM > ep 196 done. total_steps=24334 | reward=1.0 | episode_steps=20 | hours=0.007 | epsilon=0.367
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:12 PM > ep 197 done. total_steps=24351 | reward=1.0 | episode_steps=17 | hours=0.007 | epsilon=0.366
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:12 PM > ep 198 done. total_steps=24394 | reward=1.0 | episode_steps=43 | hours=0.007 | epsilon=0.366
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:12 PM > ep 199 done. total_steps=24402 | reward=1.0 | episode_steps=8 | hours=0.007 | epsilon=0.366
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.00, count = 2
2025/07/28 11:30:12 PM > ep 200 done. total_steps=24441 | reward=1.0 | episode_steps=39 | hours=0.007 | epsilon=0.365
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:12 PM > ep 201 done. total_steps=24471 | reward=1.0 | episode_steps=30 | hours=0.007 | epsilon=0.365
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:12 PM > ep 202 done. total_steps=24493 | reward=1.0 | episode_steps=22 | hours=0.007 | epsilon=0.364
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:12 PM > ep 203 done. total_steps=24495 | reward=1.0 | episode_steps=2 | hours=0.007 | epsilon=0.364
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:12 PM > ep 204 done. total_steps=24520 | reward=1.0 | episode_steps=25 | hours=0.007 | epsilon=0.364
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:12 PM > ep 205 done. total_steps=24570 | reward=1.0 | episode_steps=50 | hours=0.007 | epsilon=0.363
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:12 PM > ep 206 done. total_steps=24574 | reward=1.0 | episode_steps=4 | hours=0.007 | epsilon=0.363
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:12 PM > ep 207 done. total_steps=24591 | reward=1.0 | episode_steps=17 | hours=0.007 | epsilon=0.363
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 3.00, count = 1
2025/07/28 11:30:12 PM > ep 208 done. total_steps=24625 | reward=1.0 | episode_steps=34 | hours=0.007 | epsilon=0.363
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 4.00, count = 2
2025/07/28 11:30:12 PM > ep 209 done. total_steps=24632 | reward=1.0 | episode_steps=7 | hours=0.007 | epsilon=0.363
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:12 PM > ep 210 done. total_steps=24651 | reward=1.0 | episode_steps=19 | hours=0.007 | epsilon=0.362
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 11.00, count = 1
2025/07/28 11:30:12 PM > ep 211 done. total_steps=24659 | reward=1.0 | episode_steps=8 | hours=0.007 | epsilon=0.362
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:12 PM > ep 212 done. total_steps=24696 | reward=1.0 | episode_steps=37 | hours=0.007 | epsilon=0.362
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 2.67, count = 3
2025/07/28 11:30:12 PM > ep 213 done. total_steps=24775 | reward=1.0 | episode_steps=79 | hours=0.007 | epsilon=0.361
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:13 PM > ep 214 done. total_steps=24797 | reward=1.0 | episode_steps=22 | hours=0.007 | epsilon=0.360
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:13 PM > ep 215 done. total_steps=24801 | reward=1.0 | episode_steps=4 | hours=0.007 | epsilon=0.360
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:13 PM > ep 216 done. total_steps=24814 | reward=1.0 | episode_steps=13 | hours=0.007 | epsilon=0.360
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:13 PM > ep 217 done. total_steps=24822 | reward=1.0 | episode_steps=8 | hours=0.007 | epsilon=0.360
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:13 PM > ep 218 done. total_steps=24863 | reward=1.0 | episode_steps=41 | hours=0.007 | epsilon=0.360
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:13 PM > ep 219 done. total_steps=24882 | reward=1.0 | episode_steps=19 | hours=0.007 | epsilon=0.359
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:13 PM > ep 220 done. total_steps=24934 | reward=1.0 | episode_steps=52 | hours=0.007 | epsilon=0.359
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 13.00, count = 1
2025/07/28 11:30:13 PM > ep 221 done. total_steps=24957 | reward=1.0 | episode_steps=23 | hours=0.007 | epsilon=0.358
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:13 PM > ep 222 done. total_steps=24975 | reward=1.0 | episode_steps=18 | hours=0.007 | epsilon=0.358
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:13 PM > ep 223 done. total_steps=25050 | reward=1.0 | episode_steps=75 | hours=0.007 | epsilon=0.357
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:13 PM > ep 224 done. total_steps=25052 | reward=1.0 | episode_steps=2 | hours=0.007 | epsilon=0.357
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:13 PM > ep 225 done. total_steps=25066 | reward=1.0 | episode_steps=14 | hours=0.007 | epsilon=0.357
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:13 PM > ep 226 done. total_steps=25084 | reward=1.0 | episode_steps=18 | hours=0.007 | epsilon=0.357
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:13 PM > ep 227 done. total_steps=25107 | reward=1.0 | episode_steps=23 | hours=0.007 | epsilon=0.356
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:13 PM > ep 228 done. total_steps=25173 | reward=1.0 | episode_steps=66 | hours=0.007 | epsilon=0.356
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:13 PM > ep 229 done. total_steps=25210 | reward=1.0 | episode_steps=37 | hours=0.007 | epsilon=0.355
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:13 PM > ep 230 done. total_steps=25231 | reward=1.0 | episode_steps=21 | hours=0.007 | epsilon=0.355
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:13 PM > ep 231 done. total_steps=25236 | reward=1.0 | episode_steps=5 | hours=0.007 | epsilon=0.355
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:13 PM > ep 232 done. total_steps=25240 | reward=1.0 | episode_steps=4 | hours=0.007 | epsilon=0.355
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:13 PM > ep 233 done. total_steps=25287 | reward=1.0 | episode_steps=47 | hours=0.007 | epsilon=0.354
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:13 PM > ep 234 done. total_steps=25289 | reward=1.0 | episode_steps=2 | hours=0.007 | epsilon=0.354
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:13 PM > ep 235 done. total_steps=25291 | reward=1.0 | episode_steps=2 | hours=0.007 | epsilon=0.354
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:13 PM > ep 236 done. total_steps=25297 | reward=1.0 | episode_steps=6 | hours=0.007 | epsilon=0.354
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:13 PM > ep 237 done. total_steps=25304 | reward=1.0 | episode_steps=7 | hours=0.007 | epsilon=0.354
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:13 PM > ep 238 done. total_steps=25318 | reward=1.0 | episode_steps=14 | hours=0.007 | epsilon=0.354
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:13 PM > ep 239 done. total_steps=25329 | reward=1.0 | episode_steps=11 | hours=0.007 | epsilon=0.354
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:13 PM > ep 240 done. total_steps=25336 | reward=1.0 | episode_steps=7 | hours=0.007 | epsilon=0.354
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:13 PM > ep 241 done. total_steps=25383 | reward=1.0 | episode_steps=47 | hours=0.007 | epsilon=0.353
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:13 PM > ep 242 done. total_steps=25428 | reward=1.0 | episode_steps=45 | hours=0.007 | epsilon=0.352
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 9.00, count = 1
2025/07/28 11:30:13 PM > ep 243 done. total_steps=25433 | reward=1.0 | episode_steps=5 | hours=0.007 | epsilon=0.352
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:13 PM > ep 244 done. total_steps=25482 | reward=1.0 | episode_steps=49 | hours=0.007 | epsilon=0.352
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:13 PM > ep 245 done. total_steps=25483 | reward=1.0 | episode_steps=1 | hours=0.007 | epsilon=0.352
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:13 PM > ep 246 done. total_steps=25485 | reward=1.0 | episode_steps=2 | hours=0.007 | epsilon=0.352
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:13 PM > ep 247 done. total_steps=25501 | reward=1.0 | episode_steps=16 | hours=0.007 | epsilon=0.351
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:13 PM > ep 248 done. total_steps=25516 | reward=1.0 | episode_steps=15 | hours=0.007 | epsilon=0.351
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:13 PM > ep 249 done. total_steps=25544 | reward=1.0 | episode_steps=28 | hours=0.007 | epsilon=0.351
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:13 PM > ep 250 done. total_steps=25555 | reward=1.0 | episode_steps=11 | hours=0.007 | epsilon=0.351
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:13 PM > ep 251 done. total_steps=25566 | reward=1.0 | episode_steps=11 | hours=0.007 | epsilon=0.351
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:13 PM > ep 252 done. total_steps=25586 | reward=1.0 | episode_steps=20 | hours=0.007 | epsilon=0.350
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:13 PM > ep 253 done. total_steps=25625 | reward=1.0 | episode_steps=39 | hours=0.007 | epsilon=0.350
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:13 PM > ep 254 done. total_steps=25640 | reward=1.0 | episode_steps=15 | hours=0.007 | epsilon=0.350
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:13 PM > ep 255 done. total_steps=25648 | reward=1.0 | episode_steps=8 | hours=0.007 | epsilon=0.350
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:13 PM > ep 256 done. total_steps=25685 | reward=1.0 | episode_steps=37 | hours=0.007 | epsilon=0.349
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 11.00, count = 1
2025/07/28 11:30:13 PM > ep 257 done. total_steps=25700 | reward=1.0 | episode_steps=15 | hours=0.007 | epsilon=0.349
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:13 PM > ep 258 done. total_steps=25703 | reward=1.0 | episode_steps=3 | hours=0.007 | epsilon=0.349
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:13 PM > ep 259 done. total_steps=25709 | reward=1.0 | episode_steps=6 | hours=0.007 | epsilon=0.349
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:13 PM > ep 260 done. total_steps=25716 | reward=1.0 | episode_steps=7 | hours=0.007 | epsilon=0.349
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:13 PM > ep 261 done. total_steps=25776 | reward=1.0 | episode_steps=60 | hours=0.007 | epsilon=0.348
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:13 PM > ep 262 done. total_steps=25782 | reward=1.0 | episode_steps=6 | hours=0.007 | epsilon=0.348
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.00, count = 1
2025/07/28 11:30:13 PM > ep 263 done. total_steps=25807 | reward=1.0 | episode_steps=25 | hours=0.007 | epsilon=0.348
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:13 PM > ep 264 done. total_steps=25810 | reward=1.0 | episode_steps=3 | hours=0.007 | epsilon=0.348
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:13 PM > ep 265 done. total_steps=25820 | reward=1.0 | episode_steps=10 | hours=0.007 | epsilon=0.348
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:13 PM > ep 266 done. total_steps=25842 | reward=1.0 | episode_steps=22 | hours=0.007 | epsilon=0.347
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:13 PM > ep 267 done. total_steps=25847 | reward=1.0 | episode_steps=5 | hours=0.007 | epsilon=0.347
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.00, count = 1
2025/07/28 11:30:13 PM > ep 268 done. total_steps=25861 | reward=1.0 | episode_steps=14 | hours=0.007 | epsilon=0.347
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.00, count = 2
2025/07/28 11:30:13 PM > ep 269 done. total_steps=25869 | reward=1.0 | episode_steps=8 | hours=0.007 | epsilon=0.347
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:13 PM > ep 270 done. total_steps=25874 | reward=1.0 | episode_steps=5 | hours=0.007 | epsilon=0.347
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:13 PM > ep 271 done. total_steps=25938 | reward=1.0 | episode_steps=64 | hours=0.007 | epsilon=0.346
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 5.00, count = 2
2025/07/28 11:30:13 PM > ep 272 done. total_steps=25947 | reward=1.0 | episode_steps=9 | hours=0.007 | epsilon=0.346
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:13 PM > ep 273 done. total_steps=25986 | reward=1.0 | episode_steps=39 | hours=0.007 | epsilon=0.345
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.00, count = 1
2025/07/28 11:30:13 PM > ep 274 done. total_steps=25992 | reward=1.0 | episode_steps=6 | hours=0.007 | epsilon=0.345
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:13 PM > ep 275 done. total_steps=26038 | reward=1.0 | episode_steps=46 | hours=0.007 | epsilon=0.345
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 3.50, count = 2
2025/07/28 11:30:13 PM > ep 276 done. total_steps=26053 | reward=1.0 | episode_steps=15 | hours=0.007 | epsilon=0.345
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:13 PM > ep 277 done. total_steps=26069 | reward=1.0 | episode_steps=16 | hours=0.007 | epsilon=0.344
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 4.00, count = 1
2025/07/28 11:30:13 PM > ep 278 done. total_steps=26111 | reward=1.0 | episode_steps=42 | hours=0.007 | epsilon=0.344
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:13 PM > ep 279 done. total_steps=26123 | reward=1.0 | episode_steps=12 | hours=0.007 | epsilon=0.344
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:14 PM > ep 280 done. total_steps=26133 | reward=1.0 | episode_steps=10 | hours=0.007 | epsilon=0.344
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:14 PM > ep 281 done. total_steps=26154 | reward=1.0 | episode_steps=21 | hours=0.007 | epsilon=0.343
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 4.00, count = 1
2025/07/28 11:30:14 PM > ep 282 done. total_steps=26161 | reward=1.0 | episode_steps=7 | hours=0.007 | epsilon=0.343
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:14 PM > ep 283 done. total_steps=26190 | reward=1.0 | episode_steps=29 | hours=0.007 | epsilon=0.343
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:14 PM > ep 284 done. total_steps=26226 | reward=1.0 | episode_steps=36 | hours=0.007 | epsilon=0.343
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:14 PM > ep 285 done. total_steps=26271 | reward=1.0 | episode_steps=45 | hours=0.007 | epsilon=0.342
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:14 PM > ep 286 done. total_steps=26294 | reward=1.0 | episode_steps=23 | hours=0.007 | epsilon=0.342
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:14 PM > ep 287 done. total_steps=26298 | reward=1.0 | episode_steps=4 | hours=0.007 | epsilon=0.342
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:14 PM > ep 288 done. total_steps=26322 | reward=1.0 | episode_steps=24 | hours=0.007 | epsilon=0.341
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:14 PM > ep 289 done. total_steps=26331 | reward=1.0 | episode_steps=9 | hours=0.007 | epsilon=0.341
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:14 PM > ep 290 done. total_steps=26358 | reward=1.0 | episode_steps=27 | hours=0.007 | epsilon=0.341
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:14 PM > ep 291 done. total_steps=26359 | reward=1.0 | episode_steps=1 | hours=0.007 | epsilon=0.341
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:14 PM > ep 292 done. total_steps=26364 | reward=1.0 | episode_steps=5 | hours=0.007 | epsilon=0.341
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:14 PM > ep 293 done. total_steps=26368 | reward=1.0 | episode_steps=4 | hours=0.007 | epsilon=0.341
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:14 PM > ep 294 done. total_steps=26381 | reward=1.0 | episode_steps=13 | hours=0.007 | epsilon=0.341
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:14 PM > ep 295 done. total_steps=26383 | reward=1.0 | episode_steps=2 | hours=0.007 | epsilon=0.341
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:14 PM > ep 296 done. total_steps=26398 | reward=1.0 | episode_steps=15 | hours=0.007 | epsilon=0.340
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:14 PM > ep 297 done. total_steps=26410 | reward=1.0 | episode_steps=12 | hours=0.007 | epsilon=0.340
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:14 PM > ep 298 done. total_steps=26424 | reward=1.0 | episode_steps=14 | hours=0.007 | epsilon=0.340
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:14 PM > ep 299 done. total_steps=26494 | reward=1.0 | episode_steps=70 | hours=0.007 | epsilon=0.339
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.00, count = 1
2025/07/28 11:30:14 PM > ep 300 done. total_steps=26516 | reward=1.0 | episode_steps=22 | hours=0.007 | epsilon=0.339
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 2.00, count = 1
2025/07/28 11:30:14 PM > ep 301 done. total_steps=26594 | reward=1.0 | episode_steps=78 | hours=0.007 | epsilon=0.338
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.00, count = 1
2025/07/28 11:30:14 PM > ep 302 done. total_steps=26597 | reward=1.0 | episode_steps=3 | hours=0.007 | epsilon=0.338
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:14 PM > ep 303 done. total_steps=26623 | reward=1.0 | episode_steps=26 | hours=0.007 | epsilon=0.338
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:14 PM > ep 304 done. total_steps=26628 | reward=1.0 | episode_steps=5 | hours=0.007 | epsilon=0.338
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:14 PM > ep 305 done. total_steps=26639 | reward=1.0 | episode_steps=11 | hours=0.007 | epsilon=0.338
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:14 PM > ep 306 done. total_steps=26665 | reward=1.0 | episode_steps=26 | hours=0.007 | epsilon=0.337
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:14 PM > ep 307 done. total_steps=26693 | reward=1.0 | episode_steps=28 | hours=0.007 | epsilon=0.337
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:14 PM > ep 308 done. total_steps=26711 | reward=1.0 | episode_steps=18 | hours=0.007 | epsilon=0.337
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.50, count = 2
2025/07/28 11:30:14 PM > ep 309 done. total_steps=26746 | reward=1.0 | episode_steps=35 | hours=0.007 | epsilon=0.336
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.33, count = 3
2025/07/28 11:30:14 PM > ep 310 done. total_steps=26786 | reward=1.0 | episode_steps=40 | hours=0.007 | epsilon=0.336
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:14 PM > ep 311 done. total_steps=26859 | reward=1.0 | episode_steps=73 | hours=0.007 | epsilon=0.335
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 2.25, count = 4
2025/07/28 11:30:14 PM > ep 312 done. total_steps=26883 | reward=1.0 | episode_steps=24 | hours=0.007 | epsilon=0.335
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.50, count = 2
2025/07/28 11:30:14 PM > ep 313 done. total_steps=26887 | reward=1.0 | episode_steps=4 | hours=0.007 | epsilon=0.335
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:14 PM > ep 314 done. total_steps=26897 | reward=1.0 | episode_steps=10 | hours=0.007 | epsilon=0.335
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:14 PM > ep 315 done. total_steps=26915 | reward=1.0 | episode_steps=18 | hours=0.007 | epsilon=0.334
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 2.50, count = 2
2025/07/28 11:30:14 PM > ep 316 done. total_steps=26942 | reward=1.0 | episode_steps=27 | hours=0.007 | epsilon=0.334
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 3.00, count = 1
2025/07/28 11:30:14 PM > ep 317 done. total_steps=26968 | reward=1.0 | episode_steps=26 | hours=0.007 | epsilon=0.334
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:14 PM > ep 318 done. total_steps=26985 | reward=1.0 | episode_steps=17 | hours=0.007 | epsilon=0.334
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 2.00, count = 2
2025/07/28 11:30:14 PM > ep 319 done. total_steps=26993 | reward=1.0 | episode_steps=8 | hours=0.007 | epsilon=0.333
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:14 PM > ep 320 done. total_steps=27050 | reward=1.0 | episode_steps=57 | hours=0.008 | epsilon=0.333
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 2.50, count = 10
2025/07/28 11:30:14 PM > ep 321 done. total_steps=27066 | reward=1.0 | episode_steps=16 | hours=0.008 | epsilon=0.333
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.00, count = 1
2025/07/28 11:30:14 PM > ep 322 done. total_steps=27095 | reward=1.0 | episode_steps=29 | hours=0.008 | epsilon=0.332
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.00, count = 1
2025/07/28 11:30:14 PM > ep 323 done. total_steps=27111 | reward=1.0 | episode_steps=16 | hours=0.008 | epsilon=0.332
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:14 PM > ep 324 done. total_steps=27120 | reward=1.0 | episode_steps=9 | hours=0.008 | epsilon=0.332
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.00, count = 1
2025/07/28 11:30:14 PM > ep 325 done. total_steps=27145 | reward=1.0 | episode_steps=25 | hours=0.008 | epsilon=0.332
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:14 PM > ep 326 done. total_steps=27156 | reward=1.0 | episode_steps=11 | hours=0.008 | epsilon=0.332
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.00, count = 2
2025/07/28 11:30:14 PM > ep 327 done. total_steps=27167 | reward=1.0 | episode_steps=11 | hours=0.008 | epsilon=0.331
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.00, count = 2
2025/07/28 11:30:14 PM > ep 328 done. total_steps=27178 | reward=1.0 | episode_steps=11 | hours=0.008 | epsilon=0.331
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.50, count = 2
2025/07/28 11:30:14 PM > ep 329 done. total_steps=27194 | reward=1.0 | episode_steps=16 | hours=0.008 | epsilon=0.331
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 2.00, count = 1
2025/07/28 11:30:14 PM > ep 330 done. total_steps=27250 | reward=1.0 | episode_steps=56 | hours=0.008 | epsilon=0.330
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 2.33, count = 6
2025/07/28 11:30:14 PM > ep 331 done. total_steps=27272 | reward=1.0 | episode_steps=22 | hours=0.008 | epsilon=0.330
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:14 PM > ep 332 done. total_steps=27280 | reward=1.0 | episode_steps=8 | hours=0.008 | epsilon=0.330
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:14 PM > ep 333 done. total_steps=27303 | reward=1.0 | episode_steps=23 | hours=0.008 | epsilon=0.330
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:14 PM > ep 334 done. total_steps=27318 | reward=1.0 | episode_steps=15 | hours=0.008 | epsilon=0.330
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:14 PM > ep 335 done. total_steps=27325 | reward=1.0 | episode_steps=7 | hours=0.008 | epsilon=0.330
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:14 PM > ep 336 done. total_steps=27347 | reward=1.0 | episode_steps=22 | hours=0.008 | epsilon=0.329
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 2.50, count = 4
2025/07/28 11:30:14 PM > ep 337 done. total_steps=27351 | reward=1.0 | episode_steps=4 | hours=0.008 | epsilon=0.329
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:14 PM > ep 338 done. total_steps=27372 | reward=1.0 | episode_steps=21 | hours=0.008 | epsilon=0.329
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:14 PM > ep 339 done. total_steps=27390 | reward=1.0 | episode_steps=18 | hours=0.008 | epsilon=0.329
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 2.67, count = 3
2025/07/28 11:30:14 PM > ep 340 done. total_steps=27420 | reward=1.0 | episode_steps=30 | hours=0.008 | epsilon=0.328
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 10.00, count = 1
2025/07/28 11:30:14 PM > ep 341 done. total_steps=27437 | reward=1.0 | episode_steps=17 | hours=0.008 | epsilon=0.328
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 2.50, count = 4
2025/07/28 11:30:14 PM > ep 342 done. total_steps=27465 | reward=1.0 | episode_steps=28 | hours=0.008 | epsilon=0.328
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 5.00, count = 1
2025/07/28 11:30:15 PM > ep 343 done. total_steps=27502 | reward=1.0 | episode_steps=37 | hours=0.008 | epsilon=0.328
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:15 PM > ep 344 done. total_steps=27520 | reward=1.0 | episode_steps=18 | hours=0.008 | epsilon=0.327
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:15 PM > ep 345 done. total_steps=27541 | reward=1.0 | episode_steps=21 | hours=0.008 | epsilon=0.327
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.00, count = 2
2025/07/28 11:30:15 PM > ep 346 done. total_steps=27579 | reward=1.0 | episode_steps=38 | hours=0.008 | epsilon=0.327
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 3.00, count = 1
2025/07/28 11:30:15 PM > ep 347 done. total_steps=27601 | reward=1.0 | episode_steps=22 | hours=0.008 | epsilon=0.326
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:15 PM > ep 348 done. total_steps=27634 | reward=1.0 | episode_steps=33 | hours=0.008 | epsilon=0.326
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 3.33, count = 3
2025/07/28 11:30:15 PM > ep 349 done. total_steps=27666 | reward=1.0 | episode_steps=32 | hours=0.008 | epsilon=0.326
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 5.67, count = 3
2025/07/28 11:30:15 PM > ep 350 done. total_steps=27676 | reward=1.0 | episode_steps=10 | hours=0.008 | epsilon=0.326
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:15 PM > ep 351 done. total_steps=27682 | reward=1.0 | episode_steps=6 | hours=0.008 | epsilon=0.326
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:15 PM > ep 352 done. total_steps=27687 | reward=1.0 | episode_steps=5 | hours=0.008 | epsilon=0.325
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:15 PM > ep 353 done. total_steps=27692 | reward=1.0 | episode_steps=5 | hours=0.008 | epsilon=0.325
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:15 PM > ep 354 done. total_steps=27718 | reward=1.0 | episode_steps=26 | hours=0.008 | epsilon=0.325
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 2.00, count = 1
2025/07/28 11:30:15 PM > ep 355 done. total_steps=27739 | reward=1.0 | episode_steps=21 | hours=0.008 | epsilon=0.325
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 5.00, count = 2
2025/07/28 11:30:15 PM > ep 356 done. total_steps=27784 | reward=1.0 | episode_steps=45 | hours=0.008 | epsilon=0.324
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 2.67, count = 9
2025/07/28 11:30:15 PM > ep 357 done. total_steps=27798 | reward=1.0 | episode_steps=14 | hours=0.008 | epsilon=0.324
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 6.00, count = 1
2025/07/28 11:30:15 PM > ep 358 done. total_steps=27818 | reward=1.0 | episode_steps=20 | hours=0.008 | epsilon=0.324
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.00, count = 2
2025/07/28 11:30:15 PM > ep 359 done. total_steps=27827 | reward=1.0 | episode_steps=9 | hours=0.008 | epsilon=0.324
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 2.00, count = 2
2025/07/28 11:30:15 PM > ep 360 done. total_steps=27882 | reward=1.0 | episode_steps=55 | hours=0.008 | epsilon=0.323
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 11.25, count = 4
2025/07/28 11:30:15 PM > ep 361 done. total_steps=27887 | reward=1.0 | episode_steps=5 | hours=0.008 | epsilon=0.323
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:15 PM > ep 362 done. total_steps=27900 | reward=1.0 | episode_steps=13 | hours=0.008 | epsilon=0.323
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:15 PM > ep 363 done. total_steps=27906 | reward=1.0 | episode_steps=6 | hours=0.008 | epsilon=0.323
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:15 PM > ep 364 done. total_steps=27910 | reward=1.0 | episode_steps=4 | hours=0.008 | epsilon=0.323
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:15 PM > ep 365 done. total_steps=27952 | reward=1.0 | episode_steps=42 | hours=0.008 | epsilon=0.322
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 2.33, count = 6
2025/07/28 11:30:15 PM > ep 366 done. total_steps=27961 | reward=1.0 | episode_steps=9 | hours=0.008 | epsilon=0.322
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 4.00, count = 1
2025/07/28 11:30:15 PM > ep 367 done. total_steps=27993 | reward=1.0 | episode_steps=32 | hours=0.008 | epsilon=0.322
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.50, count = 6
2025/07/28 11:30:15 PM > ep 368 done. total_steps=27998 | reward=1.0 | episode_steps=5 | hours=0.008 | epsilon=0.322
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:15 PM > ep 369 done. total_steps=28024 | reward=1.0 | episode_steps=26 | hours=0.008 | epsilon=0.322
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:15 PM > ep 370 done. total_steps=28036 | reward=1.0 | episode_steps=12 | hours=0.008 | epsilon=0.322
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.20, count = 5
2025/07/28 11:30:15 PM > ep 371 done. total_steps=28048 | reward=1.0 | episode_steps=12 | hours=0.008 | epsilon=0.321
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:15 PM > ep 372 done. total_steps=28080 | reward=1.0 | episode_steps=32 | hours=0.008 | epsilon=0.321
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 3.14, count = 7
2025/07/28 11:30:15 PM > ep 373 done. total_steps=28098 | reward=1.0 | episode_steps=18 | hours=0.008 | epsilon=0.321
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.00, count = 1
2025/07/28 11:30:15 PM > ep 374 done. total_steps=28129 | reward=1.0 | episode_steps=31 | hours=0.008 | epsilon=0.321
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:15 PM > ep 375 done. total_steps=28131 | reward=1.0 | episode_steps=2 | hours=0.008 | epsilon=0.320
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:15 PM > ep 376 done. total_steps=28157 | reward=1.0 | episode_steps=26 | hours=0.008 | epsilon=0.320
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 23.00, count = 1
2025/07/28 11:30:15 PM > ep 377 done. total_steps=28173 | reward=1.0 | episode_steps=16 | hours=0.008 | epsilon=0.320
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.00, count = 1
2025/07/28 11:30:15 PM > ep 378 done. total_steps=28250 | reward=1.0 | episode_steps=77 | hours=0.008 | epsilon=0.319
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 7.62, count = 8
2025/07/28 11:30:15 PM > ep 379 done. total_steps=28336 | reward=1.0 | episode_steps=86 | hours=0.008 | epsilon=0.318
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 8.86, count = 7
2025/07/28 11:30:15 PM > ep 380 done. total_steps=28353 | reward=1.0 | episode_steps=17 | hours=0.008 | epsilon=0.318
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:15 PM > ep 381 done. total_steps=28356 | reward=1.0 | episode_steps=3 | hours=0.008 | epsilon=0.318
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.00, count = 1
2025/07/28 11:30:15 PM > ep 382 done. total_steps=28388 | reward=1.0 | episode_steps=32 | hours=0.008 | epsilon=0.318
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 12.00, count = 1
2025/07/28 11:30:15 PM > ep 383 done. total_steps=28402 | reward=1.0 | episode_steps=14 | hours=0.008 | epsilon=0.318
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 12.00, count = 1
2025/07/28 11:30:15 PM > ep 384 done. total_steps=28405 | reward=1.0 | episode_steps=3 | hours=0.008 | epsilon=0.317
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:15 PM > ep 385 done. total_steps=28414 | reward=1.0 | episode_steps=9 | hours=0.008 | epsilon=0.317
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:15 PM > ep 386 done. total_steps=28435 | reward=1.0 | episode_steps=21 | hours=0.008 | epsilon=0.317
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 2.67, count = 3
2025/07/28 11:30:15 PM > ep 387 done. total_steps=28444 | reward=1.0 | episode_steps=9 | hours=0.008 | epsilon=0.317
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.00, count = 1
2025/07/28 11:30:15 PM > ep 388 done. total_steps=28469 | reward=1.0 | episode_steps=25 | hours=0.008 | epsilon=0.317
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:15 PM > ep 389 done. total_steps=28477 | reward=1.0 | episode_steps=8 | hours=0.008 | epsilon=0.317
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:15 PM > ep 390 done. total_steps=28486 | reward=1.0 | episode_steps=9 | hours=0.008 | epsilon=0.317
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:15 PM > ep 391 done. total_steps=28524 | reward=1.0 | episode_steps=38 | hours=0.008 | epsilon=0.316
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 12.00, count = 1
2025/07/28 11:30:15 PM > ep 392 done. total_steps=28530 | reward=1.0 | episode_steps=6 | hours=0.008 | epsilon=0.316
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:15 PM > ep 393 done. total_steps=28540 | reward=1.0 | episode_steps=10 | hours=0.008 | epsilon=0.316
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.00, count = 3
2025/07/28 11:30:15 PM > ep 394 done. total_steps=28547 | reward=1.0 | episode_steps=7 | hours=0.008 | epsilon=0.316
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:15 PM > ep 395 done. total_steps=28558 | reward=1.0 | episode_steps=11 | hours=0.008 | epsilon=0.316
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 7.00, count = 1
2025/07/28 11:30:15 PM > ep 396 done. total_steps=28591 | reward=1.0 | episode_steps=33 | hours=0.008 | epsilon=0.315
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 5.50, count = 2
2025/07/28 11:30:15 PM > ep 397 done. total_steps=28617 | reward=1.0 | episode_steps=26 | hours=0.008 | epsilon=0.315
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:15 PM > ep 398 done. total_steps=28621 | reward=1.0 | episode_steps=4 | hours=0.008 | epsilon=0.315
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:15 PM > ep 399 done. total_steps=28632 | reward=1.0 | episode_steps=11 | hours=0.008 | epsilon=0.315
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:15 PM > ep 400 done. total_steps=28652 | reward=1.0 | episode_steps=20 | hours=0.008 | epsilon=0.315
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 3.50, count = 2
2025/07/28 11:30:15 PM > ep 401 done. total_steps=28716 | reward=1.0 | episode_steps=64 | hours=0.008 | epsilon=0.314
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 23.50, count = 2
2025/07/28 11:30:15 PM > ep 402 done. total_steps=28725 | reward=1.0 | episode_steps=9 | hours=0.008 | epsilon=0.314
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:15 PM > ep 403 done. total_steps=28795 | reward=1.0 | episode_steps=70 | hours=0.008 | epsilon=0.313
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 14.25, count = 4
2025/07/28 11:30:16 PM > ep 404 done. total_steps=28822 | reward=1.0 | episode_steps=27 | hours=0.008 | epsilon=0.313
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:16 PM > ep 405 done. total_steps=28840 | reward=1.0 | episode_steps=18 | hours=0.008 | epsilon=0.313
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:16 PM > ep 406 done. total_steps=28903 | reward=1.0 | episode_steps=63 | hours=0.008 | epsilon=0.312
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 18.33, count = 3
2025/07/28 11:30:16 PM > ep 407 done. total_steps=28921 | reward=1.0 | episode_steps=18 | hours=0.008 | epsilon=0.312
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:16 PM > ep 408 done. total_steps=28940 | reward=1.0 | episode_steps=19 | hours=0.008 | epsilon=0.312
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:16 PM > ep 409 done. total_steps=28960 | reward=1.0 | episode_steps=20 | hours=0.008 | epsilon=0.312
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 2.33, count = 3
2025/07/28 11:30:16 PM > ep 410 done. total_steps=28967 | reward=1.0 | episode_steps=7 | hours=0.008 | epsilon=0.311
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.00, count = 1
2025/07/28 11:30:16 PM > ep 411 done. total_steps=29106 | reward=1.0 | episode_steps=139 | hours=0.008 | epsilon=0.310
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 12.20, count = 10
2025/07/28 11:30:16 PM > ep 412 done. total_steps=29123 | reward=1.0 | episode_steps=17 | hours=0.008 | epsilon=0.310
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 6.00, count = 1
2025/07/28 11:30:16 PM > ep 413 done. total_steps=29132 | reward=1.0 | episode_steps=9 | hours=0.008 | epsilon=0.310
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:16 PM > ep 414 done. total_steps=29149 | reward=1.0 | episode_steps=17 | hours=0.008 | epsilon=0.310
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:16 PM > ep 415 done. total_steps=29159 | reward=1.0 | episode_steps=10 | hours=0.008 | epsilon=0.309
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:16 PM > ep 416 done. total_steps=29180 | reward=1.0 | episode_steps=21 | hours=0.008 | epsilon=0.309
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 3.50, count = 2
2025/07/28 11:30:16 PM > ep 417 done. total_steps=29200 | reward=1.0 | episode_steps=20 | hours=0.008 | epsilon=0.309
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 8.00, count = 1
2025/07/28 11:30:16 PM > ep 418 done. total_steps=29209 | reward=1.0 | episode_steps=9 | hours=0.008 | epsilon=0.309
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:16 PM > ep 419 done. total_steps=29233 | reward=1.0 | episode_steps=24 | hours=0.008 | epsilon=0.309
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:16 PM > ep 420 done. total_steps=29241 | reward=1.0 | episode_steps=8 | hours=0.008 | epsilon=0.309
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:16 PM > ep 421 done. total_steps=29269 | reward=1.0 | episode_steps=28 | hours=0.008 | epsilon=0.308
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 4.00, count = 1
2025/07/28 11:30:16 PM > ep 422 done. total_steps=29272 | reward=1.0 | episode_steps=3 | hours=0.008 | epsilon=0.308
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:16 PM > ep 423 done. total_steps=29282 | reward=1.0 | episode_steps=10 | hours=0.008 | epsilon=0.308
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:16 PM > ep 424 done. total_steps=29285 | reward=1.0 | episode_steps=3 | hours=0.008 | epsilon=0.308
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:16 PM > ep 425 done. total_steps=29309 | reward=1.0 | episode_steps=24 | hours=0.008 | epsilon=0.308
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 6.00, count = 3
2025/07/28 11:30:16 PM > ep 426 done. total_steps=29326 | reward=1.0 | episode_steps=17 | hours=0.008 | epsilon=0.308
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:16 PM > ep 427 done. total_steps=29356 | reward=1.0 | episode_steps=30 | hours=0.008 | epsilon=0.307
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:16 PM > ep 428 done. total_steps=29370 | reward=1.0 | episode_steps=14 | hours=0.008 | epsilon=0.307
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 2.00, count = 2
2025/07/28 11:30:16 PM > ep 429 done. total_steps=29393 | reward=1.0 | episode_steps=23 | hours=0.008 | epsilon=0.307
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 15.00, count = 1
2025/07/28 11:30:16 PM > ep 430 done. total_steps=29400 | reward=1.0 | episode_steps=7 | hours=0.008 | epsilon=0.307
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.00, count = 1
2025/07/28 11:30:16 PM > ep 431 done. total_steps=29415 | reward=1.0 | episode_steps=15 | hours=0.008 | epsilon=0.307
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:16 PM > ep 432 done. total_steps=29417 | reward=1.0 | episode_steps=2 | hours=0.008 | epsilon=0.307
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:16 PM > ep 433 done. total_steps=29439 | reward=1.0 | episode_steps=22 | hours=0.008 | epsilon=0.307
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:16 PM > ep 434 done. total_steps=29461 | reward=1.0 | episode_steps=22 | hours=0.008 | epsilon=0.306
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:16 PM > ep 435 done. total_steps=29480 | reward=1.0 | episode_steps=19 | hours=0.008 | epsilon=0.306
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 6.50, count = 2
2025/07/28 11:30:16 PM > ep 436 done. total_steps=29487 | reward=1.0 | episode_steps=7 | hours=0.008 | epsilon=0.306
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:16 PM > ep 437 done. total_steps=29510 | reward=1.0 | episode_steps=23 | hours=0.008 | epsilon=0.306
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 7.00, count = 1
2025/07/28 11:30:16 PM > ep 438 done. total_steps=29548 | reward=1.0 | episode_steps=38 | hours=0.008 | epsilon=0.305
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 34.00, count = 1
2025/07/28 11:30:16 PM > ep 439 done. total_steps=29552 | reward=1.0 | episode_steps=4 | hours=0.008 | epsilon=0.305
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:16 PM > ep 440 done. total_steps=29573 | reward=1.0 | episode_steps=21 | hours=0.008 | epsilon=0.305
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 10.00, count = 1
2025/07/28 11:30:16 PM > ep 441 done. total_steps=29621 | reward=1.0 | episode_steps=48 | hours=0.008 | epsilon=0.305
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 3.00, count = 1
2025/07/28 11:30:16 PM > ep 442 done. total_steps=29635 | reward=1.0 | episode_steps=14 | hours=0.008 | epsilon=0.305
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 3.67, count = 3
2025/07/28 11:30:16 PM > ep 443 done. total_steps=29654 | reward=1.0 | episode_steps=19 | hours=0.008 | epsilon=0.304
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:16 PM > ep 444 done. total_steps=29678 | reward=1.0 | episode_steps=24 | hours=0.008 | epsilon=0.304
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:16 PM > ep 445 done. total_steps=29695 | reward=1.0 | episode_steps=17 | hours=0.008 | epsilon=0.304
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 3.00, count = 2
2025/07/28 11:30:16 PM > ep 446 done. total_steps=29716 | reward=1.0 | episode_steps=21 | hours=0.008 | epsilon=0.304
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.67, count = 3
2025/07/28 11:30:16 PM > ep 447 done. total_steps=29741 | reward=1.0 | episode_steps=25 | hours=0.008 | epsilon=0.303
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 5.00, count = 4
2025/07/28 11:30:16 PM > ep 448 done. total_steps=29751 | reward=1.0 | episode_steps=10 | hours=0.008 | epsilon=0.303
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:16 PM > ep 449 done. total_steps=29777 | reward=1.0 | episode_steps=26 | hours=0.008 | epsilon=0.303
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 7.00, count = 2
2025/07/28 11:30:16 PM > ep 450 done. total_steps=29794 | reward=1.0 | episode_steps=17 | hours=0.008 | epsilon=0.303
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 2.00, count = 1
2025/07/28 11:30:16 PM > ep 451 done. total_steps=29803 | reward=1.0 | episode_steps=9 | hours=0.008 | epsilon=0.303
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:16 PM > ep 452 done. total_steps=29818 | reward=1.0 | episode_steps=15 | hours=0.008 | epsilon=0.303
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:16 PM > ep 453 done. total_steps=29837 | reward=1.0 | episode_steps=19 | hours=0.008 | epsilon=0.302
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 15.00, count = 1
2025/07/28 11:30:16 PM > ep 454 done. total_steps=29842 | reward=1.0 | episode_steps=5 | hours=0.008 | epsilon=0.302
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:16 PM > ep 455 done. total_steps=29856 | reward=1.0 | episode_steps=14 | hours=0.008 | epsilon=0.302
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 3.00, count = 1
2025/07/28 11:30:16 PM > ep 456 done. total_steps=29865 | reward=1.0 | episode_steps=9 | hours=0.008 | epsilon=0.302
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 2.00, count = 1
2025/07/28 11:30:16 PM > ep 457 done. total_steps=29872 | reward=1.0 | episode_steps=7 | hours=0.008 | epsilon=0.302
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:16 PM > ep 458 done. total_steps=29895 | reward=1.0 | episode_steps=23 | hours=0.008 | epsilon=0.302
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 4.00, count = 1
2025/07/28 11:30:16 PM > ep 459 done. total_steps=29898 | reward=1.0 | episode_steps=3 | hours=0.008 | epsilon=0.302
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:16 PM > ep 460 done. total_steps=29909 | reward=1.0 | episode_steps=11 | hours=0.008 | epsilon=0.302
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:16 PM > ep 461 done. total_steps=29931 | reward=1.0 | episode_steps=22 | hours=0.008 | epsilon=0.302
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:16 PM > ep 462 done. total_steps=29950 | reward=1.0 | episode_steps=19 | hours=0.008 | epsilon=0.301
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:16 PM > ep 463 done. total_steps=29956 | reward=1.0 | episode_steps=6 | hours=0.008 | epsilon=0.301
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:16 PM > ep 464 done. total_steps=29974 | reward=1.0 | episode_steps=18 | hours=0.008 | epsilon=0.301
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:16 PM > ep 465 done. total_steps=29978 | reward=1.0 | episode_steps=4 | hours=0.008 | epsilon=0.301
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:16 PM > ep 466 done. total_steps=30010 | reward=1.0 | episode_steps=32 | hours=0.008 | epsilon=0.301
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.00, count = 1
2025/07/28 11:30:16 PM > ep 467 done. total_steps=30033 | reward=1.0 | episode_steps=23 | hours=0.008 | epsilon=0.300
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 4.25, count = 4
2025/07/28 11:30:16 PM > ep 468 done. total_steps=30051 | reward=1.0 | episode_steps=18 | hours=0.008 | epsilon=0.300
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 15.00, count = 1
2025/07/28 11:30:16 PM > ep 469 done. total_steps=30058 | reward=1.0 | episode_steps=7 | hours=0.008 | epsilon=0.300
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:16 PM > ep 470 done. total_steps=30065 | reward=1.0 | episode_steps=7 | hours=0.008 | epsilon=0.300
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:16 PM > ep 471 done. total_steps=30091 | reward=1.0 | episode_steps=26 | hours=0.008 | epsilon=0.300
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 472 done. total_steps=30127 | reward=1.0 | episode_steps=36 | hours=0.008 | epsilon=0.300
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 3.75, count = 4
2025/07/28 11:30:17 PM > ep 473 done. total_steps=30135 | reward=1.0 | episode_steps=8 | hours=0.008 | epsilon=0.299
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 5.00, count = 1
2025/07/28 11:30:17 PM > ep 474 done. total_steps=30151 | reward=1.0 | episode_steps=16 | hours=0.008 | epsilon=0.299
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 475 done. total_steps=30171 | reward=1.0 | episode_steps=20 | hours=0.008 | epsilon=0.299
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 10.00, count = 1
2025/07/28 11:30:17 PM > ep 476 done. total_steps=30173 | reward=1.0 | episode_steps=2 | hours=0.008 | epsilon=0.299
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 477 done. total_steps=30203 | reward=1.0 | episode_steps=30 | hours=0.008 | epsilon=0.299
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 12.50, count = 2
2025/07/28 11:30:17 PM > ep 478 done. total_steps=30214 | reward=1.0 | episode_steps=11 | hours=0.008 | epsilon=0.299
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.50, count = 2
2025/07/28 11:30:17 PM > ep 479 done. total_steps=30217 | reward=1.0 | episode_steps=3 | hours=0.008 | epsilon=0.299
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 480 done. total_steps=30221 | reward=1.0 | episode_steps=4 | hours=0.008 | epsilon=0.299
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 481 done. total_steps=30236 | reward=1.0 | episode_steps=15 | hours=0.008 | epsilon=0.298
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 482 done. total_steps=30248 | reward=1.0 | episode_steps=12 | hours=0.008 | epsilon=0.298
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 483 done. total_steps=30255 | reward=1.0 | episode_steps=7 | hours=0.008 | epsilon=0.298
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 2.00, count = 1
2025/07/28 11:30:17 PM > ep 484 done. total_steps=30274 | reward=1.0 | episode_steps=19 | hours=0.008 | epsilon=0.298
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 4.25, count = 4
2025/07/28 11:30:17 PM > ep 485 done. total_steps=30293 | reward=1.0 | episode_steps=19 | hours=0.008 | epsilon=0.298
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 2.80, count = 5
2025/07/28 11:30:17 PM > ep 486 done. total_steps=30297 | reward=1.0 | episode_steps=4 | hours=0.008 | epsilon=0.298
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 487 done. total_steps=30342 | reward=1.0 | episode_steps=45 | hours=0.008 | epsilon=0.297
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 5.17, count = 6
2025/07/28 11:30:17 PM > ep 488 done. total_steps=30356 | reward=1.0 | episode_steps=14 | hours=0.008 | epsilon=0.297
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.50, count = 2
2025/07/28 11:30:17 PM > ep 489 done. total_steps=30358 | reward=1.0 | episode_steps=2 | hours=0.008 | epsilon=0.297
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 490 done. total_steps=30375 | reward=1.0 | episode_steps=17 | hours=0.008 | epsilon=0.297
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 16.00, count = 1
2025/07/28 11:30:17 PM > ep 491 done. total_steps=30400 | reward=1.0 | episode_steps=25 | hours=0.008 | epsilon=0.297
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 492 done. total_steps=30443 | reward=1.0 | episode_steps=43 | hours=0.008 | epsilon=0.296
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 6.80, count = 5
2025/07/28 11:30:17 PM > ep 493 done. total_steps=30459 | reward=1.0 | episode_steps=16 | hours=0.008 | epsilon=0.296
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 4.50, count = 2
2025/07/28 11:30:17 PM > ep 494 done. total_steps=30461 | reward=1.0 | episode_steps=2 | hours=0.008 | epsilon=0.296
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 495 done. total_steps=30468 | reward=1.0 | episode_steps=7 | hours=0.008 | epsilon=0.296
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.00, count = 1
2025/07/28 11:30:17 PM > ep 496 done. total_steps=30476 | reward=1.0 | episode_steps=8 | hours=0.008 | epsilon=0.296
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 497 done. total_steps=30500 | reward=1.0 | episode_steps=24 | hours=0.008 | epsilon=0.296
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 498 done. total_steps=30507 | reward=1.0 | episode_steps=7 | hours=0.008 | epsilon=0.296
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 499 done. total_steps=30509 | reward=1.0 | episode_steps=2 | hours=0.008 | epsilon=0.296
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 500 done. total_steps=30522 | reward=1.0 | episode_steps=13 | hours=0.008 | epsilon=0.296
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 7.00, count = 1
2025/07/28 11:30:17 PM > ep 501 done. total_steps=30536 | reward=1.0 | episode_steps=14 | hours=0.008 | epsilon=0.296
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 502 done. total_steps=30564 | reward=1.0 | episode_steps=28 | hours=0.008 | epsilon=0.295
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 503 done. total_steps=30573 | reward=1.0 | episode_steps=9 | hours=0.008 | epsilon=0.295
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 504 done. total_steps=30615 | reward=1.0 | episode_steps=42 | hours=0.009 | epsilon=0.295
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.50, count = 2
2025/07/28 11:30:17 PM > ep 505 done. total_steps=30639 | reward=1.0 | episode_steps=24 | hours=0.009 | epsilon=0.295
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 506 done. total_steps=30648 | reward=1.0 | episode_steps=9 | hours=0.009 | epsilon=0.294
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 507 done. total_steps=30652 | reward=1.0 | episode_steps=4 | hours=0.009 | epsilon=0.294
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 508 done. total_steps=30676 | reward=1.0 | episode_steps=24 | hours=0.009 | epsilon=0.294
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 13.00, count = 1
2025/07/28 11:30:17 PM > ep 509 done. total_steps=30690 | reward=1.0 | episode_steps=14 | hours=0.009 | epsilon=0.294
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 510 done. total_steps=30696 | reward=1.0 | episode_steps=6 | hours=0.009 | epsilon=0.294
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 511 done. total_steps=30706 | reward=1.0 | episode_steps=10 | hours=0.009 | epsilon=0.294
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 512 done. total_steps=30732 | reward=1.0 | episode_steps=26 | hours=0.009 | epsilon=0.294
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 10.00, count = 1
2025/07/28 11:30:17 PM > ep 513 done. total_steps=30740 | reward=1.0 | episode_steps=8 | hours=0.009 | epsilon=0.294
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 514 done. total_steps=30751 | reward=1.0 | episode_steps=11 | hours=0.009 | epsilon=0.293
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 515 done. total_steps=30774 | reward=1.0 | episode_steps=23 | hours=0.009 | epsilon=0.293
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 516 done. total_steps=30790 | reward=1.0 | episode_steps=16 | hours=0.009 | epsilon=0.293
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 517 done. total_steps=30802 | reward=1.0 | episode_steps=12 | hours=0.009 | epsilon=0.293
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 518 done. total_steps=30811 | reward=1.0 | episode_steps=9 | hours=0.009 | epsilon=0.293
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 519 done. total_steps=30844 | reward=1.0 | episode_steps=33 | hours=0.009 | epsilon=0.293
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 520 done. total_steps=30867 | reward=1.0 | episode_steps=23 | hours=0.009 | epsilon=0.292
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 2.50, count = 2
2025/07/28 11:30:17 PM > ep 521 done. total_steps=30870 | reward=1.0 | episode_steps=3 | hours=0.009 | epsilon=0.292
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 522 done. total_steps=30881 | reward=1.0 | episode_steps=11 | hours=0.009 | epsilon=0.292
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 523 done. total_steps=30897 | reward=1.0 | episode_steps=16 | hours=0.009 | epsilon=0.292
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 3.00, count = 1
2025/07/28 11:30:17 PM > ep 524 done. total_steps=30905 | reward=1.0 | episode_steps=8 | hours=0.009 | epsilon=0.292
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 525 done. total_steps=30916 | reward=1.0 | episode_steps=11 | hours=0.009 | epsilon=0.292
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 526 done. total_steps=30922 | reward=1.0 | episode_steps=6 | hours=0.009 | epsilon=0.292
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.00, count = 3
2025/07/28 11:30:17 PM > ep 527 done. total_steps=30930 | reward=1.0 | episode_steps=8 | hours=0.009 | epsilon=0.292
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 528 done. total_steps=30938 | reward=1.0 | episode_steps=8 | hours=0.009 | epsilon=0.292
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 529 done. total_steps=30973 | reward=1.0 | episode_steps=35 | hours=0.009 | epsilon=0.291
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 7.75, count = 4
2025/07/28 11:30:17 PM > ep 530 done. total_steps=30981 | reward=1.0 | episode_steps=8 | hours=0.009 | epsilon=0.291
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 531 done. total_steps=31006 | reward=1.0 | episode_steps=25 | hours=0.009 | epsilon=0.291
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 532 done. total_steps=31011 | reward=1.0 | episode_steps=5 | hours=0.009 | epsilon=0.291
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 533 done. total_steps=31019 | reward=1.0 | episode_steps=8 | hours=0.009 | epsilon=0.291
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 534 done. total_steps=31028 | reward=1.0 | episode_steps=9 | hours=0.009 | epsilon=0.291
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 535 done. total_steps=31038 | reward=1.0 | episode_steps=10 | hours=0.009 | epsilon=0.291
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 536 done. total_steps=31044 | reward=1.0 | episode_steps=6 | hours=0.009 | epsilon=0.291
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 537 done. total_steps=31068 | reward=1.0 | episode_steps=24 | hours=0.009 | epsilon=0.290
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 538 done. total_steps=31086 | reward=1.0 | episode_steps=18 | hours=0.009 | epsilon=0.290
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 539 done. total_steps=31105 | reward=1.0 | episode_steps=19 | hours=0.009 | epsilon=0.290
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 540 done. total_steps=31113 | reward=1.0 | episode_steps=8 | hours=0.009 | epsilon=0.290
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 541 done. total_steps=31115 | reward=1.0 | episode_steps=2 | hours=0.009 | epsilon=0.290
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 542 done. total_steps=31125 | reward=1.0 | episode_steps=10 | hours=0.009 | epsilon=0.290
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 543 done. total_steps=31129 | reward=1.0 | episode_steps=4 | hours=0.009 | epsilon=0.290
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 544 done. total_steps=31141 | reward=1.0 | episode_steps=12 | hours=0.009 | epsilon=0.290
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 545 done. total_steps=31158 | reward=1.0 | episode_steps=17 | hours=0.009 | epsilon=0.290
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 3.00, count = 2
2025/07/28 11:30:17 PM > ep 546 done. total_steps=31177 | reward=1.0 | episode_steps=19 | hours=0.009 | epsilon=0.289
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 547 done. total_steps=31196 | reward=1.0 | episode_steps=19 | hours=0.009 | epsilon=0.289
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 13.00, count = 1
2025/07/28 11:30:17 PM > ep 548 done. total_steps=31234 | reward=1.0 | episode_steps=38 | hours=0.009 | epsilon=0.289
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 8.00, count = 1
2025/07/28 11:30:17 PM > ep 549 done. total_steps=31264 | reward=1.0 | episode_steps=30 | hours=0.009 | epsilon=0.289
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 550 done. total_steps=31307 | reward=1.0 | episode_steps=43 | hours=0.009 | epsilon=0.288
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 9.50, count = 2
2025/07/28 11:30:17 PM > ep 551 done. total_steps=31313 | reward=1.0 | episode_steps=6 | hours=0.009 | epsilon=0.288
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 552 done. total_steps=31329 | reward=1.0 | episode_steps=16 | hours=0.009 | epsilon=0.288
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 553 done. total_steps=31346 | reward=1.0 | episode_steps=17 | hours=0.009 | epsilon=0.288
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 554 done. total_steps=31359 | reward=1.0 | episode_steps=13 | hours=0.009 | epsilon=0.288
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 555 done. total_steps=31376 | reward=1.0 | episode_steps=17 | hours=0.009 | epsilon=0.287
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 556 done. total_steps=31399 | reward=1.0 | episode_steps=23 | hours=0.009 | epsilon=0.287
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 557 done. total_steps=31403 | reward=1.0 | episode_steps=4 | hours=0.009 | epsilon=0.287
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 558 done. total_steps=31409 | reward=1.0 | episode_steps=6 | hours=0.009 | epsilon=0.287
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.00, count = 1
2025/07/28 11:30:17 PM > ep 559 done. total_steps=31428 | reward=1.0 | episode_steps=19 | hours=0.009 | epsilon=0.287
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 560 done. total_steps=31433 | reward=1.0 | episode_steps=5 | hours=0.009 | epsilon=0.287
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 561 done. total_steps=31436 | reward=1.0 | episode_steps=3 | hours=0.009 | epsilon=0.287
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:17 PM > ep 562 done. total_steps=31446 | reward=1.0 | episode_steps=10 | hours=0.009 | epsilon=0.287
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:18 PM > ep 563 done. total_steps=31448 | reward=1.0 | episode_steps=2 | hours=0.009 | epsilon=0.287
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:18 PM > ep 564 done. total_steps=31522 | reward=1.0 | episode_steps=74 | hours=0.009 | epsilon=0.286
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 26.00, count = 1
2025/07/28 11:30:18 PM > ep 565 done. total_steps=31541 | reward=1.0 | episode_steps=19 | hours=0.009 | epsilon=0.286
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 16.00, count = 1
2025/07/28 11:30:18 PM > ep 566 done. total_steps=31552 | reward=1.0 | episode_steps=11 | hours=0.009 | epsilon=0.286
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:18 PM > ep 567 done. total_steps=31564 | reward=1.0 | episode_steps=12 | hours=0.009 | epsilon=0.286
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:18 PM > ep 568 done. total_steps=31590 | reward=1.0 | episode_steps=26 | hours=0.009 | epsilon=0.285
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:18 PM > ep 569 done. total_steps=31592 | reward=1.0 | episode_steps=2 | hours=0.009 | epsilon=0.285
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:18 PM > ep 570 done. total_steps=31598 | reward=1.0 | episode_steps=6 | hours=0.009 | epsilon=0.285
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:18 PM > ep 571 done. total_steps=31628 | reward=1.0 | episode_steps=30 | hours=0.009 | epsilon=0.285
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 3.33, count = 6
2025/07/28 11:30:18 PM > ep 572 done. total_steps=31645 | reward=1.0 | episode_steps=17 | hours=0.009 | epsilon=0.285
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 4.00, count = 1
2025/07/28 11:30:18 PM > ep 573 done. total_steps=31676 | reward=1.0 | episode_steps=31 | hours=0.009 | epsilon=0.285
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:18 PM > ep 574 done. total_steps=31688 | reward=1.0 | episode_steps=12 | hours=0.009 | epsilon=0.285
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:18 PM > ep 575 done. total_steps=31704 | reward=1.0 | episode_steps=16 | hours=0.009 | epsilon=0.284
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 6.50, count = 2
2025/07/28 11:30:18 PM > ep 576 done. total_steps=31715 | reward=1.0 | episode_steps=11 | hours=0.009 | epsilon=0.284
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:18 PM > ep 577 done. total_steps=31727 | reward=1.0 | episode_steps=12 | hours=0.009 | epsilon=0.284
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:18 PM > ep 578 done. total_steps=31728 | reward=1.0 | episode_steps=1 | hours=0.009 | epsilon=0.284
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:18 PM > ep 579 done. total_steps=31731 | reward=1.0 | episode_steps=3 | hours=0.009 | epsilon=0.284
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:18 PM > ep 580 done. total_steps=31755 | reward=1.0 | episode_steps=24 | hours=0.009 | epsilon=0.284
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:18 PM > ep 581 done. total_steps=31759 | reward=1.0 | episode_steps=4 | hours=0.009 | epsilon=0.284
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:18 PM > ep 582 done. total_steps=31771 | reward=1.0 | episode_steps=12 | hours=0.009 | epsilon=0.284
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:18 PM > ep 583 done. total_steps=31780 | reward=1.0 | episode_steps=9 | hours=0.009 | epsilon=0.284
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:18 PM > ep 584 done. total_steps=31785 | reward=1.0 | episode_steps=5 | hours=0.009 | epsilon=0.284
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.00, count = 2
2025/07/28 11:30:18 PM > ep 585 done. total_steps=31795 | reward=1.0 | episode_steps=10 | hours=0.009 | epsilon=0.284
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:18 PM > ep 586 done. total_steps=31815 | reward=1.0 | episode_steps=20 | hours=0.009 | epsilon=0.283
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:18 PM > ep 587 done. total_steps=31831 | reward=1.0 | episode_steps=16 | hours=0.009 | epsilon=0.283
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:18 PM > ep 588 done. total_steps=31863 | reward=1.0 | episode_steps=32 | hours=0.009 | epsilon=0.283
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.40, count = 5
2025/07/28 11:30:18 PM > ep 589 done. total_steps=31867 | reward=1.0 | episode_steps=4 | hours=0.009 | epsilon=0.283
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:18 PM > ep 590 done. total_steps=31892 | reward=1.0 | episode_steps=25 | hours=0.009 | epsilon=0.283
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:18 PM > ep 591 done. total_steps=31901 | reward=1.0 | episode_steps=9 | hours=0.009 | epsilon=0.283
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:18 PM > ep 592 done. total_steps=31927 | reward=1.0 | episode_steps=26 | hours=0.009 | epsilon=0.282
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 2.00, count = 1
2025/07/28 11:30:18 PM > ep 593 done. total_steps=31934 | reward=1.0 | episode_steps=7 | hours=0.009 | epsilon=0.282
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:18 PM > ep 594 done. total_steps=31942 | reward=1.0 | episode_steps=8 | hours=0.009 | epsilon=0.282
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:18 PM > ep 595 done. total_steps=31943 | reward=1.0 | episode_steps=1 | hours=0.009 | epsilon=0.282
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:18 PM > ep 596 done. total_steps=31978 | reward=1.0 | episode_steps=35 | hours=0.009 | epsilon=0.282
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 7.50, count = 2
2025/07/28 11:30:18 PM > ep 597 done. total_steps=31985 | reward=1.0 | episode_steps=7 | hours=0.009 | epsilon=0.282
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:18 PM > ep 598 done. total_steps=31991 | reward=1.0 | episode_steps=6 | hours=0.009 | epsilon=0.282
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:18 PM > ep 599 done. total_steps=32022 | reward=1.0 | episode_steps=31 | hours=0.009 | epsilon=0.282
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:18 PM > ep 600 done. total_steps=32027 | reward=1.0 | episode_steps=5 | hours=0.009 | epsilon=0.281
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:18 PM > ep 601 done. total_steps=32047 | reward=1.0 | episode_steps=20 | hours=0.009 | epsilon=0.281
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:18 PM > ep 602 done. total_steps=32077 | reward=1.0 | episode_steps=30 | hours=0.009 | epsilon=0.281
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:18 PM > ep 603 done. total_steps=32091 | reward=1.0 | episode_steps=14 | hours=0.009 | epsilon=0.281
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:18 PM > ep 604 done. total_steps=32099 | reward=1.0 | episode_steps=8 | hours=0.009 | epsilon=0.281
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:18 PM > ep 605 done. total_steps=32113 | reward=1.0 | episode_steps=14 | hours=0.009 | epsilon=0.281
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 4.00, count = 1
2025/07/28 11:30:18 PM > ep 606 done. total_steps=32131 | reward=1.0 | episode_steps=18 | hours=0.009 | epsilon=0.281
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 3.40, count = 5
2025/07/28 11:30:18 PM > ep 607 done. total_steps=32143 | reward=1.0 | episode_steps=12 | hours=0.009 | epsilon=0.280
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:18 PM > ep 608 done. total_steps=32148 | reward=1.0 | episode_steps=5 | hours=0.009 | epsilon=0.280
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:18 PM > ep 609 done. total_steps=32169 | reward=1.0 | episode_steps=21 | hours=0.009 | epsilon=0.280
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:18 PM > ep 610 done. total_steps=32180 | reward=1.0 | episode_steps=11 | hours=0.009 | epsilon=0.280
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:18 PM > ep 611 done. total_steps=32185 | reward=1.0 | episode_steps=5 | hours=0.009 | epsilon=0.280
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:18 PM > ep 612 done. total_steps=32191 | reward=1.0 | episode_steps=6 | hours=0.009 | epsilon=0.280
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:18 PM > ep 613 done. total_steps=32198 | reward=1.0 | episode_steps=7 | hours=0.009 | epsilon=0.280
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:18 PM > ep 614 done. total_steps=32225 | reward=1.0 | episode_steps=27 | hours=0.009 | epsilon=0.280
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.57, count = 7
2025/07/28 11:30:18 PM > ep 615 done. total_steps=32244 | reward=1.0 | episode_steps=19 | hours=0.009 | epsilon=0.280
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:18 PM > ep 616 done. total_steps=32246 | reward=1.0 | episode_steps=2 | hours=0.009 | epsilon=0.279
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.00, count = 1
2025/07/28 11:30:18 PM > ep 617 done. total_steps=32266 | reward=1.0 | episode_steps=20 | hours=0.009 | epsilon=0.279
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 2.00, count = 1
2025/07/28 11:30:18 PM > ep 618 done. total_steps=32287 | reward=1.0 | episode_steps=21 | hours=0.009 | epsilon=0.279
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 5.00, count = 2
2025/07/28 11:30:18 PM > ep 619 done. total_steps=32308 | reward=1.0 | episode_steps=21 | hours=0.009 | epsilon=0.279
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:18 PM > ep 620 done. total_steps=32345 | reward=1.0 | episode_steps=37 | hours=0.009 | epsilon=0.279
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 34.00, count = 1
2025/07/28 11:30:18 PM > ep 621 done. total_steps=32354 | reward=1.0 | episode_steps=9 | hours=0.009 | epsilon=0.279
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 2.00, count = 2
2025/07/28 11:30:18 PM > ep 622 done. total_steps=32378 | reward=1.0 | episode_steps=24 | hours=0.009 | epsilon=0.278
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:18 PM > ep 623 done. total_steps=32387 | reward=1.0 | episode_steps=9 | hours=0.009 | epsilon=0.278
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:18 PM > ep 624 done. total_steps=32391 | reward=1.0 | episode_steps=4 | hours=0.009 | epsilon=0.278
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:18 PM > ep 625 done. total_steps=32422 | reward=1.0 | episode_steps=31 | hours=0.009 | epsilon=0.278
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 11.50, count = 2
2025/07/28 11:30:18 PM > ep 626 done. total_steps=32442 | reward=1.0 | episode_steps=20 | hours=0.009 | epsilon=0.278
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:18 PM > ep 627 done. total_steps=32463 | reward=1.0 | episode_steps=21 | hours=0.009 | epsilon=0.278
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:18 PM > ep 628 done. total_steps=32503 | reward=1.0 | episode_steps=40 | hours=0.009 | epsilon=0.277
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 22.00, count = 1
2025/07/28 11:30:18 PM > ep 629 done. total_steps=32507 | reward=1.0 | episode_steps=4 | hours=0.009 | epsilon=0.277
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:18 PM > ep 630 done. total_steps=32508 | reward=1.0 | episode_steps=1 | hours=0.009 | epsilon=0.277
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:18 PM > ep 631 done. total_steps=32537 | reward=1.0 | episode_steps=29 | hours=0.009 | epsilon=0.277
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:18 PM > ep 632 done. total_steps=32557 | reward=1.0 | episode_steps=20 | hours=0.009 | epsilon=0.277
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.00, count = 1
2025/07/28 11:30:18 PM > ep 633 done. total_steps=32577 | reward=1.0 | episode_steps=20 | hours=0.009 | epsilon=0.277
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 2.50, count = 2
2025/07/28 11:30:18 PM > ep 634 done. total_steps=32587 | reward=1.0 | episode_steps=10 | hours=0.009 | epsilon=0.276
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.20, count = 5
2025/07/28 11:30:18 PM > ep 635 done. total_steps=32603 | reward=1.0 | episode_steps=16 | hours=0.009 | epsilon=0.276
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 3.00, count = 5
2025/07/28 11:30:18 PM > ep 636 done. total_steps=32618 | reward=1.0 | episode_steps=15 | hours=0.009 | epsilon=0.276
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:18 PM > ep 637 done. total_steps=32634 | reward=1.0 | episode_steps=16 | hours=0.009 | epsilon=0.276
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 11.00, count = 1
2025/07/28 11:30:18 PM > ep 638 done. total_steps=32645 | reward=1.0 | episode_steps=11 | hours=0.009 | epsilon=0.276
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:18 PM > ep 639 done. total_steps=32676 | reward=1.0 | episode_steps=31 | hours=0.009 | epsilon=0.276
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 5.75, count = 4
2025/07/28 11:30:18 PM > ep 640 done. total_steps=32708 | reward=1.0 | episode_steps=32 | hours=0.009 | epsilon=0.275
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.50, count = 4
2025/07/28 11:30:18 PM > ep 641 done. total_steps=32725 | reward=1.0 | episode_steps=17 | hours=0.009 | epsilon=0.275
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 13.00, count = 1
2025/07/28 11:30:18 PM > ep 642 done. total_steps=32731 | reward=1.0 | episode_steps=6 | hours=0.009 | epsilon=0.275
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 4.00, count = 1
2025/07/28 11:30:18 PM > ep 643 done. total_steps=32737 | reward=1.0 | episode_steps=6 | hours=0.009 | epsilon=0.275
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:18 PM > ep 644 done. total_steps=32777 | reward=1.0 | episode_steps=40 | hours=0.009 | epsilon=0.275
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 29.00, count = 1
2025/07/28 11:30:18 PM > ep 645 done. total_steps=32796 | reward=1.0 | episode_steps=19 | hours=0.009 | epsilon=0.275
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 2.67, count = 6
2025/07/28 11:30:19 PM > ep 646 done. total_steps=32813 | reward=1.0 | episode_steps=17 | hours=0.009 | epsilon=0.274
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:19 PM > ep 647 done. total_steps=32843 | reward=1.0 | episode_steps=30 | hours=0.009 | epsilon=0.274
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:19 PM > ep 648 done. total_steps=32846 | reward=1.0 | episode_steps=3 | hours=0.009 | epsilon=0.274
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:19 PM > ep 649 done. total_steps=32850 | reward=1.0 | episode_steps=4 | hours=0.009 | epsilon=0.274
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:19 PM > ep 650 done. total_steps=32884 | reward=1.0 | episode_steps=34 | hours=0.009 | epsilon=0.274
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 22.00, count = 1
2025/07/28 11:30:19 PM > ep 651 done. total_steps=32894 | reward=1.0 | episode_steps=10 | hours=0.009 | epsilon=0.274
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:19 PM > ep 652 done. total_steps=32920 | reward=1.0 | episode_steps=26 | hours=0.009 | epsilon=0.274
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 8.00, count = 1
2025/07/28 11:30:19 PM > ep 653 done. total_steps=32923 | reward=1.0 | episode_steps=3 | hours=0.009 | epsilon=0.274
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:19 PM > ep 654 done. total_steps=32936 | reward=1.0 | episode_steps=13 | hours=0.009 | epsilon=0.273
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 5.00, count = 2
2025/07/28 11:30:19 PM > ep 655 done. total_steps=32965 | reward=1.0 | episode_steps=29 | hours=0.009 | epsilon=0.273
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:19 PM > ep 656 done. total_steps=32990 | reward=1.0 | episode_steps=25 | hours=0.009 | epsilon=0.273
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 18.00, count = 1
2025/07/28 11:30:19 PM > ep 657 done. total_steps=32996 | reward=1.0 | episode_steps=6 | hours=0.009 | epsilon=0.273
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 4.00, count = 1
2025/07/28 11:30:19 PM > ep 658 done. total_steps=33013 | reward=1.0 | episode_steps=17 | hours=0.009 | epsilon=0.273
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 11.00, count = 1
2025/07/28 11:30:19 PM > ep 659 done. total_steps=33026 | reward=1.0 | episode_steps=13 | hours=0.009 | epsilon=0.273
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:19 PM > ep 660 done. total_steps=33038 | reward=1.0 | episode_steps=12 | hours=0.009 | epsilon=0.273
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:19 PM > ep 661 done. total_steps=33046 | reward=1.0 | episode_steps=8 | hours=0.009 | epsilon=0.272
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:19 PM > ep 662 done. total_steps=33055 | reward=1.0 | episode_steps=9 | hours=0.009 | epsilon=0.272
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:19 PM > ep 663 done. total_steps=33077 | reward=1.0 | episode_steps=22 | hours=0.009 | epsilon=0.272
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 20.00, count = 1
2025/07/28 11:30:19 PM > ep 664 done. total_steps=33082 | reward=1.0 | episode_steps=5 | hours=0.009 | epsilon=0.272
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:19 PM > ep 665 done. total_steps=33112 | reward=1.0 | episode_steps=30 | hours=0.009 | epsilon=0.272
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:19 PM > ep 666 done. total_steps=33125 | reward=1.0 | episode_steps=13 | hours=0.009 | epsilon=0.272
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 4.00, count = 2
2025/07/28 11:30:19 PM > ep 667 done. total_steps=33130 | reward=1.0 | episode_steps=5 | hours=0.009 | epsilon=0.272
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:19 PM > ep 668 done. total_steps=33138 | reward=1.0 | episode_steps=8 | hours=0.009 | epsilon=0.272
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:19 PM > ep 669 done. total_steps=33154 | reward=1.0 | episode_steps=16 | hours=0.009 | epsilon=0.272
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:19 PM > ep 670 done. total_steps=33170 | reward=1.0 | episode_steps=16 | hours=0.009 | epsilon=0.271
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:19 PM > ep 671 done. total_steps=33190 | reward=1.0 | episode_steps=20 | hours=0.009 | epsilon=0.271
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:19 PM > ep 672 done. total_steps=33216 | reward=1.0 | episode_steps=26 | hours=0.009 | epsilon=0.271
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 7.00, count = 1
2025/07/28 11:30:19 PM > ep 673 done. total_steps=33241 | reward=1.0 | episode_steps=25 | hours=0.009 | epsilon=0.271
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 20.00, count = 1
2025/07/28 11:30:19 PM > ep 674 done. total_steps=33256 | reward=1.0 | episode_steps=15 | hours=0.009 | epsilon=0.271
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:19 PM > ep 675 done. total_steps=33268 | reward=1.0 | episode_steps=12 | hours=0.009 | epsilon=0.271
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 2.67, count = 3
2025/07/28 11:30:19 PM > ep 676 done. total_steps=33277 | reward=1.0 | episode_steps=9 | hours=0.009 | epsilon=0.270
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:19 PM > ep 677 done. total_steps=33293 | reward=1.0 | episode_steps=16 | hours=0.009 | epsilon=0.270
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:19 PM > ep 678 done. total_steps=33305 | reward=1.0 | episode_steps=12 | hours=0.009 | epsilon=0.270
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:19 PM > ep 679 done. total_steps=33342 | reward=1.0 | episode_steps=37 | hours=0.009 | epsilon=0.270
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 11.67, count = 3
2025/07/28 11:30:19 PM > ep 680 done. total_steps=33346 | reward=1.0 | episode_steps=4 | hours=0.009 | epsilon=0.270
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:19 PM > ep 681 done. total_steps=33366 | reward=1.0 | episode_steps=20 | hours=0.009 | epsilon=0.270
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 3.50, count = 2
2025/07/28 11:30:19 PM > ep 682 done. total_steps=33383 | reward=1.0 | episode_steps=17 | hours=0.009 | epsilon=0.270
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:19 PM > ep 683 done. total_steps=33393 | reward=1.0 | episode_steps=10 | hours=0.009 | epsilon=0.269
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 2.00, count = 4
2025/07/28 11:30:19 PM > ep 684 done. total_steps=33418 | reward=1.0 | episode_steps=25 | hours=0.009 | epsilon=0.269
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 21.00, count = 1
2025/07/28 11:30:19 PM > ep 685 done. total_steps=33427 | reward=1.0 | episode_steps=9 | hours=0.009 | epsilon=0.269
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:19 PM > ep 686 done. total_steps=33434 | reward=1.0 | episode_steps=7 | hours=0.009 | epsilon=0.269
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:19 PM > ep 687 done. total_steps=33438 | reward=1.0 | episode_steps=4 | hours=0.009 | epsilon=0.269
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:19 PM > ep 688 done. total_steps=33458 | reward=1.0 | episode_steps=20 | hours=0.009 | epsilon=0.269
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 13.00, count = 1
2025/07/28 11:30:19 PM > ep 689 done. total_steps=33472 | reward=1.0 | episode_steps=14 | hours=0.009 | epsilon=0.269
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 4.00, count = 3
2025/07/28 11:30:19 PM > ep 690 done. total_steps=33514 | reward=1.0 | episode_steps=42 | hours=0.009 | epsilon=0.268
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 18.00, count = 1
2025/07/28 11:30:19 PM > ep 691 done. total_steps=33548 | reward=1.0 | episode_steps=34 | hours=0.009 | epsilon=0.268
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:19 PM > ep 692 done. total_steps=33554 | reward=1.0 | episode_steps=6 | hours=0.009 | epsilon=0.268
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:19 PM > ep 693 done. total_steps=33556 | reward=1.0 | episode_steps=2 | hours=0.009 | epsilon=0.268
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:19 PM > ep 694 done. total_steps=33560 | reward=1.0 | episode_steps=4 | hours=0.009 | epsilon=0.268
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 2.00, count = 1
2025/07/28 11:30:19 PM > ep 695 done. total_steps=33570 | reward=1.0 | episode_steps=10 | hours=0.009 | epsilon=0.268
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:19 PM > ep 696 done. total_steps=33590 | reward=1.0 | episode_steps=20 | hours=0.009 | epsilon=0.268
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:19 PM > ep 697 done. total_steps=33607 | reward=1.0 | episode_steps=17 | hours=0.009 | epsilon=0.268
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 6.50, count = 2
2025/07/28 11:30:19 PM > ep 698 done. total_steps=33610 | reward=1.0 | episode_steps=3 | hours=0.009 | epsilon=0.268
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:19 PM > ep 699 done. total_steps=33645 | reward=1.0 | episode_steps=35 | hours=0.009 | epsilon=0.267
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:19 PM > ep 700 done. total_steps=33664 | reward=1.0 | episode_steps=19 | hours=0.009 | epsilon=0.267
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:19 PM > ep 701 done. total_steps=33672 | reward=1.0 | episode_steps=8 | hours=0.009 | epsilon=0.267
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:19 PM > ep 702 done. total_steps=33688 | reward=1.0 | episode_steps=16 | hours=0.009 | epsilon=0.267
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:19 PM > ep 703 done. total_steps=33701 | reward=1.0 | episode_steps=13 | hours=0.009 | epsilon=0.267
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:19 PM > ep 704 done. total_steps=33703 | reward=1.0 | episode_steps=2 | hours=0.009 | epsilon=0.267
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:19 PM > ep 705 done. total_steps=33764 | reward=1.0 | episode_steps=61 | hours=0.009 | epsilon=0.266
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 29.00, count = 2
2025/07/28 11:30:19 PM > ep 706 done. total_steps=33770 | reward=1.0 | episode_steps=6 | hours=0.009 | epsilon=0.266
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:19 PM > ep 707 done. total_steps=33790 | reward=1.0 | episode_steps=20 | hours=0.009 | epsilon=0.266
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 13.00, count = 1
2025/07/28 11:30:19 PM > ep 708 done. total_steps=33830 | reward=1.0 | episode_steps=40 | hours=0.009 | epsilon=0.266
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 25.00, count = 1
2025/07/28 11:30:19 PM > ep 709 done. total_steps=33835 | reward=1.0 | episode_steps=5 | hours=0.009 | epsilon=0.266
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:19 PM > ep 710 done. total_steps=33842 | reward=1.0 | episode_steps=7 | hours=0.009 | epsilon=0.266
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:19 PM > ep 711 done. total_steps=33847 | reward=1.0 | episode_steps=5 | hours=0.009 | epsilon=0.266
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:19 PM > ep 712 done. total_steps=33867 | reward=1.0 | episode_steps=20 | hours=0.009 | epsilon=0.266
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.86, count = 7
2025/07/28 11:30:19 PM > ep 713 done. total_steps=33927 | reward=1.0 | episode_steps=60 | hours=0.009 | epsilon=0.265
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 32.00, count = 1
2025/07/28 11:30:19 PM > ep 714 done. total_steps=33929 | reward=1.0 | episode_steps=2 | hours=0.009 | epsilon=0.265
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:19 PM > ep 715 done. total_steps=33942 | reward=1.0 | episode_steps=13 | hours=0.009 | epsilon=0.265
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:19 PM > ep 716 done. total_steps=33968 | reward=1.0 | episode_steps=26 | hours=0.009 | epsilon=0.265
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 4.17, count = 6
2025/07/28 11:30:19 PM > ep 717 done. total_steps=33991 | reward=1.0 | episode_steps=23 | hours=0.009 | epsilon=0.264
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:19 PM > ep 718 done. total_steps=33998 | reward=1.0 | episode_steps=7 | hours=0.009 | epsilon=0.264
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:19 PM > ep 719 done. total_steps=34001 | reward=1.0 | episode_steps=3 | hours=0.009 | epsilon=0.264
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:19 PM > ep 720 done. total_steps=34028 | reward=1.0 | episode_steps=27 | hours=0.009 | epsilon=0.264
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:19 PM > ep 721 done. total_steps=34080 | reward=1.0 | episode_steps=52 | hours=0.009 | epsilon=0.264
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:19 PM > ep 722 done. total_steps=34116 | reward=1.0 | episode_steps=36 | hours=0.009 | epsilon=0.263
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 32.00, count = 1
2025/07/28 11:30:20 PM > ep 723 done. total_steps=34145 | reward=1.0 | episode_steps=29 | hours=0.009 | epsilon=0.263
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 14.00, count = 2
2025/07/28 11:30:20 PM > ep 724 done. total_steps=34148 | reward=1.0 | episode_steps=3 | hours=0.009 | epsilon=0.263
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:20 PM > ep 725 done. total_steps=34151 | reward=1.0 | episode_steps=3 | hours=0.009 | epsilon=0.263
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:20 PM > ep 726 done. total_steps=34163 | reward=1.0 | episode_steps=12 | hours=0.009 | epsilon=0.263
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:20 PM > ep 727 done. total_steps=34173 | reward=1.0 | episode_steps=10 | hours=0.009 | epsilon=0.263
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:20 PM > ep 728 done. total_steps=34198 | reward=1.0 | episode_steps=25 | hours=0.009 | epsilon=0.263
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:20 PM > ep 729 done. total_steps=34224 | reward=1.0 | episode_steps=26 | hours=0.010 | epsilon=0.263
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 25.00, count = 1
2025/07/28 11:30:20 PM > ep 730 done. total_steps=34241 | reward=1.0 | episode_steps=17 | hours=0.010 | epsilon=0.262
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:20 PM > ep 731 done. total_steps=34243 | reward=1.0 | episode_steps=2 | hours=0.010 | epsilon=0.262
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:20 PM > ep 732 done. total_steps=34271 | reward=1.0 | episode_steps=28 | hours=0.010 | epsilon=0.262
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 16.00, count = 1
2025/07/28 11:30:20 PM > ep 733 done. total_steps=34291 | reward=1.0 | episode_steps=20 | hours=0.010 | epsilon=0.262
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:20 PM > ep 734 done. total_steps=34303 | reward=1.0 | episode_steps=12 | hours=0.010 | epsilon=0.262
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:20 PM > ep 735 done. total_steps=34329 | reward=1.0 | episode_steps=26 | hours=0.010 | epsilon=0.262
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:20 PM > ep 736 done. total_steps=34340 | reward=1.0 | episode_steps=11 | hours=0.010 | epsilon=0.262
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:20 PM > ep 737 done. total_steps=34358 | reward=1.0 | episode_steps=18 | hours=0.010 | epsilon=0.262
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:20 PM > ep 738 done. total_steps=34378 | reward=1.0 | episode_steps=20 | hours=0.010 | epsilon=0.261
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:20 PM > ep 739 done. total_steps=34389 | reward=1.0 | episode_steps=11 | hours=0.010 | epsilon=0.261
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 2.50, count = 2
2025/07/28 11:30:20 PM > ep 740 done. total_steps=34395 | reward=1.0 | episode_steps=6 | hours=0.010 | epsilon=0.261
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:20 PM > ep 741 done. total_steps=34417 | reward=1.0 | episode_steps=22 | hours=0.010 | epsilon=0.261
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 11.00, count = 1
2025/07/28 11:30:20 PM > ep 742 done. total_steps=34445 | reward=1.0 | episode_steps=28 | hours=0.010 | epsilon=0.261
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:20 PM > ep 743 done. total_steps=34461 | reward=1.0 | episode_steps=16 | hours=0.010 | epsilon=0.261
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 8.00, count = 1
2025/07/28 11:30:20 PM > ep 744 done. total_steps=34509 | reward=1.0 | episode_steps=48 | hours=0.010 | epsilon=0.260
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:20 PM > ep 745 done. total_steps=34514 | reward=1.0 | episode_steps=5 | hours=0.010 | epsilon=0.260
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 2.00, count = 2
2025/07/28 11:30:20 PM > ep 746 done. total_steps=34529 | reward=1.0 | episode_steps=15 | hours=0.010 | epsilon=0.260
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 10.00, count = 1
2025/07/28 11:30:20 PM > ep 747 done. total_steps=34534 | reward=1.0 | episode_steps=5 | hours=0.010 | epsilon=0.260
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:20 PM > ep 748 done. total_steps=34536 | reward=1.0 | episode_steps=2 | hours=0.010 | epsilon=0.260
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:20 PM > ep 749 done. total_steps=34553 | reward=1.0 | episode_steps=17 | hours=0.010 | epsilon=0.260
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:20 PM > ep 750 done. total_steps=34588 | reward=1.0 | episode_steps=35 | hours=0.010 | epsilon=0.260
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 9.00, count = 1
2025/07/28 11:30:20 PM > ep 751 done. total_steps=34621 | reward=1.0 | episode_steps=33 | hours=0.010 | epsilon=0.259
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:20 PM > ep 752 done. total_steps=34643 | reward=1.0 | episode_steps=22 | hours=0.010 | epsilon=0.259
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:20 PM > ep 753 done. total_steps=34654 | reward=1.0 | episode_steps=11 | hours=0.010 | epsilon=0.259
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 10.00, count = 1
2025/07/28 11:30:20 PM > ep 754 done. total_steps=34673 | reward=1.0 | episode_steps=19 | hours=0.010 | epsilon=0.259
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:20 PM > ep 755 done. total_steps=34694 | reward=1.0 | episode_steps=21 | hours=0.010 | epsilon=0.259
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:20 PM > ep 756 done. total_steps=34723 | reward=1.0 | episode_steps=29 | hours=0.010 | epsilon=0.259
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 6.75, count = 4
2025/07/28 11:30:20 PM > ep 757 done. total_steps=34741 | reward=1.0 | episode_steps=18 | hours=0.010 | epsilon=0.258
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:20 PM > ep 758 done. total_steps=34777 | reward=1.0 | episode_steps=36 | hours=0.010 | epsilon=0.258
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 22.00, count = 1
2025/07/28 11:30:20 PM > ep 759 done. total_steps=34803 | reward=1.0 | episode_steps=26 | hours=0.010 | epsilon=0.258
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 3.00, count = 1
2025/07/28 11:30:20 PM > ep 760 done. total_steps=34805 | reward=1.0 | episode_steps=2 | hours=0.010 | epsilon=0.258
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:20 PM > ep 761 done. total_steps=34846 | reward=1.0 | episode_steps=41 | hours=0.010 | epsilon=0.258
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 11.00, count = 2
2025/07/28 11:30:20 PM > ep 762 done. total_steps=34856 | reward=1.0 | episode_steps=10 | hours=0.010 | epsilon=0.258
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:20 PM > ep 763 done. total_steps=34868 | reward=1.0 | episode_steps=12 | hours=0.010 | epsilon=0.257
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:20 PM > ep 764 done. total_steps=34894 | reward=1.0 | episode_steps=26 | hours=0.010 | epsilon=0.257
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:20 PM > ep 765 done. total_steps=34903 | reward=1.0 | episode_steps=9 | hours=0.010 | epsilon=0.257
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 3.00, count = 2
2025/07/28 11:30:20 PM > ep 766 done. total_steps=34939 | reward=1.0 | episode_steps=36 | hours=0.010 | epsilon=0.257
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:20 PM > ep 767 done. total_steps=34948 | reward=1.0 | episode_steps=9 | hours=0.010 | epsilon=0.257
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 5.00, count = 1
2025/07/28 11:30:20 PM > ep 768 done. total_steps=34949 | reward=1.0 | episode_steps=1 | hours=0.010 | epsilon=0.257
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:20 PM > ep 769 done. total_steps=34962 | reward=1.0 | episode_steps=13 | hours=0.010 | epsilon=0.257
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:20 PM > ep 770 done. total_steps=34971 | reward=1.0 | episode_steps=9 | hours=0.010 | epsilon=0.257
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:20 PM > ep 771 done. total_steps=34983 | reward=1.0 | episode_steps=12 | hours=0.010 | epsilon=0.257
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:20 PM > ep 772 done. total_steps=35002 | reward=1.0 | episode_steps=19 | hours=0.010 | epsilon=0.256
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:20 PM > ep 773 done. total_steps=35020 | reward=1.0 | episode_steps=18 | hours=0.010 | epsilon=0.256
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:20 PM > ep 774 done. total_steps=35031 | reward=1.0 | episode_steps=11 | hours=0.010 | epsilon=0.256
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:20 PM > ep 775 done. total_steps=35034 | reward=1.0 | episode_steps=3 | hours=0.010 | epsilon=0.256
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:20 PM > ep 776 done. total_steps=35069 | reward=1.0 | episode_steps=35 | hours=0.010 | epsilon=0.256
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:20 PM > ep 777 done. total_steps=35095 | reward=1.0 | episode_steps=26 | hours=0.010 | epsilon=0.256
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:20 PM > ep 778 done. total_steps=35121 | reward=1.0 | episode_steps=26 | hours=0.010 | epsilon=0.255
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.00, count = 1
2025/07/28 11:30:20 PM > ep 779 done. total_steps=35125 | reward=1.0 | episode_steps=4 | hours=0.010 | epsilon=0.255
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:20 PM > ep 780 done. total_steps=35133 | reward=1.0 | episode_steps=8 | hours=0.010 | epsilon=0.255
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:20 PM > ep 781 done. total_steps=35141 | reward=1.0 | episode_steps=8 | hours=0.010 | epsilon=0.255
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:20 PM > ep 782 done. total_steps=35158 | reward=1.0 | episode_steps=17 | hours=0.010 | epsilon=0.255
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 6.00, count = 1
2025/07/28 11:30:20 PM > ep 783 done. total_steps=35177 | reward=1.0 | episode_steps=19 | hours=0.010 | epsilon=0.255
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 16.00, count = 1
2025/07/28 11:30:20 PM > ep 784 done. total_steps=35182 | reward=1.0 | episode_steps=5 | hours=0.010 | epsilon=0.255
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:20 PM > ep 785 done. total_steps=35202 | reward=1.0 | episode_steps=20 | hours=0.010 | epsilon=0.255
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:20 PM > ep 786 done. total_steps=35208 | reward=1.0 | episode_steps=6 | hours=0.010 | epsilon=0.255
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:20 PM > ep 787 done. total_steps=35223 | reward=1.0 | episode_steps=15 | hours=0.010 | epsilon=0.255
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:20 PM > ep 788 done. total_steps=35241 | reward=1.0 | episode_steps=18 | hours=0.010 | epsilon=0.255
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:20 PM > ep 789 done. total_steps=35249 | reward=1.0 | episode_steps=8 | hours=0.010 | epsilon=0.254
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:20 PM > ep 790 done. total_steps=35278 | reward=1.0 | episode_steps=29 | hours=0.010 | epsilon=0.254
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:20 PM > ep 791 done. total_steps=35287 | reward=1.0 | episode_steps=9 | hours=0.010 | epsilon=0.254
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:20 PM > ep 792 done. total_steps=35294 | reward=1.0 | episode_steps=7 | hours=0.010 | epsilon=0.254
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:20 PM > ep 793 done. total_steps=35345 | reward=1.0 | episode_steps=51 | hours=0.010 | epsilon=0.254
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:20 PM > ep 794 done. total_steps=35374 | reward=1.0 | episode_steps=29 | hours=0.010 | epsilon=0.254
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 6.00, count = 1
2025/07/28 11:30:20 PM > ep 795 done. total_steps=35387 | reward=1.0 | episode_steps=13 | hours=0.010 | epsilon=0.253
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:20 PM > ep 796 done. total_steps=35404 | reward=1.0 | episode_steps=17 | hours=0.010 | epsilon=0.253
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 16.00, count = 1
2025/07/28 11:30:20 PM > ep 797 done. total_steps=35407 | reward=1.0 | episode_steps=3 | hours=0.010 | epsilon=0.253
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:20 PM > ep 798 done. total_steps=35411 | reward=1.0 | episode_steps=4 | hours=0.010 | epsilon=0.253
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 799 done. total_steps=35427 | reward=1.0 | episode_steps=16 | hours=0.010 | epsilon=0.253
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 800 done. total_steps=35442 | reward=1.0 | episode_steps=15 | hours=0.010 | epsilon=0.253
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 801 done. total_steps=35459 | reward=1.0 | episode_steps=17 | hours=0.010 | epsilon=0.253
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 802 done. total_steps=35471 | reward=1.0 | episode_steps=12 | hours=0.010 | epsilon=0.253
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 803 done. total_steps=35479 | reward=1.0 | episode_steps=8 | hours=0.010 | epsilon=0.253
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 804 done. total_steps=35498 | reward=1.0 | episode_steps=19 | hours=0.010 | epsilon=0.253
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 805 done. total_steps=35514 | reward=1.0 | episode_steps=16 | hours=0.010 | epsilon=0.252
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 806 done. total_steps=35527 | reward=1.0 | episode_steps=13 | hours=0.010 | epsilon=0.252
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 807 done. total_steps=35541 | reward=1.0 | episode_steps=14 | hours=0.010 | epsilon=0.252
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 808 done. total_steps=35566 | reward=1.0 | episode_steps=25 | hours=0.010 | epsilon=0.252
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 809 done. total_steps=35569 | reward=1.0 | episode_steps=3 | hours=0.010 | epsilon=0.252
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 810 done. total_steps=35586 | reward=1.0 | episode_steps=17 | hours=0.010 | epsilon=0.252
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 811 done. total_steps=35615 | reward=1.0 | episode_steps=29 | hours=0.010 | epsilon=0.252
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 812 done. total_steps=35631 | reward=1.0 | episode_steps=16 | hours=0.010 | epsilon=0.252
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 10.00, count = 1
2025/07/28 11:30:21 PM > ep 813 done. total_steps=35635 | reward=1.0 | episode_steps=4 | hours=0.010 | epsilon=0.252
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 814 done. total_steps=35639 | reward=1.0 | episode_steps=4 | hours=0.010 | epsilon=0.251
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 815 done. total_steps=35654 | reward=1.0 | episode_steps=15 | hours=0.010 | epsilon=0.251
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 13.00, count = 1
2025/07/28 11:30:21 PM > ep 816 done. total_steps=35661 | reward=1.0 | episode_steps=7 | hours=0.010 | epsilon=0.251
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 817 done. total_steps=35684 | reward=1.0 | episode_steps=23 | hours=0.010 | epsilon=0.251
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 818 done. total_steps=35705 | reward=1.0 | episode_steps=21 | hours=0.010 | epsilon=0.251
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 819 done. total_steps=35732 | reward=1.0 | episode_steps=27 | hours=0.010 | epsilon=0.251
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 820 done. total_steps=35736 | reward=1.0 | episode_steps=4 | hours=0.010 | epsilon=0.251
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 821 done. total_steps=35753 | reward=1.0 | episode_steps=17 | hours=0.010 | epsilon=0.251
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 822 done. total_steps=35771 | reward=1.0 | episode_steps=18 | hours=0.010 | epsilon=0.250
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 823 done. total_steps=35779 | reward=1.0 | episode_steps=8 | hours=0.010 | epsilon=0.250
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 824 done. total_steps=35789 | reward=1.0 | episode_steps=10 | hours=0.010 | epsilon=0.250
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 825 done. total_steps=35819 | reward=1.0 | episode_steps=30 | hours=0.010 | epsilon=0.250
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 826 done. total_steps=35847 | reward=1.0 | episode_steps=28 | hours=0.010 | epsilon=0.250
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 827 done. total_steps=35874 | reward=1.0 | episode_steps=27 | hours=0.010 | epsilon=0.250
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 828 done. total_steps=35895 | reward=1.0 | episode_steps=21 | hours=0.010 | epsilon=0.250
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 829 done. total_steps=35919 | reward=1.0 | episode_steps=24 | hours=0.010 | epsilon=0.249
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 830 done. total_steps=35943 | reward=1.0 | episode_steps=24 | hours=0.010 | epsilon=0.249
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.00, count = 1
2025/07/28 11:30:21 PM > ep 831 done. total_steps=35944 | reward=1.0 | episode_steps=1 | hours=0.010 | epsilon=0.249
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 832 done. total_steps=35954 | reward=1.0 | episode_steps=10 | hours=0.010 | epsilon=0.249
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 833 done. total_steps=35964 | reward=1.0 | episode_steps=10 | hours=0.010 | epsilon=0.249
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.00, count = 1
2025/07/28 11:30:21 PM > ep 834 done. total_steps=35974 | reward=1.0 | episode_steps=10 | hours=0.010 | epsilon=0.249
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.00, count = 1
2025/07/28 11:30:21 PM > ep 835 done. total_steps=35990 | reward=1.0 | episode_steps=16 | hours=0.010 | epsilon=0.249
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 836 done. total_steps=36005 | reward=1.0 | episode_steps=15 | hours=0.010 | epsilon=0.249
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 837 done. total_steps=36013 | reward=1.0 | episode_steps=8 | hours=0.010 | epsilon=0.249
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 2.00, count = 2
2025/07/28 11:30:21 PM > ep 838 done. total_steps=36021 | reward=1.0 | episode_steps=8 | hours=0.010 | epsilon=0.249
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 839 done. total_steps=36040 | reward=1.0 | episode_steps=19 | hours=0.010 | epsilon=0.248
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 840 done. total_steps=36044 | reward=1.0 | episode_steps=4 | hours=0.010 | epsilon=0.248
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 841 done. total_steps=36048 | reward=1.0 | episode_steps=4 | hours=0.010 | epsilon=0.248
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 842 done. total_steps=36054 | reward=1.0 | episode_steps=6 | hours=0.010 | epsilon=0.248
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 3.00, count = 1
2025/07/28 11:30:21 PM > ep 843 done. total_steps=36057 | reward=1.0 | episode_steps=3 | hours=0.010 | epsilon=0.248
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.00, count = 1
2025/07/28 11:30:21 PM > ep 844 done. total_steps=36061 | reward=1.0 | episode_steps=4 | hours=0.010 | epsilon=0.248
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 845 done. total_steps=36077 | reward=1.0 | episode_steps=16 | hours=0.010 | epsilon=0.248
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 846 done. total_steps=36080 | reward=1.0 | episode_steps=3 | hours=0.010 | epsilon=0.248
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.00, count = 1
2025/07/28 11:30:21 PM > ep 847 done. total_steps=36086 | reward=1.0 | episode_steps=6 | hours=0.010 | epsilon=0.248
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 848 done. total_steps=36116 | reward=1.0 | episode_steps=30 | hours=0.010 | epsilon=0.248
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 849 done. total_steps=36122 | reward=1.0 | episode_steps=6 | hours=0.010 | epsilon=0.248
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 850 done. total_steps=36135 | reward=1.0 | episode_steps=13 | hours=0.010 | epsilon=0.248
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 851 done. total_steps=36166 | reward=1.0 | episode_steps=31 | hours=0.010 | epsilon=0.248
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 852 done. total_steps=36179 | reward=1.0 | episode_steps=13 | hours=0.010 | epsilon=0.247
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 853 done. total_steps=36198 | reward=1.0 | episode_steps=19 | hours=0.010 | epsilon=0.247
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 15.00, count = 1
2025/07/28 11:30:21 PM > ep 854 done. total_steps=36207 | reward=1.0 | episode_steps=9 | hours=0.010 | epsilon=0.247
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 855 done. total_steps=36225 | reward=1.0 | episode_steps=18 | hours=0.010 | epsilon=0.247
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 856 done. total_steps=36244 | reward=1.0 | episode_steps=19 | hours=0.010 | epsilon=0.247
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 857 done. total_steps=36275 | reward=1.0 | episode_steps=31 | hours=0.010 | epsilon=0.247
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 858 done. total_steps=36281 | reward=1.0 | episode_steps=6 | hours=0.010 | epsilon=0.247
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 859 done. total_steps=36292 | reward=1.0 | episode_steps=11 | hours=0.010 | epsilon=0.247
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 860 done. total_steps=36304 | reward=1.0 | episode_steps=12 | hours=0.010 | epsilon=0.247
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 3.00, count = 1
2025/07/28 11:30:21 PM > ep 861 done. total_steps=36319 | reward=1.0 | episode_steps=15 | hours=0.010 | epsilon=0.246
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 862 done. total_steps=36343 | reward=1.0 | episode_steps=24 | hours=0.010 | epsilon=0.246
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 863 done. total_steps=36353 | reward=1.0 | episode_steps=10 | hours=0.010 | epsilon=0.246
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 864 done. total_steps=36363 | reward=1.0 | episode_steps=10 | hours=0.010 | epsilon=0.246
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 865 done. total_steps=36391 | reward=1.0 | episode_steps=28 | hours=0.010 | epsilon=0.246
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 866 done. total_steps=36407 | reward=1.0 | episode_steps=16 | hours=0.010 | epsilon=0.246
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 7.50, count = 2
2025/07/28 11:30:21 PM > ep 867 done. total_steps=36425 | reward=1.0 | episode_steps=18 | hours=0.010 | epsilon=0.246
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 868 done. total_steps=36454 | reward=1.0 | episode_steps=29 | hours=0.010 | epsilon=0.245
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 869 done. total_steps=36455 | reward=1.0 | episode_steps=1 | hours=0.010 | epsilon=0.245
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 870 done. total_steps=36475 | reward=1.0 | episode_steps=20 | hours=0.010 | epsilon=0.245
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 871 done. total_steps=36483 | reward=1.0 | episode_steps=8 | hours=0.010 | epsilon=0.245
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 872 done. total_steps=36488 | reward=1.0 | episode_steps=5 | hours=0.010 | epsilon=0.245
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 873 done. total_steps=36516 | reward=1.0 | episode_steps=28 | hours=0.010 | epsilon=0.245
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 4.00, count = 1
2025/07/28 11:30:21 PM > ep 874 done. total_steps=36537 | reward=1.0 | episode_steps=21 | hours=0.010 | epsilon=0.245
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 875 done. total_steps=36552 | reward=1.0 | episode_steps=15 | hours=0.010 | epsilon=0.245
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 876 done. total_steps=36558 | reward=1.0 | episode_steps=6 | hours=0.010 | epsilon=0.245
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 877 done. total_steps=36573 | reward=1.0 | episode_steps=15 | hours=0.010 | epsilon=0.245
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 878 done. total_steps=36591 | reward=1.0 | episode_steps=18 | hours=0.010 | epsilon=0.244
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 879 done. total_steps=36615 | reward=1.0 | episode_steps=24 | hours=0.010 | epsilon=0.244
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 880 done. total_steps=36633 | reward=1.0 | episode_steps=18 | hours=0.010 | epsilon=0.244
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 881 done. total_steps=36653 | reward=1.0 | episode_steps=20 | hours=0.010 | epsilon=0.244
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 882 done. total_steps=36664 | reward=1.0 | episode_steps=11 | hours=0.010 | epsilon=0.244
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 883 done. total_steps=36670 | reward=1.0 | episode_steps=6 | hours=0.010 | epsilon=0.244
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 884 done. total_steps=36683 | reward=1.0 | episode_steps=13 | hours=0.010 | epsilon=0.244
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 885 done. total_steps=36708 | reward=1.0 | episode_steps=25 | hours=0.010 | epsilon=0.244
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 9.00, count = 1
2025/07/28 11:30:21 PM > ep 886 done. total_steps=36735 | reward=1.0 | episode_steps=27 | hours=0.010 | epsilon=0.243
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 887 done. total_steps=36750 | reward=1.0 | episode_steps=15 | hours=0.010 | epsilon=0.243
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 888 done. total_steps=36779 | reward=1.0 | episode_steps=29 | hours=0.010 | epsilon=0.243
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:21 PM > ep 889 done. total_steps=36798 | reward=1.0 | episode_steps=19 | hours=0.010 | epsilon=0.243
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.00, count = 1
2025/07/28 11:30:22 PM > ep 890 done. total_steps=36832 | reward=1.0 | episode_steps=34 | hours=0.010 | epsilon=0.243
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:22 PM > ep 891 done. total_steps=36838 | reward=1.0 | episode_steps=6 | hours=0.010 | epsilon=0.243
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:22 PM > ep 892 done. total_steps=36876 | reward=1.0 | episode_steps=38 | hours=0.010 | epsilon=0.242
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:22 PM > ep 893 done. total_steps=36908 | reward=1.0 | episode_steps=32 | hours=0.010 | epsilon=0.242
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:22 PM > ep 894 done. total_steps=36913 | reward=1.0 | episode_steps=5 | hours=0.010 | epsilon=0.242
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:22 PM > ep 895 done. total_steps=36927 | reward=1.0 | episode_steps=14 | hours=0.010 | epsilon=0.242
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 10.00, count = 1
2025/07/28 11:30:22 PM > ep 896 done. total_steps=36948 | reward=1.0 | episode_steps=21 | hours=0.010 | epsilon=0.242
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:22 PM > ep 897 done. total_steps=36949 | reward=1.0 | episode_steps=1 | hours=0.010 | epsilon=0.242
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:22 PM > ep 898 done. total_steps=36956 | reward=1.0 | episode_steps=7 | hours=0.010 | epsilon=0.242
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:22 PM > ep 899 done. total_steps=36962 | reward=1.0 | episode_steps=6 | hours=0.010 | epsilon=0.242
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:22 PM > ep 900 done. total_steps=36970 | reward=1.0 | episode_steps=8 | hours=0.010 | epsilon=0.242
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:22 PM > ep 901 done. total_steps=37013 | reward=1.0 | episode_steps=43 | hours=0.010 | epsilon=0.241
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:22 PM > ep 902 done. total_steps=37018 | reward=1.0 | episode_steps=5 | hours=0.010 | epsilon=0.241
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:22 PM > ep 903 done. total_steps=37038 | reward=1.0 | episode_steps=20 | hours=0.010 | epsilon=0.241
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:22 PM > ep 904 done. total_steps=37047 | reward=1.0 | episode_steps=9 | hours=0.010 | epsilon=0.241
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:22 PM > ep 905 done. total_steps=37071 | reward=1.0 | episode_steps=24 | hours=0.010 | epsilon=0.241
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:22 PM > ep 906 done. total_steps=37090 | reward=1.0 | episode_steps=19 | hours=0.010 | epsilon=0.241
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:22 PM > ep 907 done. total_steps=37097 | reward=1.0 | episode_steps=7 | hours=0.010 | epsilon=0.241
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:22 PM > ep 908 done. total_steps=37120 | reward=1.0 | episode_steps=23 | hours=0.010 | epsilon=0.241
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:22 PM > ep 909 done. total_steps=37162 | reward=1.0 | episode_steps=42 | hours=0.010 | epsilon=0.240
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:22 PM > ep 910 done. total_steps=37185 | reward=1.0 | episode_steps=23 | hours=0.010 | epsilon=0.240
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 2.00, count = 1
2025/07/28 11:30:22 PM > ep 911 done. total_steps=37194 | reward=1.0 | episode_steps=9 | hours=0.010 | epsilon=0.240
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:22 PM > ep 912 done. total_steps=37216 | reward=1.0 | episode_steps=22 | hours=0.010 | epsilon=0.240
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:22 PM > ep 913 done. total_steps=37237 | reward=1.0 | episode_steps=21 | hours=0.010 | epsilon=0.240
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:22 PM > ep 914 done. total_steps=37269 | reward=1.0 | episode_steps=32 | hours=0.010 | epsilon=0.240
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:22 PM > ep 915 done. total_steps=37282 | reward=1.0 | episode_steps=13 | hours=0.010 | epsilon=0.240
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:22 PM > ep 916 done. total_steps=37298 | reward=1.0 | episode_steps=16 | hours=0.010 | epsilon=0.239
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:22 PM > ep 917 done. total_steps=37343 | reward=1.0 | episode_steps=45 | hours=0.010 | epsilon=0.239
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:22 PM > ep 918 done. total_steps=37372 | reward=1.0 | episode_steps=29 | hours=0.010 | epsilon=0.239
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:22 PM > ep 919 done. total_steps=37390 | reward=1.0 | episode_steps=18 | hours=0.010 | epsilon=0.239
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:22 PM > ep 920 done. total_steps=37405 | reward=1.0 | episode_steps=15 | hours=0.010 | epsilon=0.239
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:22 PM > ep 921 done. total_steps=37409 | reward=1.0 | episode_steps=4 | hours=0.010 | epsilon=0.239
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:22 PM > ep 922 done. total_steps=37418 | reward=1.0 | episode_steps=9 | hours=0.010 | epsilon=0.239
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.00, count = 2
2025/07/28 11:30:22 PM > ep 923 done. total_steps=37504 | reward=1.0 | episode_steps=86 | hours=0.010 | epsilon=0.238
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:22 PM > ep 924 done. total_steps=37555 | reward=1.0 | episode_steps=51 | hours=0.010 | epsilon=0.238
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.00, count = 3
2025/07/28 11:30:22 PM > ep 925 done. total_steps=37571 | reward=1.0 | episode_steps=16 | hours=0.010 | epsilon=0.238
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:22 PM > ep 926 done. total_steps=37594 | reward=1.0 | episode_steps=23 | hours=0.010 | epsilon=0.237
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.00, count = 2
2025/07/28 11:30:22 PM > ep 927 done. total_steps=37607 | reward=1.0 | episode_steps=13 | hours=0.010 | epsilon=0.237
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.33, count = 3
2025/07/28 11:30:22 PM > ep 928 done. total_steps=37625 | reward=1.0 | episode_steps=18 | hours=0.010 | epsilon=0.237
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:22 PM > ep 929 done. total_steps=37643 | reward=1.0 | episode_steps=18 | hours=0.010 | epsilon=0.237
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 2.00, count = 1
2025/07/28 11:30:22 PM > ep 930 done. total_steps=37735 | reward=1.0 | episode_steps=92 | hours=0.010 | epsilon=0.236
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.00, count = 3
2025/07/28 11:30:22 PM > ep 931 done. total_steps=37742 | reward=1.0 | episode_steps=7 | hours=0.010 | epsilon=0.236
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:22 PM > ep 932 done. total_steps=37775 | reward=1.0 | episode_steps=33 | hours=0.010 | epsilon=0.236
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:22 PM > ep 933 done. total_steps=37802 | reward=1.0 | episode_steps=27 | hours=0.011 | epsilon=0.236
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.33, count = 6
2025/07/28 11:30:22 PM > ep 934 done. total_steps=37829 | reward=1.0 | episode_steps=27 | hours=0.011 | epsilon=0.236
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:22 PM > ep 935 done. total_steps=37933 | reward=1.0 | episode_steps=104 | hours=0.011 | epsilon=0.235
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:22 PM > ep 936 done. total_steps=38151 | reward=1.0 | episode_steps=218 | hours=0.011 | epsilon=0.234
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:22 PM > ep 937 done. total_steps=38207 | reward=1.0 | episode_steps=56 | hours=0.011 | epsilon=0.233
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:22 PM > ep 938 done. total_steps=38213 | reward=1.0 | episode_steps=6 | hours=0.011 | epsilon=0.233
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:23 PM > ep 939 done. total_steps=38304 | reward=1.0 | episode_steps=91 | hours=0.011 | epsilon=0.233
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 10.00, count = 1
2025/07/28 11:30:23 PM > ep 940 done. total_steps=38334 | reward=1.0 | episode_steps=30 | hours=0.011 | epsilon=0.232
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:23 PM > ep 941 done. total_steps=38552 | reward=1.0 | episode_steps=218 | hours=0.011 | epsilon=0.231
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:23 PM > ep 942 done. total_steps=38583 | reward=1.0 | episode_steps=31 | hours=0.011 | epsilon=0.231
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:23 PM > ep 943 done. total_steps=38659 | reward=1.0 | episode_steps=76 | hours=0.011 | epsilon=0.230
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:23 PM > ep 944 done. total_steps=38775 | reward=1.0 | episode_steps=116 | hours=0.011 | epsilon=0.230
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 1.00, count = 2
2025/07/28 11:30:23 PM > ep 945 done. total_steps=38782 | reward=1.0 | episode_steps=7 | hours=0.011 | epsilon=0.229
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:23 PM > ep 946 done. total_steps=38840 | reward=1.0 | episode_steps=58 | hours=0.011 | epsilon=0.229
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:23 PM > ep 947 done. total_steps=38861 | reward=1.0 | episode_steps=21 | hours=0.011 | epsilon=0.229
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:23 PM > ep 948 done. total_steps=38996 | reward=1.0 | episode_steps=135 | hours=0.011 | epsilon=0.228
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:23 PM > ep 949 done. total_steps=38999 | reward=1.0 | episode_steps=3 | hours=0.011 | epsilon=0.228
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:23 PM > ep 950 done. total_steps=39004 | reward=1.0 | episode_steps=5 | hours=0.011 | epsilon=0.228
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:23 PM > ep 951 done. total_steps=39658 | reward=1.0 | episode_steps=654 | hours=0.011 | epsilon=0.224
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 3.00, count = 2
2025/07/28 11:30:24 PM > ep 952 done. total_steps=40111 | reward=1.0 | episode_steps=453 | hours=0.011 | epsilon=0.221
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 2.93, count = 15
2025/07/28 11:30:24 PM > ep 953 done. total_steps=40436 | reward=1.0 | episode_steps=325 | hours=0.011 | epsilon=0.219
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:24 PM > ep 954 done. total_steps=40535 | reward=1.0 | episode_steps=99 | hours=0.011 | epsilon=0.219
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:24 PM > ep 955 done. total_steps=40541 | reward=1.0 | episode_steps=6 | hours=0.011 | epsilon=0.219
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 2.00, count = 1
2025/07/28 11:30:24 PM > ep 956 done. total_steps=40574 | reward=1.0 | episode_steps=33 | hours=0.011 | epsilon=0.218
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:24 PM > ep 957 done. total_steps=40631 | reward=1.0 | episode_steps=57 | hours=0.011 | epsilon=0.218
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 2.83, count = 6
2025/07/28 11:30:24 PM > ep 958 done. total_steps=40672 | reward=1.0 | episode_steps=41 | hours=0.011 | epsilon=0.218
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:24 PM > ep 959 done. total_steps=40703 | reward=1.0 | episode_steps=31 | hours=0.011 | epsilon=0.218
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:24 PM > ep 960 done. total_steps=40783 | reward=1.0 | episode_steps=80 | hours=0.011 | epsilon=0.217
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 8.22, count = 9
2025/07/28 11:30:24 PM > ep 961 done. total_steps=40816 | reward=1.0 | episode_steps=33 | hours=0.011 | epsilon=0.217
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 19.00, count = 1
2025/07/28 11:30:24 PM > ep 962 done. total_steps=40841 | reward=1.0 | episode_steps=25 | hours=0.011 | epsilon=0.217
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 17.00, count = 1
2025/07/28 11:30:24 PM > ep 963 done. total_steps=40847 | reward=1.0 | episode_steps=6 | hours=0.011 | epsilon=0.217
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 4.00, count = 1
2025/07/28 11:30:24 PM > ep 964 done. total_steps=40992 | reward=1.0 | episode_steps=145 | hours=0.011 | epsilon=0.216
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 38.00, count = 1
2025/07/28 11:30:24 PM > ep 965 done. total_steps=41005 | reward=1.0 | episode_steps=13 | hours=0.011 | epsilon=0.216
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:24 PM > ep 966 done. total_steps=41018 | reward=1.0 | episode_steps=13 | hours=0.011 | epsilon=0.216
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:24 PM > ep 967 done. total_steps=41028 | reward=1.0 | episode_steps=10 | hours=0.011 | epsilon=0.216
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 2.50, count = 2
2025/07/28 11:30:24 PM > ep 968 done. total_steps=41053 | reward=1.0 | episode_steps=25 | hours=0.011 | epsilon=0.216
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 11.00, count = 1
2025/07/28 11:30:24 PM > ep 969 done. total_steps=41071 | reward=1.0 | episode_steps=18 | hours=0.011 | epsilon=0.215
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:24 PM > ep 970 done. total_steps=41101 | reward=1.0 | episode_steps=30 | hours=0.011 | epsilon=0.215
  - Option 0: avg len = 0.00, count = 1
  - Option 1: avg len = 2.00, count = 1
2025/07/28 11:30:24 PM > ep 971 done. total_steps=41154 | reward=1.0 | episode_steps=53 | hours=0.011 | epsilon=0.215
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:24 PM > ep 972 done. total_steps=41179 | reward=1.0 | episode_steps=25 | hours=0.011 | epsilon=0.215
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:24 PM > ep 973 done. total_steps=41212 | reward=1.0 | episode_steps=33 | hours=0.011 | epsilon=0.215
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:25 PM > ep 974 done. total_steps=41232 | reward=1.0 | episode_steps=20 | hours=0.011 | epsilon=0.215
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:25 PM > ep 975 done. total_steps=41245 | reward=1.0 | episode_steps=13 | hours=0.011 | epsilon=0.214
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:25 PM > ep 976 done. total_steps=41311 | reward=1.0 | episode_steps=66 | hours=0.011 | epsilon=0.214
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:25 PM > ep 977 done. total_steps=41464 | reward=1.0 | episode_steps=153 | hours=0.012 | epsilon=0.213
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:25 PM > ep 978 done. total_steps=41505 | reward=1.0 | episode_steps=41 | hours=0.012 | epsilon=0.213
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:25 PM > ep 979 done. total_steps=41526 | reward=1.0 | episode_steps=21 | hours=0.012 | epsilon=0.213
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:25 PM > ep 980 done. total_steps=41608 | reward=1.0 | episode_steps=82 | hours=0.012 | epsilon=0.212
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:25 PM > ep 981 done. total_steps=41669 | reward=1.0 | episode_steps=61 | hours=0.012 | epsilon=0.212
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:25 PM > ep 982 done. total_steps=41754 | reward=1.0 | episode_steps=85 | hours=0.012 | epsilon=0.212
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:25 PM > ep 983 done. total_steps=41778 | reward=1.0 | episode_steps=24 | hours=0.012 | epsilon=0.211
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:25 PM > ep 984 done. total_steps=41832 | reward=1.0 | episode_steps=54 | hours=0.012 | epsilon=0.211
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:25 PM > ep 985 done. total_steps=41835 | reward=1.0 | episode_steps=3 | hours=0.012 | epsilon=0.211
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:25 PM > ep 986 done. total_steps=41860 | reward=1.0 | episode_steps=25 | hours=0.012 | epsilon=0.211
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:25 PM > ep 987 done. total_steps=41907 | reward=1.0 | episode_steps=47 | hours=0.012 | epsilon=0.211
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:25 PM > ep 988 done. total_steps=41984 | reward=1.0 | episode_steps=77 | hours=0.012 | epsilon=0.210
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:25 PM > ep 989 done. total_steps=42051 | reward=1.0 | episode_steps=67 | hours=0.012 | epsilon=0.210
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:25 PM > ep 990 done. total_steps=42101 | reward=1.0 | episode_steps=50 | hours=0.012 | epsilon=0.210
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:25 PM > ep 991 done. total_steps=42234 | reward=1.0 | episode_steps=133 | hours=0.012 | epsilon=0.209
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:25 PM > ep 992 done. total_steps=42255 | reward=1.0 | episode_steps=21 | hours=0.012 | epsilon=0.209
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:25 PM > ep 993 done. total_steps=42273 | reward=1.0 | episode_steps=18 | hours=0.012 | epsilon=0.209
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:25 PM > ep 994 done. total_steps=42421 | reward=1.0 | episode_steps=148 | hours=0.012 | epsilon=0.208
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:26 PM > ep 995 done. total_steps=42776 | reward=1.0 | episode_steps=355 | hours=0.012 | epsilon=0.206
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:26 PM > ep 996 done. total_steps=43117 | reward=1.0 | episode_steps=341 | hours=0.012 | epsilon=0.204
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:26 PM > ep 997 done. total_steps=43246 | reward=1.0 | episode_steps=129 | hours=0.012 | epsilon=0.204
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:26 PM > ep 998 done. total_steps=43278 | reward=1.0 | episode_steps=32 | hours=0.012 | epsilon=0.203
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:26 PM > ep 999 done. total_steps=43305 | reward=1.0 | episode_steps=27 | hours=0.012 | epsilon=0.203
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:26 PM > ep 1000 done. total_steps=43532 | reward=1.0 | episode_steps=227 | hours=0.012 | epsilon=0.202
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:27 PM > ep 1001 done. total_steps=44532 | reward=0.0 | episode_steps=1000 | hours=0.012 | epsilon=0.197
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:28 PM > ep 1002 done. total_steps=45532 | reward=0.0 | episode_steps=1000 | hours=0.013 | epsilon=0.192
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:28 PM > ep 1003 done. total_steps=45561 | reward=1.0 | episode_steps=29 | hours=0.013 | epsilon=0.192
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:28 PM > ep 1004 done. total_steps=46561 | reward=0.0 | episode_steps=1000 | hours=0.013 | epsilon=0.188
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:29 PM > ep 1005 done. total_steps=47561 | reward=0.0 | episode_steps=1000 | hours=0.013 | epsilon=0.183
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:30 PM > ep 1006 done. total_steps=48561 | reward=0.0 | episode_steps=1000 | hours=0.013 | epsilon=0.179
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:30 PM > ep 1007 done. total_steps=49561 | reward=0.0 | episode_steps=1000 | hours=0.014 | epsilon=0.176
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:30 PM > ep 1008 done. total_steps=49617 | reward=1.0 | episode_steps=56 | hours=0.014 | epsilon=0.175
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:31 PM > ep 1009 done. total_steps=49845 | reward=1.0 | episode_steps=228 | hours=0.014 | epsilon=0.174
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:31 PM > ep 1010 done. total_steps=50845 | reward=0.0 | episode_steps=1000 | hours=0.014 | epsilon=0.171
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:31 PM > ep 1011 done. total_steps=50860 | reward=1.0 | episode_steps=15 | hours=0.014 | epsilon=0.171
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:32 PM > ep 1012 done. total_steps=51860 | reward=0.0 | episode_steps=1000 | hours=0.014 | epsilon=0.167
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:32 PM > ep 1013 done. total_steps=51869 | reward=1.0 | episode_steps=9 | hours=0.014 | epsilon=0.167
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:32 PM > ep 1014 done. total_steps=51893 | reward=1.0 | episode_steps=24 | hours=0.014 | epsilon=0.167
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:32 PM > ep 1015 done. total_steps=51979 | reward=1.0 | episode_steps=86 | hours=0.014 | epsilon=0.167
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:33 PM > ep 1016 done. total_steps=52691 | reward=1.0 | episode_steps=712 | hours=0.015 | epsilon=0.165
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:34 PM > ep 1017 done. total_steps=53569 | reward=1.0 | episode_steps=878 | hours=0.015 | epsilon=0.162
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:35 PM > ep 1018 done. total_steps=54569 | reward=0.0 | episode_steps=1000 | hours=0.015 | epsilon=0.159
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:35 PM > ep 1019 done. total_steps=55569 | reward=0.0 | episode_steps=1000 | hours=0.015 | epsilon=0.156
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:36 PM > ep 1020 done. total_steps=56569 | reward=0.0 | episode_steps=1000 | hours=0.016 | epsilon=0.153
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:36 PM > ep 1021 done. total_steps=56847 | reward=1.0 | episode_steps=278 | hours=0.016 | epsilon=0.152
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:36 PM > ep 1022 done. total_steps=57147 | reward=1.0 | episode_steps=300 | hours=0.016 | epsilon=0.152
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:37 PM > ep 1023 done. total_steps=57690 | reward=1.0 | episode_steps=543 | hours=0.016 | epsilon=0.150
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:37 PM > ep 1024 done. total_steps=57915 | reward=1.0 | episode_steps=225 | hours=0.016 | epsilon=0.150
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:37 PM > ep 1025 done. total_steps=58301 | reward=1.0 | episode_steps=386 | hours=0.016 | epsilon=0.149
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:37 PM > ep 1026 done. total_steps=58363 | reward=1.0 | episode_steps=62 | hours=0.016 | epsilon=0.149
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:38 PM > ep 1027 done. total_steps=59363 | reward=0.0 | episode_steps=1000 | hours=0.016 | epsilon=0.146
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:39 PM > ep 1028 done. total_steps=60363 | reward=0.0 | episode_steps=1000 | hours=0.017 | epsilon=0.144
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:39 PM > ep 1029 done. total_steps=60419 | reward=1.0 | episode_steps=56 | hours=0.017 | epsilon=0.144
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:39 PM > ep 1030 done. total_steps=60518 | reward=1.0 | episode_steps=99 | hours=0.017 | epsilon=0.144
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:39 PM > ep 1031 done. total_steps=60522 | reward=1.0 | episode_steps=4 | hours=0.017 | epsilon=0.144
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:39 PM > ep 1032 done. total_steps=60717 | reward=1.0 | episode_steps=195 | hours=0.017 | epsilon=0.143
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:39 PM > ep 1033 done. total_steps=61017 | reward=1.0 | episode_steps=300 | hours=0.017 | epsilon=0.143
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:39 PM > ep 1034 done. total_steps=61030 | reward=1.0 | episode_steps=13 | hours=0.017 | epsilon=0.143
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:40 PM > ep 1035 done. total_steps=61282 | reward=1.0 | episode_steps=252 | hours=0.017 | epsilon=0.142
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:40 PM > ep 1036 done. total_steps=61312 | reward=1.0 | episode_steps=30 | hours=0.017 | epsilon=0.142
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:40 PM > ep 1037 done. total_steps=61836 | reward=1.0 | episode_steps=524 | hours=0.017 | epsilon=0.141
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:41 PM > ep 1038 done. total_steps=62615 | reward=1.0 | episode_steps=779 | hours=0.017 | epsilon=0.139
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:41 PM > ep 1039 done. total_steps=62893 | reward=1.0 | episode_steps=278 | hours=0.017 | epsilon=0.139
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:41 PM > ep 1040 done. total_steps=63056 | reward=1.0 | episode_steps=163 | hours=0.018 | epsilon=0.138
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:41 PM > ep 1041 done. total_steps=63102 | reward=1.0 | episode_steps=46 | hours=0.018 | epsilon=0.138
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:41 PM > ep 1042 done. total_steps=63124 | reward=1.0 | episode_steps=22 | hours=0.018 | epsilon=0.138
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:41 PM > ep 1043 done. total_steps=63183 | reward=1.0 | episode_steps=59 | hours=0.018 | epsilon=0.138
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:41 PM > ep 1044 done. total_steps=63198 | reward=1.0 | episode_steps=15 | hours=0.018 | epsilon=0.138
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:41 PM > ep 1045 done. total_steps=63491 | reward=1.0 | episode_steps=293 | hours=0.018 | epsilon=0.138
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:41 PM > ep 1046 done. total_steps=63538 | reward=1.0 | episode_steps=47 | hours=0.018 | epsilon=0.138
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:41 PM > ep 1047 done. total_steps=63552 | reward=1.0 | episode_steps=14 | hours=0.018 | epsilon=0.138
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:41 PM > ep 1048 done. total_steps=63759 | reward=1.0 | episode_steps=207 | hours=0.018 | epsilon=0.137
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:41 PM > ep 1049 done. total_steps=63841 | reward=1.0 | episode_steps=82 | hours=0.018 | epsilon=0.137
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:42 PM > ep 1050 done. total_steps=64095 | reward=1.0 | episode_steps=254 | hours=0.018 | epsilon=0.137
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:42 PM > ep 1051 done. total_steps=64154 | reward=1.0 | episode_steps=59 | hours=0.018 | epsilon=0.136
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:42 PM > ep 1052 done. total_steps=64346 | reward=1.0 | episode_steps=192 | hours=0.018 | epsilon=0.136
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:42 PM > ep 1053 done. total_steps=64524 | reward=1.0 | episode_steps=178 | hours=0.018 | epsilon=0.136
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:42 PM > ep 1054 done. total_steps=64527 | reward=1.0 | episode_steps=3 | hours=0.018 | epsilon=0.136
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:42 PM > ep 1055 done. total_steps=64590 | reward=1.0 | episode_steps=63 | hours=0.018 | epsilon=0.136
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:42 PM > ep 1056 done. total_steps=65224 | reward=1.0 | episode_steps=634 | hours=0.018 | epsilon=0.135
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:43 PM > ep 1057 done. total_steps=65393 | reward=1.0 | episode_steps=169 | hours=0.018 | epsilon=0.134
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:43 PM > ep 1058 done. total_steps=65491 | reward=1.0 | episode_steps=98 | hours=0.018 | epsilon=0.134
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:43 PM > ep 1059 done. total_steps=65622 | reward=1.0 | episode_steps=131 | hours=0.018 | epsilon=0.134
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:43 PM > ep 1060 done. total_steps=65636 | reward=1.0 | episode_steps=14 | hours=0.018 | epsilon=0.134
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:43 PM > ep 1061 done. total_steps=65637 | reward=1.0 | episode_steps=1 | hours=0.018 | epsilon=0.134
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:43 PM > ep 1062 done. total_steps=65707 | reward=1.0 | episode_steps=70 | hours=0.018 | epsilon=0.134
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:43 PM > ep 1063 done. total_steps=65802 | reward=1.0 | episode_steps=95 | hours=0.018 | epsilon=0.134
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:43 PM > ep 1064 done. total_steps=65944 | reward=1.0 | episode_steps=142 | hours=0.018 | epsilon=0.133
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:43 PM > ep 1065 done. total_steps=66091 | reward=1.0 | episode_steps=147 | hours=0.018 | epsilon=0.133
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:43 PM > ep 1066 done. total_steps=66134 | reward=1.0 | episode_steps=43 | hours=0.018 | epsilon=0.133
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:43 PM > ep 1067 done. total_steps=66212 | reward=1.0 | episode_steps=78 | hours=0.018 | epsilon=0.133
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:43 PM > ep 1068 done. total_steps=66237 | reward=1.0 | episode_steps=25 | hours=0.018 | epsilon=0.133
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:43 PM > ep 1069 done. total_steps=66239 | reward=1.0 | episode_steps=2 | hours=0.018 | epsilon=0.133
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:43 PM > ep 1070 done. total_steps=66270 | reward=1.0 | episode_steps=31 | hours=0.018 | epsilon=0.133
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:43 PM > ep 1071 done. total_steps=66381 | reward=1.0 | episode_steps=111 | hours=0.018 | epsilon=0.133
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:43 PM > ep 1072 done. total_steps=66389 | reward=1.0 | episode_steps=8 | hours=0.018 | epsilon=0.133
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:43 PM > ep 1073 done. total_steps=66433 | reward=1.0 | episode_steps=44 | hours=0.018 | epsilon=0.132
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:43 PM > ep 1074 done. total_steps=66437 | reward=1.0 | episode_steps=4 | hours=0.018 | epsilon=0.132
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:43 PM > ep 1075 done. total_steps=66453 | reward=1.0 | episode_steps=16 | hours=0.018 | epsilon=0.132
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:43 PM > ep 1076 done. total_steps=66509 | reward=1.0 | episode_steps=56 | hours=0.018 | epsilon=0.132
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:43 PM > ep 1077 done. total_steps=66617 | reward=1.0 | episode_steps=108 | hours=0.019 | epsilon=0.132
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:44 PM > ep 1078 done. total_steps=66639 | reward=1.0 | episode_steps=22 | hours=0.019 | epsilon=0.132
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:44 PM > ep 1079 done. total_steps=66688 | reward=1.0 | episode_steps=49 | hours=0.019 | epsilon=0.132
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:44 PM > ep 1080 done. total_steps=66742 | reward=1.0 | episode_steps=54 | hours=0.019 | epsilon=0.132
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:44 PM > ep 1081 done. total_steps=66927 | reward=1.0 | episode_steps=185 | hours=0.019 | epsilon=0.132
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:44 PM > ep 1082 done. total_steps=66970 | reward=1.0 | episode_steps=43 | hours=0.019 | epsilon=0.132
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:44 PM > ep 1083 done. total_steps=66972 | reward=1.0 | episode_steps=2 | hours=0.019 | epsilon=0.132
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:44 PM > ep 1084 done. total_steps=67014 | reward=1.0 | episode_steps=42 | hours=0.019 | epsilon=0.132
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:44 PM > ep 1085 done. total_steps=67018 | reward=1.0 | episode_steps=4 | hours=0.019 | epsilon=0.132
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:44 PM > ep 1086 done. total_steps=67020 | reward=1.0 | episode_steps=2 | hours=0.019 | epsilon=0.132
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:44 PM > ep 1087 done. total_steps=67032 | reward=1.0 | episode_steps=12 | hours=0.019 | epsilon=0.132
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:44 PM > ep 1088 done. total_steps=67057 | reward=1.0 | episode_steps=25 | hours=0.019 | epsilon=0.131
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:44 PM > ep 1089 done. total_steps=67063 | reward=1.0 | episode_steps=6 | hours=0.019 | epsilon=0.131
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:44 PM > ep 1090 done. total_steps=67205 | reward=1.0 | episode_steps=142 | hours=0.019 | epsilon=0.131
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:44 PM > ep 1091 done. total_steps=67233 | reward=1.0 | episode_steps=28 | hours=0.019 | epsilon=0.131
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:44 PM > ep 1092 done. total_steps=67333 | reward=1.0 | episode_steps=100 | hours=0.019 | epsilon=0.131
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:44 PM > ep 1093 done. total_steps=67487 | reward=1.0 | episode_steps=154 | hours=0.019 | epsilon=0.131
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:44 PM > ep 1094 done. total_steps=67491 | reward=1.0 | episode_steps=4 | hours=0.019 | epsilon=0.131
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:44 PM > ep 1095 done. total_steps=67517 | reward=1.0 | episode_steps=26 | hours=0.019 | epsilon=0.131
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:44 PM > ep 1096 done. total_steps=67528 | reward=1.0 | episode_steps=11 | hours=0.019 | epsilon=0.131
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:44 PM > ep 1097 done. total_steps=67606 | reward=1.0 | episode_steps=78 | hours=0.019 | epsilon=0.131
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:44 PM > ep 1098 done. total_steps=67711 | reward=1.0 | episode_steps=105 | hours=0.019 | epsilon=0.130
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:44 PM > ep 1099 done. total_steps=67738 | reward=1.0 | episode_steps=27 | hours=0.019 | epsilon=0.130
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:44 PM > ep 1100 done. total_steps=67779 | reward=1.0 | episode_steps=41 | hours=0.019 | epsilon=0.130
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:44 PM > ep 1101 done. total_steps=67791 | reward=1.0 | episode_steps=12 | hours=0.019 | epsilon=0.130
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:44 PM > ep 1102 done. total_steps=67815 | reward=1.0 | episode_steps=24 | hours=0.019 | epsilon=0.130
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:44 PM > ep 1103 done. total_steps=67842 | reward=1.0 | episode_steps=27 | hours=0.019 | epsilon=0.130
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:44 PM > ep 1104 done. total_steps=67880 | reward=1.0 | episode_steps=38 | hours=0.019 | epsilon=0.130
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:45 PM > ep 1105 done. total_steps=67942 | reward=1.0 | episode_steps=62 | hours=0.019 | epsilon=0.130
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:45 PM > ep 1106 done. total_steps=67962 | reward=1.0 | episode_steps=20 | hours=0.019 | epsilon=0.130
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:45 PM > ep 1107 done. total_steps=67992 | reward=1.0 | episode_steps=30 | hours=0.019 | epsilon=0.130
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:45 PM > ep 1108 done. total_steps=68024 | reward=1.0 | episode_steps=32 | hours=0.019 | epsilon=0.130
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:45 PM > ep 1109 done. total_steps=68052 | reward=1.0 | episode_steps=28 | hours=0.019 | epsilon=0.130
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:45 PM > ep 1110 done. total_steps=68057 | reward=1.0 | episode_steps=5 | hours=0.019 | epsilon=0.130
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:45 PM > ep 1111 done. total_steps=68083 | reward=1.0 | episode_steps=26 | hours=0.019 | epsilon=0.130
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:45 PM > ep 1112 done. total_steps=68194 | reward=1.0 | episode_steps=111 | hours=0.019 | epsilon=0.130
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:45 PM > ep 1113 done. total_steps=68260 | reward=1.0 | episode_steps=66 | hours=0.019 | epsilon=0.130
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:45 PM > ep 1114 done. total_steps=68277 | reward=1.0 | episode_steps=17 | hours=0.019 | epsilon=0.130
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:45 PM > ep 1115 done. total_steps=68364 | reward=1.0 | episode_steps=87 | hours=0.019 | epsilon=0.129
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:45 PM > ep 1116 done. total_steps=68499 | reward=1.0 | episode_steps=135 | hours=0.019 | epsilon=0.129
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:45 PM > ep 1117 done. total_steps=68599 | reward=1.0 | episode_steps=100 | hours=0.019 | epsilon=0.129
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:45 PM > ep 1118 done. total_steps=68627 | reward=1.0 | episode_steps=28 | hours=0.019 | epsilon=0.129
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:45 PM > ep 1119 done. total_steps=68670 | reward=1.0 | episode_steps=43 | hours=0.019 | epsilon=0.129
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:45 PM > ep 1120 done. total_steps=68740 | reward=1.0 | episode_steps=70 | hours=0.019 | epsilon=0.129
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:45 PM > ep 1121 done. total_steps=68749 | reward=1.0 | episode_steps=9 | hours=0.019 | epsilon=0.129
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:45 PM > ep 1122 done. total_steps=68763 | reward=1.0 | episode_steps=14 | hours=0.019 | epsilon=0.129
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:45 PM > ep 1123 done. total_steps=68815 | reward=1.0 | episode_steps=52 | hours=0.019 | epsilon=0.129
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:45 PM > ep 1124 done. total_steps=68823 | reward=1.0 | episode_steps=8 | hours=0.019 | epsilon=0.129
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:45 PM > ep 1125 done. total_steps=68861 | reward=1.0 | episode_steps=38 | hours=0.019 | epsilon=0.129
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:45 PM > ep 1126 done. total_steps=68893 | reward=1.0 | episode_steps=32 | hours=0.019 | epsilon=0.129
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:45 PM > ep 1127 done. total_steps=68921 | reward=1.0 | episode_steps=28 | hours=0.019 | epsilon=0.129
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:45 PM > ep 1128 done. total_steps=68939 | reward=1.0 | episode_steps=18 | hours=0.019 | epsilon=0.129
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:45 PM > ep 1129 done. total_steps=68956 | reward=1.0 | episode_steps=17 | hours=0.019 | epsilon=0.129
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:45 PM > ep 1130 done. total_steps=68980 | reward=1.0 | episode_steps=24 | hours=0.019 | epsilon=0.129
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:45 PM > ep 1131 done. total_steps=69039 | reward=1.0 | episode_steps=59 | hours=0.019 | epsilon=0.129
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:45 PM > ep 1132 done. total_steps=69062 | reward=1.0 | episode_steps=23 | hours=0.019 | epsilon=0.128
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:45 PM > ep 1133 done. total_steps=69087 | reward=1.0 | episode_steps=25 | hours=0.019 | epsilon=0.128
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:45 PM > ep 1134 done. total_steps=69111 | reward=1.0 | episode_steps=24 | hours=0.019 | epsilon=0.128
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:45 PM > ep 1135 done. total_steps=69211 | reward=1.0 | episode_steps=100 | hours=0.019 | epsilon=0.128
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:45 PM > ep 1136 done. total_steps=69233 | reward=1.0 | episode_steps=22 | hours=0.019 | epsilon=0.128
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:45 PM > ep 1137 done. total_steps=69235 | reward=1.0 | episode_steps=2 | hours=0.019 | epsilon=0.128
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:45 PM > ep 1138 done. total_steps=69247 | reward=1.0 | episode_steps=12 | hours=0.019 | epsilon=0.128
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:46 PM > ep 1139 done. total_steps=69285 | reward=1.0 | episode_steps=38 | hours=0.019 | epsilon=0.128
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:46 PM > ep 1140 done. total_steps=69427 | reward=1.0 | episode_steps=142 | hours=0.019 | epsilon=0.128
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:46 PM > ep 1141 done. total_steps=69632 | reward=1.0 | episode_steps=205 | hours=0.019 | epsilon=0.128
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:46 PM > ep 1142 done. total_steps=69762 | reward=1.0 | episode_steps=130 | hours=0.019 | epsilon=0.128
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:46 PM > ep 1143 done. total_steps=69824 | reward=1.0 | episode_steps=62 | hours=0.019 | epsilon=0.127
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:46 PM > ep 1144 done. total_steps=69879 | reward=1.0 | episode_steps=55 | hours=0.019 | epsilon=0.127
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:46 PM > ep 1145 done. total_steps=69958 | reward=1.0 | episode_steps=79 | hours=0.019 | epsilon=0.127
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:46 PM > ep 1146 done. total_steps=70368 | reward=1.0 | episode_steps=410 | hours=0.020 | epsilon=0.127
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:46 PM > ep 1147 done. total_steps=70426 | reward=1.0 | episode_steps=58 | hours=0.020 | epsilon=0.127
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:46 PM > ep 1148 done. total_steps=70445 | reward=1.0 | episode_steps=19 | hours=0.020 | epsilon=0.127
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:46 PM > ep 1149 done. total_steps=70455 | reward=1.0 | episode_steps=10 | hours=0.020 | epsilon=0.127
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:46 PM > ep 1150 done. total_steps=70475 | reward=1.0 | episode_steps=20 | hours=0.020 | epsilon=0.127
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:46 PM > ep 1151 done. total_steps=70511 | reward=1.0 | episode_steps=36 | hours=0.020 | epsilon=0.126
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:46 PM > ep 1152 done. total_steps=70550 | reward=1.0 | episode_steps=39 | hours=0.020 | epsilon=0.126
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:46 PM > ep 1153 done. total_steps=70574 | reward=1.0 | episode_steps=24 | hours=0.020 | epsilon=0.126
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:47 PM > ep 1154 done. total_steps=70687 | reward=1.0 | episode_steps=113 | hours=0.020 | epsilon=0.126
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:47 PM > ep 1155 done. total_steps=70721 | reward=1.0 | episode_steps=34 | hours=0.020 | epsilon=0.126
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:47 PM > ep 1156 done. total_steps=70731 | reward=1.0 | episode_steps=10 | hours=0.020 | epsilon=0.126
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:47 PM > ep 1157 done. total_steps=70736 | reward=1.0 | episode_steps=5 | hours=0.020 | epsilon=0.126
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:47 PM > ep 1158 done. total_steps=70749 | reward=1.0 | episode_steps=13 | hours=0.020 | epsilon=0.126
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:47 PM > ep 1159 done. total_steps=70831 | reward=1.0 | episode_steps=82 | hours=0.020 | epsilon=0.126
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:47 PM > ep 1160 done. total_steps=70875 | reward=1.0 | episode_steps=44 | hours=0.020 | epsilon=0.126
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:47 PM > ep 1161 done. total_steps=70877 | reward=1.0 | episode_steps=2 | hours=0.020 | epsilon=0.126
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:47 PM > ep 1162 done. total_steps=71057 | reward=1.0 | episode_steps=180 | hours=0.020 | epsilon=0.126
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:47 PM > ep 1163 done. total_steps=71116 | reward=1.0 | episode_steps=59 | hours=0.020 | epsilon=0.126
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:47 PM > ep 1164 done. total_steps=71155 | reward=1.0 | episode_steps=39 | hours=0.020 | epsilon=0.126
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:47 PM > ep 1165 done. total_steps=71161 | reward=1.0 | episode_steps=6 | hours=0.020 | epsilon=0.126
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:47 PM > ep 1166 done. total_steps=71215 | reward=1.0 | episode_steps=54 | hours=0.020 | epsilon=0.126
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:47 PM > ep 1167 done. total_steps=71300 | reward=1.0 | episode_steps=85 | hours=0.020 | epsilon=0.125
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:47 PM > ep 1168 done. total_steps=71343 | reward=1.0 | episode_steps=43 | hours=0.020 | epsilon=0.125
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:47 PM > ep 1169 done. total_steps=71390 | reward=1.0 | episode_steps=47 | hours=0.020 | epsilon=0.125
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:47 PM > ep 1170 done. total_steps=71402 | reward=1.0 | episode_steps=12 | hours=0.020 | epsilon=0.125
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:47 PM > ep 1171 done. total_steps=71421 | reward=1.0 | episode_steps=19 | hours=0.020 | epsilon=0.125
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:47 PM > ep 1172 done. total_steps=71438 | reward=1.0 | episode_steps=17 | hours=0.020 | epsilon=0.125
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:47 PM > ep 1173 done. total_steps=71458 | reward=1.0 | episode_steps=20 | hours=0.020 | epsilon=0.125
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:47 PM > ep 1174 done. total_steps=71462 | reward=1.0 | episode_steps=4 | hours=0.020 | epsilon=0.125
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:47 PM > ep 1175 done. total_steps=71471 | reward=1.0 | episode_steps=9 | hours=0.020 | epsilon=0.125
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:47 PM > ep 1176 done. total_steps=71480 | reward=1.0 | episode_steps=9 | hours=0.020 | epsilon=0.125
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:47 PM > ep 1177 done. total_steps=71490 | reward=1.0 | episode_steps=10 | hours=0.020 | epsilon=0.125
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:47 PM > ep 1178 done. total_steps=71492 | reward=1.0 | episode_steps=2 | hours=0.020 | epsilon=0.125
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:47 PM > ep 1179 done. total_steps=71505 | reward=1.0 | episode_steps=13 | hours=0.020 | epsilon=0.125
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:47 PM > ep 1180 done. total_steps=71532 | reward=1.0 | episode_steps=27 | hours=0.020 | epsilon=0.125
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:47 PM > ep 1181 done. total_steps=71564 | reward=1.0 | episode_steps=32 | hours=0.020 | epsilon=0.125
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:47 PM > ep 1182 done. total_steps=71603 | reward=1.0 | episode_steps=39 | hours=0.020 | epsilon=0.125
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:47 PM > ep 1183 done. total_steps=71697 | reward=1.0 | episode_steps=94 | hours=0.020 | epsilon=0.125
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:47 PM > ep 1184 done. total_steps=71738 | reward=1.0 | episode_steps=41 | hours=0.020 | epsilon=0.125
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:47 PM > ep 1185 done. total_steps=71763 | reward=1.0 | episode_steps=25 | hours=0.020 | epsilon=0.125
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:47 PM > ep 1186 done. total_steps=71765 | reward=1.0 | episode_steps=2 | hours=0.020 | epsilon=0.125
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:47 PM > ep 1187 done. total_steps=71778 | reward=1.0 | episode_steps=13 | hours=0.020 | epsilon=0.125
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:47 PM > ep 1188 done. total_steps=71804 | reward=1.0 | episode_steps=26 | hours=0.020 | epsilon=0.125
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:47 PM > ep 1189 done. total_steps=71828 | reward=1.0 | episode_steps=24 | hours=0.020 | epsilon=0.125
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:47 PM > ep 1190 done. total_steps=71837 | reward=1.0 | episode_steps=9 | hours=0.020 | epsilon=0.125
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:47 PM > ep 1191 done. total_steps=71844 | reward=1.0 | episode_steps=7 | hours=0.020 | epsilon=0.125
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:47 PM > ep 1192 done. total_steps=71868 | reward=1.0 | episode_steps=24 | hours=0.020 | epsilon=0.125
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:48 PM > ep 1193 done. total_steps=71943 | reward=1.0 | episode_steps=75 | hours=0.020 | epsilon=0.125
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:48 PM > ep 1194 done. total_steps=72012 | reward=1.0 | episode_steps=69 | hours=0.020 | epsilon=0.125
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:48 PM > ep 1195 done. total_steps=72025 | reward=1.0 | episode_steps=13 | hours=0.020 | epsilon=0.125
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:48 PM > ep 1196 done. total_steps=72040 | reward=1.0 | episode_steps=15 | hours=0.020 | epsilon=0.125
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:48 PM > ep 1197 done. total_steps=72065 | reward=1.0 | episode_steps=25 | hours=0.020 | epsilon=0.125
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:48 PM > ep 1198 done. total_steps=72108 | reward=1.0 | episode_steps=43 | hours=0.020 | epsilon=0.124
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:48 PM > ep 1199 done. total_steps=72170 | reward=1.0 | episode_steps=62 | hours=0.020 | epsilon=0.124
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:48 PM > ep 1200 done. total_steps=72303 | reward=1.0 | episode_steps=133 | hours=0.020 | epsilon=0.124
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:48 PM > ep 1201 done. total_steps=72309 | reward=1.0 | episode_steps=6 | hours=0.020 | epsilon=0.124
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:48 PM > ep 1202 done. total_steps=72316 | reward=1.0 | episode_steps=7 | hours=0.020 | epsilon=0.124
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:48 PM > ep 1203 done. total_steps=72373 | reward=1.0 | episode_steps=57 | hours=0.020 | epsilon=0.124
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:48 PM > ep 1204 done. total_steps=72378 | reward=1.0 | episode_steps=5 | hours=0.020 | epsilon=0.124
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:48 PM > ep 1205 done. total_steps=72387 | reward=1.0 | episode_steps=9 | hours=0.020 | epsilon=0.124
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:48 PM > ep 1206 done. total_steps=72397 | reward=1.0 | episode_steps=10 | hours=0.020 | epsilon=0.124
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:48 PM > ep 1207 done. total_steps=72418 | reward=1.0 | episode_steps=21 | hours=0.020 | epsilon=0.124
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:48 PM > ep 1208 done. total_steps=72431 | reward=1.0 | episode_steps=13 | hours=0.020 | epsilon=0.124
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:48 PM > ep 1209 done. total_steps=72437 | reward=1.0 | episode_steps=6 | hours=0.020 | epsilon=0.124
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:48 PM > ep 1210 done. total_steps=72588 | reward=1.0 | episode_steps=151 | hours=0.020 | epsilon=0.124
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:48 PM > ep 1211 done. total_steps=72599 | reward=1.0 | episode_steps=11 | hours=0.020 | epsilon=0.124
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:48 PM > ep 1212 done. total_steps=72894 | reward=1.0 | episode_steps=295 | hours=0.020 | epsilon=0.124
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:48 PM > ep 1213 done. total_steps=72909 | reward=1.0 | episode_steps=15 | hours=0.020 | epsilon=0.123
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:48 PM > ep 1214 done. total_steps=72956 | reward=1.0 | episode_steps=47 | hours=0.020 | epsilon=0.123
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:48 PM > ep 1215 done. total_steps=72979 | reward=1.0 | episode_steps=23 | hours=0.020 | epsilon=0.123
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:48 PM > ep 1216 done. total_steps=72984 | reward=1.0 | episode_steps=5 | hours=0.020 | epsilon=0.123
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:48 PM > ep 1217 done. total_steps=72992 | reward=1.0 | episode_steps=8 | hours=0.020 | epsilon=0.123
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:48 PM > ep 1218 done. total_steps=72994 | reward=1.0 | episode_steps=2 | hours=0.020 | epsilon=0.123
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:48 PM > ep 1219 done. total_steps=73003 | reward=1.0 | episode_steps=9 | hours=0.020 | epsilon=0.123
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:48 PM > ep 1220 done. total_steps=73047 | reward=1.0 | episode_steps=44 | hours=0.020 | epsilon=0.123
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:48 PM > ep 1221 done. total_steps=73055 | reward=1.0 | episode_steps=8 | hours=0.020 | epsilon=0.123
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:48 PM > ep 1222 done. total_steps=73059 | reward=1.0 | episode_steps=4 | hours=0.020 | epsilon=0.123
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:48 PM > ep 1223 done. total_steps=73074 | reward=1.0 | episode_steps=15 | hours=0.020 | epsilon=0.123
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:48 PM > ep 1224 done. total_steps=73075 | reward=1.0 | episode_steps=1 | hours=0.020 | epsilon=0.123
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:48 PM > ep 1225 done. total_steps=73081 | reward=1.0 | episode_steps=6 | hours=0.020 | epsilon=0.123
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:48 PM > ep 1226 done. total_steps=73088 | reward=1.0 | episode_steps=7 | hours=0.020 | epsilon=0.123
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:48 PM > ep 1227 done. total_steps=73138 | reward=1.0 | episode_steps=50 | hours=0.020 | epsilon=0.123
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:48 PM > ep 1228 done. total_steps=73174 | reward=1.0 | episode_steps=36 | hours=0.020 | epsilon=0.123
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:48 PM > ep 1229 done. total_steps=73255 | reward=1.0 | episode_steps=81 | hours=0.020 | epsilon=0.123
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:49 PM > ep 1230 done. total_steps=73302 | reward=1.0 | episode_steps=47 | hours=0.020 | epsilon=0.123
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:49 PM > ep 1231 done. total_steps=73325 | reward=1.0 | episode_steps=23 | hours=0.020 | epsilon=0.123
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:49 PM > ep 1232 done. total_steps=73350 | reward=1.0 | episode_steps=25 | hours=0.020 | epsilon=0.123
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:49 PM > ep 1233 done. total_steps=73383 | reward=1.0 | episode_steps=33 | hours=0.020 | epsilon=0.123
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:49 PM > ep 1234 done. total_steps=73391 | reward=1.0 | episode_steps=8 | hours=0.020 | epsilon=0.123
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:49 PM > ep 1235 done. total_steps=73423 | reward=1.0 | episode_steps=32 | hours=0.020 | epsilon=0.123
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:49 PM > ep 1236 done. total_steps=73433 | reward=1.0 | episode_steps=10 | hours=0.020 | epsilon=0.123
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:49 PM > ep 1237 done. total_steps=73451 | reward=1.0 | episode_steps=18 | hours=0.020 | epsilon=0.123
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:49 PM > ep 1238 done. total_steps=73515 | reward=1.0 | episode_steps=64 | hours=0.020 | epsilon=0.123
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:49 PM > ep 1239 done. total_steps=73524 | reward=1.0 | episode_steps=9 | hours=0.020 | epsilon=0.123
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:49 PM > ep 1240 done. total_steps=73541 | reward=1.0 | episode_steps=17 | hours=0.020 | epsilon=0.123
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:49 PM > ep 1241 done. total_steps=73629 | reward=1.0 | episode_steps=88 | hours=0.020 | epsilon=0.123
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:49 PM > ep 1242 done. total_steps=73711 | reward=1.0 | episode_steps=82 | hours=0.020 | epsilon=0.123
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:49 PM > ep 1243 done. total_steps=73721 | reward=1.0 | episode_steps=10 | hours=0.020 | epsilon=0.123
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:49 PM > ep 1244 done. total_steps=73724 | reward=1.0 | episode_steps=3 | hours=0.020 | epsilon=0.123
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:49 PM > ep 1245 done. total_steps=73731 | reward=1.0 | episode_steps=7 | hours=0.020 | epsilon=0.123
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:49 PM > ep 1246 done. total_steps=73742 | reward=1.0 | episode_steps=11 | hours=0.020 | epsilon=0.123
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:49 PM > ep 1247 done. total_steps=73804 | reward=1.0 | episode_steps=62 | hours=0.021 | epsilon=0.122
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:49 PM > ep 1248 done. total_steps=73888 | reward=1.0 | episode_steps=84 | hours=0.021 | epsilon=0.122
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:49 PM > ep 1249 done. total_steps=73904 | reward=1.0 | episode_steps=16 | hours=0.021 | epsilon=0.122
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:49 PM > ep 1250 done. total_steps=73936 | reward=1.0 | episode_steps=32 | hours=0.021 | epsilon=0.122
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:49 PM > ep 1251 done. total_steps=73947 | reward=1.0 | episode_steps=11 | hours=0.021 | epsilon=0.122
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:49 PM > ep 1252 done. total_steps=73949 | reward=1.0 | episode_steps=2 | hours=0.021 | epsilon=0.122
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:49 PM > ep 1253 done. total_steps=73962 | reward=1.0 | episode_steps=13 | hours=0.021 | epsilon=0.122
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:49 PM > ep 1254 done. total_steps=74005 | reward=1.0 | episode_steps=43 | hours=0.021 | epsilon=0.122
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:49 PM > ep 1255 done. total_steps=74013 | reward=1.0 | episode_steps=8 | hours=0.021 | epsilon=0.122
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:49 PM > ep 1256 done. total_steps=74062 | reward=1.0 | episode_steps=49 | hours=0.021 | epsilon=0.122
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:49 PM > ep 1257 done. total_steps=74071 | reward=1.0 | episode_steps=9 | hours=0.021 | epsilon=0.122
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:49 PM > ep 1258 done. total_steps=74126 | reward=1.0 | episode_steps=55 | hours=0.021 | epsilon=0.122
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:49 PM > ep 1259 done. total_steps=74137 | reward=1.0 | episode_steps=11 | hours=0.021 | epsilon=0.122
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:49 PM > ep 1260 done. total_steps=74145 | reward=1.0 | episode_steps=8 | hours=0.021 | epsilon=0.122
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:49 PM > ep 1261 done. total_steps=74200 | reward=1.0 | episode_steps=55 | hours=0.021 | epsilon=0.122
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:49 PM > ep 1262 done. total_steps=74212 | reward=1.0 | episode_steps=12 | hours=0.021 | epsilon=0.122
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:49 PM > ep 1263 done. total_steps=74238 | reward=1.0 | episode_steps=26 | hours=0.021 | epsilon=0.122
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:49 PM > ep 1264 done. total_steps=74256 | reward=1.0 | episode_steps=18 | hours=0.021 | epsilon=0.122
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:49 PM > ep 1265 done. total_steps=74281 | reward=1.0 | episode_steps=25 | hours=0.021 | epsilon=0.122
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:49 PM > ep 1266 done. total_steps=74285 | reward=1.0 | episode_steps=4 | hours=0.021 | epsilon=0.122
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:49 PM > ep 1267 done. total_steps=74311 | reward=1.0 | episode_steps=26 | hours=0.021 | epsilon=0.122
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:49 PM > ep 1268 done. total_steps=74411 | reward=1.0 | episode_steps=100 | hours=0.021 | epsilon=0.122
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:49 PM > ep 1269 done. total_steps=74429 | reward=1.0 | episode_steps=18 | hours=0.021 | epsilon=0.122
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:49 PM > ep 1270 done. total_steps=74462 | reward=1.0 | episode_steps=33 | hours=0.021 | epsilon=0.122
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:49 PM > ep 1271 done. total_steps=74505 | reward=1.0 | episode_steps=43 | hours=0.021 | epsilon=0.122
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:49 PM > ep 1272 done. total_steps=74515 | reward=1.0 | episode_steps=10 | hours=0.021 | epsilon=0.122
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:49 PM > ep 1273 done. total_steps=74525 | reward=1.0 | episode_steps=10 | hours=0.021 | epsilon=0.122
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:49 PM > ep 1274 done. total_steps=74539 | reward=1.0 | episode_steps=14 | hours=0.021 | epsilon=0.122
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:49 PM > ep 1275 done. total_steps=74557 | reward=1.0 | episode_steps=18 | hours=0.021 | epsilon=0.122
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:49 PM > ep 1276 done. total_steps=74584 | reward=1.0 | episode_steps=27 | hours=0.021 | epsilon=0.122
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1277 done. total_steps=74599 | reward=1.0 | episode_steps=15 | hours=0.021 | epsilon=0.122
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1278 done. total_steps=74645 | reward=1.0 | episode_steps=46 | hours=0.021 | epsilon=0.122
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1279 done. total_steps=74667 | reward=1.0 | episode_steps=22 | hours=0.021 | epsilon=0.122
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1280 done. total_steps=74676 | reward=1.0 | episode_steps=9 | hours=0.021 | epsilon=0.122
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1281 done. total_steps=74686 | reward=1.0 | episode_steps=10 | hours=0.021 | epsilon=0.122
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1282 done. total_steps=74695 | reward=1.0 | episode_steps=9 | hours=0.021 | epsilon=0.121
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1283 done. total_steps=74700 | reward=1.0 | episode_steps=5 | hours=0.021 | epsilon=0.121
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1284 done. total_steps=74706 | reward=1.0 | episode_steps=6 | hours=0.021 | epsilon=0.121
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1285 done. total_steps=74735 | reward=1.0 | episode_steps=29 | hours=0.021 | epsilon=0.121
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1286 done. total_steps=74739 | reward=1.0 | episode_steps=4 | hours=0.021 | epsilon=0.121
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1287 done. total_steps=74750 | reward=1.0 | episode_steps=11 | hours=0.021 | epsilon=0.121
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1288 done. total_steps=74753 | reward=1.0 | episode_steps=3 | hours=0.021 | epsilon=0.121
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1289 done. total_steps=74768 | reward=1.0 | episode_steps=15 | hours=0.021 | epsilon=0.121
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1290 done. total_steps=74864 | reward=1.0 | episode_steps=96 | hours=0.021 | epsilon=0.121
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1291 done. total_steps=74884 | reward=1.0 | episode_steps=20 | hours=0.021 | epsilon=0.121
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1292 done. total_steps=74902 | reward=1.0 | episode_steps=18 | hours=0.021 | epsilon=0.121
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1293 done. total_steps=74903 | reward=1.0 | episode_steps=1 | hours=0.021 | epsilon=0.121
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1294 done. total_steps=74926 | reward=1.0 | episode_steps=23 | hours=0.021 | epsilon=0.121
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1295 done. total_steps=74928 | reward=1.0 | episode_steps=2 | hours=0.021 | epsilon=0.121
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1296 done. total_steps=74966 | reward=1.0 | episode_steps=38 | hours=0.021 | epsilon=0.121
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1297 done. total_steps=74982 | reward=1.0 | episode_steps=16 | hours=0.021 | epsilon=0.121
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1298 done. total_steps=74989 | reward=1.0 | episode_steps=7 | hours=0.021 | epsilon=0.121
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1299 done. total_steps=75013 | reward=1.0 | episode_steps=24 | hours=0.021 | epsilon=0.121
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1300 done. total_steps=75022 | reward=1.0 | episode_steps=9 | hours=0.021 | epsilon=0.121
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1301 done. total_steps=75038 | reward=1.0 | episode_steps=16 | hours=0.021 | epsilon=0.121
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1302 done. total_steps=75042 | reward=1.0 | episode_steps=4 | hours=0.021 | epsilon=0.121
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1303 done. total_steps=75057 | reward=1.0 | episode_steps=15 | hours=0.021 | epsilon=0.121
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1304 done. total_steps=75059 | reward=1.0 | episode_steps=2 | hours=0.021 | epsilon=0.121
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1305 done. total_steps=75071 | reward=1.0 | episode_steps=12 | hours=0.021 | epsilon=0.121
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1306 done. total_steps=75103 | reward=1.0 | episode_steps=32 | hours=0.021 | epsilon=0.121
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1307 done. total_steps=75110 | reward=1.0 | episode_steps=7 | hours=0.021 | epsilon=0.121
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1308 done. total_steps=75140 | reward=1.0 | episode_steps=30 | hours=0.021 | epsilon=0.121
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1309 done. total_steps=75176 | reward=1.0 | episode_steps=36 | hours=0.021 | epsilon=0.121
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1310 done. total_steps=75182 | reward=1.0 | episode_steps=6 | hours=0.021 | epsilon=0.121
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1311 done. total_steps=75204 | reward=1.0 | episode_steps=22 | hours=0.021 | epsilon=0.121
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1312 done. total_steps=75216 | reward=1.0 | episode_steps=12 | hours=0.021 | epsilon=0.121
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1313 done. total_steps=75234 | reward=1.0 | episode_steps=18 | hours=0.021 | epsilon=0.121
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1314 done. total_steps=75245 | reward=1.0 | episode_steps=11 | hours=0.021 | epsilon=0.121
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1315 done. total_steps=75249 | reward=1.0 | episode_steps=4 | hours=0.021 | epsilon=0.121
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1316 done. total_steps=75261 | reward=1.0 | episode_steps=12 | hours=0.021 | epsilon=0.121
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1317 done. total_steps=75273 | reward=1.0 | episode_steps=12 | hours=0.021 | epsilon=0.121
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1318 done. total_steps=75283 | reward=1.0 | episode_steps=10 | hours=0.021 | epsilon=0.121
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1319 done. total_steps=75299 | reward=1.0 | episode_steps=16 | hours=0.021 | epsilon=0.121
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1320 done. total_steps=75304 | reward=1.0 | episode_steps=5 | hours=0.021 | epsilon=0.121
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1321 done. total_steps=75309 | reward=1.0 | episode_steps=5 | hours=0.021 | epsilon=0.121
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1322 done. total_steps=75321 | reward=1.0 | episode_steps=12 | hours=0.021 | epsilon=0.121
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1323 done. total_steps=75342 | reward=1.0 | episode_steps=21 | hours=0.021 | epsilon=0.121
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1324 done. total_steps=75356 | reward=1.0 | episode_steps=14 | hours=0.021 | epsilon=0.121
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1325 done. total_steps=75374 | reward=1.0 | episode_steps=18 | hours=0.021 | epsilon=0.121
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1326 done. total_steps=75389 | reward=1.0 | episode_steps=15 | hours=0.021 | epsilon=0.121
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1327 done. total_steps=75413 | reward=1.0 | episode_steps=24 | hours=0.021 | epsilon=0.121
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1328 done. total_steps=75463 | reward=1.0 | episode_steps=50 | hours=0.021 | epsilon=0.121
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1329 done. total_steps=75465 | reward=1.0 | episode_steps=2 | hours=0.021 | epsilon=0.121
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1330 done. total_steps=75499 | reward=1.0 | episode_steps=34 | hours=0.021 | epsilon=0.121
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1331 done. total_steps=75513 | reward=1.0 | episode_steps=14 | hours=0.021 | epsilon=0.121
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1332 done. total_steps=75538 | reward=1.0 | episode_steps=25 | hours=0.021 | epsilon=0.121
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1333 done. total_steps=75544 | reward=1.0 | episode_steps=6 | hours=0.021 | epsilon=0.121
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1334 done. total_steps=75558 | reward=1.0 | episode_steps=14 | hours=0.021 | epsilon=0.121
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1335 done. total_steps=75586 | reward=1.0 | episode_steps=28 | hours=0.021 | epsilon=0.121
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1336 done. total_steps=75601 | reward=1.0 | episode_steps=15 | hours=0.021 | epsilon=0.121
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1337 done. total_steps=75609 | reward=1.0 | episode_steps=8 | hours=0.021 | epsilon=0.121
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1338 done. total_steps=75622 | reward=1.0 | episode_steps=13 | hours=0.021 | epsilon=0.121
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1339 done. total_steps=75657 | reward=1.0 | episode_steps=35 | hours=0.021 | epsilon=0.120
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1340 done. total_steps=75675 | reward=1.0 | episode_steps=18 | hours=0.021 | epsilon=0.120
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1341 done. total_steps=75701 | reward=1.0 | episode_steps=26 | hours=0.021 | epsilon=0.120
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1342 done. total_steps=75720 | reward=1.0 | episode_steps=19 | hours=0.021 | epsilon=0.120
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1343 done. total_steps=75737 | reward=1.0 | episode_steps=17 | hours=0.021 | epsilon=0.120
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1344 done. total_steps=75748 | reward=1.0 | episode_steps=11 | hours=0.021 | epsilon=0.120
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1345 done. total_steps=75764 | reward=1.0 | episode_steps=16 | hours=0.021 | epsilon=0.120
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1346 done. total_steps=75769 | reward=1.0 | episode_steps=5 | hours=0.021 | epsilon=0.120
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1347 done. total_steps=75779 | reward=1.0 | episode_steps=10 | hours=0.021 | epsilon=0.120
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1348 done. total_steps=75798 | reward=1.0 | episode_steps=19 | hours=0.021 | epsilon=0.120
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1349 done. total_steps=75804 | reward=1.0 | episode_steps=6 | hours=0.021 | epsilon=0.120
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1350 done. total_steps=75824 | reward=1.0 | episode_steps=20 | hours=0.021 | epsilon=0.120
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1351 done. total_steps=75836 | reward=1.0 | episode_steps=12 | hours=0.021 | epsilon=0.120
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1352 done. total_steps=75850 | reward=1.0 | episode_steps=14 | hours=0.021 | epsilon=0.120
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1353 done. total_steps=75869 | reward=1.0 | episode_steps=19 | hours=0.021 | epsilon=0.120
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:50 PM > ep 1354 done. total_steps=75876 | reward=1.0 | episode_steps=7 | hours=0.021 | epsilon=0.120
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1355 done. total_steps=75887 | reward=1.0 | episode_steps=11 | hours=0.021 | epsilon=0.120
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1356 done. total_steps=75906 | reward=1.0 | episode_steps=19 | hours=0.021 | epsilon=0.120
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1357 done. total_steps=75932 | reward=1.0 | episode_steps=26 | hours=0.021 | epsilon=0.120
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1358 done. total_steps=75949 | reward=1.0 | episode_steps=17 | hours=0.021 | epsilon=0.120
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1359 done. total_steps=75984 | reward=1.0 | episode_steps=35 | hours=0.021 | epsilon=0.120
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1360 done. total_steps=76004 | reward=1.0 | episode_steps=20 | hours=0.021 | epsilon=0.120
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1361 done. total_steps=76006 | reward=1.0 | episode_steps=2 | hours=0.021 | epsilon=0.120
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1362 done. total_steps=76043 | reward=1.0 | episode_steps=37 | hours=0.021 | epsilon=0.120
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1363 done. total_steps=76072 | reward=1.0 | episode_steps=29 | hours=0.021 | epsilon=0.120
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1364 done. total_steps=76082 | reward=1.0 | episode_steps=10 | hours=0.021 | epsilon=0.120
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1365 done. total_steps=76107 | reward=1.0 | episode_steps=25 | hours=0.021 | epsilon=0.120
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1366 done. total_steps=76122 | reward=1.0 | episode_steps=15 | hours=0.021 | epsilon=0.120
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1367 done. total_steps=76140 | reward=1.0 | episode_steps=18 | hours=0.021 | epsilon=0.120
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1368 done. total_steps=76145 | reward=1.0 | episode_steps=5 | hours=0.021 | epsilon=0.120
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1369 done. total_steps=76175 | reward=1.0 | episode_steps=30 | hours=0.021 | epsilon=0.120
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1370 done. total_steps=76194 | reward=1.0 | episode_steps=19 | hours=0.021 | epsilon=0.120
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1371 done. total_steps=76215 | reward=1.0 | episode_steps=21 | hours=0.021 | epsilon=0.120
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1372 done. total_steps=76231 | reward=1.0 | episode_steps=16 | hours=0.021 | epsilon=0.120
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1373 done. total_steps=76272 | reward=1.0 | episode_steps=41 | hours=0.021 | epsilon=0.120
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1374 done. total_steps=76314 | reward=1.0 | episode_steps=42 | hours=0.021 | epsilon=0.120
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1375 done. total_steps=76336 | reward=1.0 | episode_steps=22 | hours=0.021 | epsilon=0.120
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1376 done. total_steps=76351 | reward=1.0 | episode_steps=15 | hours=0.021 | epsilon=0.120
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1377 done. total_steps=76375 | reward=1.0 | episode_steps=24 | hours=0.021 | epsilon=0.120
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1378 done. total_steps=76418 | reward=1.0 | episode_steps=43 | hours=0.021 | epsilon=0.120
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1379 done. total_steps=76444 | reward=1.0 | episode_steps=26 | hours=0.021 | epsilon=0.120
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1380 done. total_steps=76462 | reward=1.0 | episode_steps=18 | hours=0.021 | epsilon=0.120
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1381 done. total_steps=76476 | reward=1.0 | episode_steps=14 | hours=0.021 | epsilon=0.120
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1382 done. total_steps=76489 | reward=1.0 | episode_steps=13 | hours=0.021 | epsilon=0.120
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1383 done. total_steps=76515 | reward=1.0 | episode_steps=26 | hours=0.021 | epsilon=0.120
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1384 done. total_steps=76518 | reward=1.0 | episode_steps=3 | hours=0.021 | epsilon=0.120
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1385 done. total_steps=76542 | reward=1.0 | episode_steps=24 | hours=0.021 | epsilon=0.120
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1386 done. total_steps=76548 | reward=1.0 | episode_steps=6 | hours=0.021 | epsilon=0.120
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1387 done. total_steps=76575 | reward=1.0 | episode_steps=27 | hours=0.021 | epsilon=0.120
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1388 done. total_steps=76598 | reward=1.0 | episode_steps=23 | hours=0.021 | epsilon=0.120
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1389 done. total_steps=76605 | reward=1.0 | episode_steps=7 | hours=0.021 | epsilon=0.120
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1390 done. total_steps=76635 | reward=1.0 | episode_steps=30 | hours=0.021 | epsilon=0.120
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1391 done. total_steps=76646 | reward=1.0 | episode_steps=11 | hours=0.021 | epsilon=0.119
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1392 done. total_steps=76664 | reward=1.0 | episode_steps=18 | hours=0.021 | epsilon=0.119
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1393 done. total_steps=76685 | reward=1.0 | episode_steps=21 | hours=0.021 | epsilon=0.119
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1394 done. total_steps=76694 | reward=1.0 | episode_steps=9 | hours=0.021 | epsilon=0.119
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1395 done. total_steps=76719 | reward=1.0 | episode_steps=25 | hours=0.021 | epsilon=0.119
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1396 done. total_steps=76722 | reward=1.0 | episode_steps=3 | hours=0.021 | epsilon=0.119
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1397 done. total_steps=76767 | reward=1.0 | episode_steps=45 | hours=0.021 | epsilon=0.119
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1398 done. total_steps=76775 | reward=1.0 | episode_steps=8 | hours=0.021 | epsilon=0.119
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1399 done. total_steps=76809 | reward=1.0 | episode_steps=34 | hours=0.021 | epsilon=0.119
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1400 done. total_steps=76867 | reward=1.0 | episode_steps=58 | hours=0.021 | epsilon=0.119
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1401 done. total_steps=76893 | reward=1.0 | episode_steps=26 | hours=0.021 | epsilon=0.119
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1402 done. total_steps=76954 | reward=1.0 | episode_steps=61 | hours=0.021 | epsilon=0.119
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1403 done. total_steps=76966 | reward=1.0 | episode_steps=12 | hours=0.021 | epsilon=0.119
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1404 done. total_steps=76994 | reward=1.0 | episode_steps=28 | hours=0.021 | epsilon=0.119
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1405 done. total_steps=76996 | reward=1.0 | episode_steps=2 | hours=0.021 | epsilon=0.119
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1406 done. total_steps=77013 | reward=1.0 | episode_steps=17 | hours=0.021 | epsilon=0.119
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1407 done. total_steps=77048 | reward=1.0 | episode_steps=35 | hours=0.021 | epsilon=0.119
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1408 done. total_steps=77049 | reward=1.0 | episode_steps=1 | hours=0.021 | epsilon=0.119
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1409 done. total_steps=77064 | reward=1.0 | episode_steps=15 | hours=0.021 | epsilon=0.119
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1410 done. total_steps=77070 | reward=1.0 | episode_steps=6 | hours=0.021 | epsilon=0.119
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1411 done. total_steps=77079 | reward=1.0 | episode_steps=9 | hours=0.021 | epsilon=0.119
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1412 done. total_steps=77110 | reward=1.0 | episode_steps=31 | hours=0.021 | epsilon=0.119
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1413 done. total_steps=77118 | reward=1.0 | episode_steps=8 | hours=0.021 | epsilon=0.119
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1414 done. total_steps=77135 | reward=1.0 | episode_steps=17 | hours=0.021 | epsilon=0.119
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1415 done. total_steps=77141 | reward=1.0 | episode_steps=6 | hours=0.021 | epsilon=0.119
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1416 done. total_steps=77174 | reward=1.0 | episode_steps=33 | hours=0.021 | epsilon=0.119
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:51 PM > ep 1417 done. total_steps=77192 | reward=1.0 | episode_steps=18 | hours=0.021 | epsilon=0.119
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:52 PM > ep 1418 done. total_steps=77234 | reward=1.0 | episode_steps=42 | hours=0.021 | epsilon=0.119
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:52 PM > ep 1419 done. total_steps=77261 | reward=1.0 | episode_steps=27 | hours=0.021 | epsilon=0.119
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:52 PM > ep 1420 done. total_steps=77299 | reward=1.0 | episode_steps=38 | hours=0.021 | epsilon=0.119
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:52 PM > ep 1421 done. total_steps=77314 | reward=1.0 | episode_steps=15 | hours=0.021 | epsilon=0.119
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:52 PM > ep 1422 done. total_steps=77355 | reward=1.0 | episode_steps=41 | hours=0.021 | epsilon=0.119
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:52 PM > ep 1423 done. total_steps=77386 | reward=1.0 | episode_steps=31 | hours=0.021 | epsilon=0.119
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:52 PM > ep 1424 done. total_steps=77412 | reward=1.0 | episode_steps=26 | hours=0.022 | epsilon=0.119
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:52 PM > ep 1425 done. total_steps=77413 | reward=1.0 | episode_steps=1 | hours=0.022 | epsilon=0.119
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:52 PM > ep 1426 done. total_steps=77426 | reward=1.0 | episode_steps=13 | hours=0.022 | epsilon=0.119
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:52 PM > ep 1427 done. total_steps=77431 | reward=1.0 | episode_steps=5 | hours=0.022 | epsilon=0.119
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:52 PM > ep 1428 done. total_steps=77448 | reward=1.0 | episode_steps=17 | hours=0.022 | epsilon=0.119
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:52 PM > ep 1429 done. total_steps=77460 | reward=1.0 | episode_steps=12 | hours=0.022 | epsilon=0.119
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:52 PM > ep 1430 done. total_steps=77475 | reward=1.0 | episode_steps=15 | hours=0.022 | epsilon=0.119
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:52 PM > ep 1431 done. total_steps=77550 | reward=1.0 | episode_steps=75 | hours=0.022 | epsilon=0.119
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:52 PM > ep 1432 done. total_steps=77556 | reward=1.0 | episode_steps=6 | hours=0.022 | epsilon=0.119
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:52 PM > ep 1433 done. total_steps=77579 | reward=1.0 | episode_steps=23 | hours=0.022 | epsilon=0.119
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:52 PM > ep 1434 done. total_steps=77603 | reward=1.0 | episode_steps=24 | hours=0.022 | epsilon=0.119
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:52 PM > ep 1435 done. total_steps=77614 | reward=1.0 | episode_steps=11 | hours=0.022 | epsilon=0.119
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:52 PM > ep 1436 done. total_steps=77658 | reward=1.0 | episode_steps=44 | hours=0.022 | epsilon=0.119
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:52 PM > ep 1437 done. total_steps=77669 | reward=1.0 | episode_steps=11 | hours=0.022 | epsilon=0.119
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:52 PM > ep 1438 done. total_steps=77694 | reward=1.0 | episode_steps=25 | hours=0.022 | epsilon=0.118
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:52 PM > ep 1439 done. total_steps=77696 | reward=1.0 | episode_steps=2 | hours=0.022 | epsilon=0.118
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:52 PM > ep 1440 done. total_steps=77725 | reward=1.0 | episode_steps=29 | hours=0.022 | epsilon=0.118
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:52 PM > ep 1441 done. total_steps=77741 | reward=1.0 | episode_steps=16 | hours=0.022 | epsilon=0.118
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:52 PM > ep 1442 done. total_steps=77752 | reward=1.0 | episode_steps=11 | hours=0.022 | epsilon=0.118
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:52 PM > ep 1443 done. total_steps=77796 | reward=1.0 | episode_steps=44 | hours=0.022 | epsilon=0.118
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:52 PM > ep 1444 done. total_steps=77810 | reward=1.0 | episode_steps=14 | hours=0.022 | epsilon=0.118
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:52 PM > ep 1445 done. total_steps=77825 | reward=1.0 | episode_steps=15 | hours=0.022 | epsilon=0.118
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:52 PM > ep 1446 done. total_steps=77870 | reward=1.0 | episode_steps=45 | hours=0.022 | epsilon=0.118
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:52 PM > ep 1447 done. total_steps=78009 | reward=1.0 | episode_steps=139 | hours=0.022 | epsilon=0.118
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:52 PM > ep 1448 done. total_steps=78018 | reward=1.0 | episode_steps=9 | hours=0.022 | epsilon=0.118
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:52 PM > ep 1449 done. total_steps=78021 | reward=1.0 | episode_steps=3 | hours=0.022 | epsilon=0.118
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:52 PM > ep 1450 done. total_steps=78039 | reward=1.0 | episode_steps=18 | hours=0.022 | epsilon=0.118
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:52 PM > ep 1451 done. total_steps=78064 | reward=1.0 | episode_steps=25 | hours=0.022 | epsilon=0.118
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:52 PM > ep 1452 done. total_steps=78068 | reward=1.0 | episode_steps=4 | hours=0.022 | epsilon=0.118
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:52 PM > ep 1453 done. total_steps=78077 | reward=1.0 | episode_steps=9 | hours=0.022 | epsilon=0.118
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:52 PM > ep 1454 done. total_steps=78101 | reward=1.0 | episode_steps=24 | hours=0.022 | epsilon=0.118
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:52 PM > ep 1455 done. total_steps=78116 | reward=1.0 | episode_steps=15 | hours=0.022 | epsilon=0.118
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:52 PM > ep 1456 done. total_steps=78133 | reward=1.0 | episode_steps=17 | hours=0.022 | epsilon=0.118
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:52 PM > ep 1457 done. total_steps=78152 | reward=1.0 | episode_steps=19 | hours=0.022 | epsilon=0.118
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:52 PM > ep 1458 done. total_steps=78167 | reward=1.0 | episode_steps=15 | hours=0.022 | epsilon=0.118
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:52 PM > ep 1459 done. total_steps=78195 | reward=1.0 | episode_steps=28 | hours=0.022 | epsilon=0.118
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:52 PM > ep 1460 done. total_steps=78212 | reward=1.0 | episode_steps=17 | hours=0.022 | epsilon=0.118
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:52 PM > ep 1461 done. total_steps=78263 | reward=1.0 | episode_steps=51 | hours=0.022 | epsilon=0.118
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:52 PM > ep 1462 done. total_steps=78323 | reward=1.0 | episode_steps=60 | hours=0.022 | epsilon=0.118
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:52 PM > ep 1463 done. total_steps=78374 | reward=1.0 | episode_steps=51 | hours=0.022 | epsilon=0.118
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:52 PM > ep 1464 done. total_steps=78395 | reward=1.0 | episode_steps=21 | hours=0.022 | epsilon=0.118
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:52 PM > ep 1465 done. total_steps=78400 | reward=1.0 | episode_steps=5 | hours=0.022 | epsilon=0.118
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:52 PM > ep 1466 done. total_steps=78431 | reward=1.0 | episode_steps=31 | hours=0.022 | epsilon=0.118
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:52 PM > ep 1467 done. total_steps=78456 | reward=1.0 | episode_steps=25 | hours=0.022 | epsilon=0.118
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:52 PM > ep 1468 done. total_steps=78489 | reward=1.0 | episode_steps=33 | hours=0.022 | epsilon=0.118
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:52 PM > ep 1469 done. total_steps=78498 | reward=1.0 | episode_steps=9 | hours=0.022 | epsilon=0.118
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:52 PM > ep 1470 done. total_steps=78516 | reward=1.0 | episode_steps=18 | hours=0.022 | epsilon=0.118
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1471 done. total_steps=78555 | reward=1.0 | episode_steps=39 | hours=0.022 | epsilon=0.118
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1472 done. total_steps=78568 | reward=1.0 | episode_steps=13 | hours=0.022 | epsilon=0.118
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1473 done. total_steps=78578 | reward=1.0 | episode_steps=10 | hours=0.022 | epsilon=0.118
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1474 done. total_steps=78591 | reward=1.0 | episode_steps=13 | hours=0.022 | epsilon=0.118
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1475 done. total_steps=78613 | reward=1.0 | episode_steps=22 | hours=0.022 | epsilon=0.118
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1476 done. total_steps=78618 | reward=1.0 | episode_steps=5 | hours=0.022 | epsilon=0.118
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1477 done. total_steps=78665 | reward=1.0 | episode_steps=47 | hours=0.022 | epsilon=0.118
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1478 done. total_steps=78677 | reward=1.0 | episode_steps=12 | hours=0.022 | epsilon=0.118
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1479 done. total_steps=78705 | reward=1.0 | episode_steps=28 | hours=0.022 | epsilon=0.118
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1480 done. total_steps=78739 | reward=1.0 | episode_steps=34 | hours=0.022 | epsilon=0.118
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1481 done. total_steps=78758 | reward=1.0 | episode_steps=19 | hours=0.022 | epsilon=0.118
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1482 done. total_steps=78765 | reward=1.0 | episode_steps=7 | hours=0.022 | epsilon=0.118
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1483 done. total_steps=78774 | reward=1.0 | episode_steps=9 | hours=0.022 | epsilon=0.118
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1484 done. total_steps=78781 | reward=1.0 | episode_steps=7 | hours=0.022 | epsilon=0.118
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1485 done. total_steps=78790 | reward=1.0 | episode_steps=9 | hours=0.022 | epsilon=0.118
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1486 done. total_steps=78795 | reward=1.0 | episode_steps=5 | hours=0.022 | epsilon=0.118
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1487 done. total_steps=78822 | reward=1.0 | episode_steps=27 | hours=0.022 | epsilon=0.117
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1488 done. total_steps=78836 | reward=1.0 | episode_steps=14 | hours=0.022 | epsilon=0.117
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1489 done. total_steps=78844 | reward=1.0 | episode_steps=8 | hours=0.022 | epsilon=0.117
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1490 done. total_steps=78879 | reward=1.0 | episode_steps=35 | hours=0.022 | epsilon=0.117
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1491 done. total_steps=78912 | reward=1.0 | episode_steps=33 | hours=0.022 | epsilon=0.117
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1492 done. total_steps=78956 | reward=1.0 | episode_steps=44 | hours=0.022 | epsilon=0.117
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1493 done. total_steps=78994 | reward=1.0 | episode_steps=38 | hours=0.022 | epsilon=0.117
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1494 done. total_steps=79015 | reward=1.0 | episode_steps=21 | hours=0.022 | epsilon=0.117
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1495 done. total_steps=79078 | reward=1.0 | episode_steps=63 | hours=0.022 | epsilon=0.117
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1496 done. total_steps=79101 | reward=1.0 | episode_steps=23 | hours=0.022 | epsilon=0.117
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1497 done. total_steps=79149 | reward=1.0 | episode_steps=48 | hours=0.022 | epsilon=0.117
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1498 done. total_steps=79163 | reward=1.0 | episode_steps=14 | hours=0.022 | epsilon=0.117
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1499 done. total_steps=79174 | reward=1.0 | episode_steps=11 | hours=0.022 | epsilon=0.117
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1500 done. total_steps=79175 | reward=1.0 | episode_steps=1 | hours=0.022 | epsilon=0.117
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1501 done. total_steps=79179 | reward=1.0 | episode_steps=4 | hours=0.022 | epsilon=0.117
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1502 done. total_steps=79218 | reward=1.0 | episode_steps=39 | hours=0.022 | epsilon=0.117
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1503 done. total_steps=79244 | reward=1.0 | episode_steps=26 | hours=0.022 | epsilon=0.117
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1504 done. total_steps=79251 | reward=1.0 | episode_steps=7 | hours=0.022 | epsilon=0.117
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1505 done. total_steps=79266 | reward=1.0 | episode_steps=15 | hours=0.022 | epsilon=0.117
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1506 done. total_steps=79287 | reward=1.0 | episode_steps=21 | hours=0.022 | epsilon=0.117
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1507 done. total_steps=79290 | reward=1.0 | episode_steps=3 | hours=0.022 | epsilon=0.117
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1508 done. total_steps=79291 | reward=1.0 | episode_steps=1 | hours=0.022 | epsilon=0.117
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1509 done. total_steps=79294 | reward=1.0 | episode_steps=3 | hours=0.022 | epsilon=0.117
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1510 done. total_steps=79333 | reward=1.0 | episode_steps=39 | hours=0.022 | epsilon=0.117
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1511 done. total_steps=79372 | reward=1.0 | episode_steps=39 | hours=0.022 | epsilon=0.117
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1512 done. total_steps=79398 | reward=1.0 | episode_steps=26 | hours=0.022 | epsilon=0.117
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1513 done. total_steps=79466 | reward=1.0 | episode_steps=68 | hours=0.022 | epsilon=0.117
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1514 done. total_steps=79484 | reward=1.0 | episode_steps=18 | hours=0.022 | epsilon=0.117
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1515 done. total_steps=79510 | reward=1.0 | episode_steps=26 | hours=0.022 | epsilon=0.117
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1516 done. total_steps=79538 | reward=1.0 | episode_steps=28 | hours=0.022 | epsilon=0.117
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1517 done. total_steps=79547 | reward=1.0 | episode_steps=9 | hours=0.022 | epsilon=0.117
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1518 done. total_steps=79563 | reward=1.0 | episode_steps=16 | hours=0.022 | epsilon=0.117
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1519 done. total_steps=79601 | reward=1.0 | episode_steps=38 | hours=0.022 | epsilon=0.117
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1520 done. total_steps=79603 | reward=1.0 | episode_steps=2 | hours=0.022 | epsilon=0.117
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1521 done. total_steps=79611 | reward=1.0 | episode_steps=8 | hours=0.022 | epsilon=0.117
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1522 done. total_steps=79622 | reward=1.0 | episode_steps=11 | hours=0.022 | epsilon=0.117
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1523 done. total_steps=79688 | reward=1.0 | episode_steps=66 | hours=0.022 | epsilon=0.117
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1524 done. total_steps=79737 | reward=1.0 | episode_steps=49 | hours=0.022 | epsilon=0.117
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1525 done. total_steps=79811 | reward=1.0 | episode_steps=74 | hours=0.022 | epsilon=0.117
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1526 done. total_steps=79827 | reward=1.0 | episode_steps=16 | hours=0.022 | epsilon=0.117
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1527 done. total_steps=79841 | reward=1.0 | episode_steps=14 | hours=0.022 | epsilon=0.117
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:53 PM > ep 1528 done. total_steps=79857 | reward=1.0 | episode_steps=16 | hours=0.022 | epsilon=0.117
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:54 PM > ep 1529 done. total_steps=79924 | reward=1.0 | episode_steps=67 | hours=0.022 | epsilon=0.117
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:54 PM > ep 1530 done. total_steps=79933 | reward=1.0 | episode_steps=9 | hours=0.022 | epsilon=0.117
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:54 PM > ep 1531 done. total_steps=79973 | reward=1.0 | episode_steps=40 | hours=0.022 | epsilon=0.117
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:54 PM > ep 1532 done. total_steps=79981 | reward=1.0 | episode_steps=8 | hours=0.022 | epsilon=0.117
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:54 PM > ep 1533 done. total_steps=80004 | reward=1.0 | episode_steps=23 | hours=0.022 | epsilon=0.116
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:54 PM > ep 1534 done. total_steps=80011 | reward=1.0 | episode_steps=7 | hours=0.022 | epsilon=0.116
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:54 PM > ep 1535 done. total_steps=80050 | reward=1.0 | episode_steps=39 | hours=0.022 | epsilon=0.116
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:54 PM > ep 1536 done. total_steps=80085 | reward=1.0 | episode_steps=35 | hours=0.022 | epsilon=0.116
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:54 PM > ep 1537 done. total_steps=80111 | reward=1.0 | episode_steps=26 | hours=0.022 | epsilon=0.116
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:54 PM > ep 1538 done. total_steps=80143 | reward=1.0 | episode_steps=32 | hours=0.022 | epsilon=0.116
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:54 PM > ep 1539 done. total_steps=80187 | reward=1.0 | episode_steps=44 | hours=0.022 | epsilon=0.116
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:54 PM > ep 1540 done. total_steps=80195 | reward=1.0 | episode_steps=8 | hours=0.022 | epsilon=0.116
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:54 PM > ep 1541 done. total_steps=80207 | reward=1.0 | episode_steps=12 | hours=0.022 | epsilon=0.116
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:54 PM > ep 1542 done. total_steps=80220 | reward=1.0 | episode_steps=13 | hours=0.022 | epsilon=0.116
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:54 PM > ep 1543 done. total_steps=80239 | reward=1.0 | episode_steps=19 | hours=0.022 | epsilon=0.116
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:54 PM > ep 1544 done. total_steps=80244 | reward=1.0 | episode_steps=5 | hours=0.022 | epsilon=0.116
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:54 PM > ep 1545 done. total_steps=80303 | reward=1.0 | episode_steps=59 | hours=0.022 | epsilon=0.116
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:54 PM > ep 1546 done. total_steps=80331 | reward=1.0 | episode_steps=28 | hours=0.022 | epsilon=0.116
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:54 PM > ep 1547 done. total_steps=80360 | reward=1.0 | episode_steps=29 | hours=0.022 | epsilon=0.116
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:54 PM > ep 1548 done. total_steps=80386 | reward=1.0 | episode_steps=26 | hours=0.022 | epsilon=0.116
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:54 PM > ep 1549 done. total_steps=80439 | reward=1.0 | episode_steps=53 | hours=0.022 | epsilon=0.116
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:54 PM > ep 1550 done. total_steps=80454 | reward=1.0 | episode_steps=15 | hours=0.022 | epsilon=0.116
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:54 PM > ep 1551 done. total_steps=80472 | reward=1.0 | episode_steps=18 | hours=0.022 | epsilon=0.116
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:54 PM > ep 1552 done. total_steps=80500 | reward=1.0 | episode_steps=28 | hours=0.022 | epsilon=0.116
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:54 PM > ep 1553 done. total_steps=80518 | reward=1.0 | episode_steps=18 | hours=0.022 | epsilon=0.116
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:54 PM > ep 1554 done. total_steps=80534 | reward=1.0 | episode_steps=16 | hours=0.022 | epsilon=0.116
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:54 PM > ep 1555 done. total_steps=80540 | reward=1.0 | episode_steps=6 | hours=0.022 | epsilon=0.116
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:54 PM > ep 1556 done. total_steps=80546 | reward=1.0 | episode_steps=6 | hours=0.022 | epsilon=0.116
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:54 PM > ep 1557 done. total_steps=80590 | reward=1.0 | episode_steps=44 | hours=0.022 | epsilon=0.116
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:54 PM > ep 1558 done. total_steps=80612 | reward=1.0 | episode_steps=22 | hours=0.022 | epsilon=0.116
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:54 PM > ep 1559 done. total_steps=80619 | reward=1.0 | episode_steps=7 | hours=0.022 | epsilon=0.116
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:54 PM > ep 1560 done. total_steps=80664 | reward=1.0 | episode_steps=45 | hours=0.022 | epsilon=0.116
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:54 PM > ep 1561 done. total_steps=80666 | reward=1.0 | episode_steps=2 | hours=0.022 | epsilon=0.116
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:54 PM > ep 1562 done. total_steps=80743 | reward=1.0 | episode_steps=77 | hours=0.022 | epsilon=0.116
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:54 PM > ep 1563 done. total_steps=80766 | reward=1.0 | episode_steps=23 | hours=0.022 | epsilon=0.116
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:54 PM > ep 1564 done. total_steps=80779 | reward=1.0 | episode_steps=13 | hours=0.022 | epsilon=0.116
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:54 PM > ep 1565 done. total_steps=80806 | reward=1.0 | episode_steps=27 | hours=0.022 | epsilon=0.116
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:54 PM > ep 1566 done. total_steps=80873 | reward=1.0 | episode_steps=67 | hours=0.022 | epsilon=0.116
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:54 PM > ep 1567 done. total_steps=80888 | reward=1.0 | episode_steps=15 | hours=0.022 | epsilon=0.116
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:54 PM > ep 1568 done. total_steps=80927 | reward=1.0 | episode_steps=39 | hours=0.022 | epsilon=0.116
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:54 PM > ep 1569 done. total_steps=80977 | reward=1.0 | episode_steps=50 | hours=0.022 | epsilon=0.116
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:54 PM > ep 1570 done. total_steps=81023 | reward=1.0 | episode_steps=46 | hours=0.023 | epsilon=0.116
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:54 PM > ep 1571 done. total_steps=81036 | reward=1.0 | episode_steps=13 | hours=0.023 | epsilon=0.116
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:54 PM > ep 1572 done. total_steps=81046 | reward=1.0 | episode_steps=10 | hours=0.023 | epsilon=0.116
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:54 PM > ep 1573 done. total_steps=81067 | reward=1.0 | episode_steps=21 | hours=0.023 | epsilon=0.116
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:54 PM > ep 1574 done. total_steps=81075 | reward=1.0 | episode_steps=8 | hours=0.023 | epsilon=0.116
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:54 PM > ep 1575 done. total_steps=81142 | reward=1.0 | episode_steps=67 | hours=0.023 | epsilon=0.116
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:54 PM > ep 1576 done. total_steps=81150 | reward=1.0 | episode_steps=8 | hours=0.023 | epsilon=0.116
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:55 PM > ep 1577 done. total_steps=81176 | reward=1.0 | episode_steps=26 | hours=0.023 | epsilon=0.116
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:55 PM > ep 1578 done. total_steps=81194 | reward=1.0 | episode_steps=18 | hours=0.023 | epsilon=0.116
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:55 PM > ep 1579 done. total_steps=81196 | reward=1.0 | episode_steps=2 | hours=0.023 | epsilon=0.116
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:55 PM > ep 1580 done. total_steps=81227 | reward=1.0 | episode_steps=31 | hours=0.023 | epsilon=0.116
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:55 PM > ep 1581 done. total_steps=81261 | reward=1.0 | episode_steps=34 | hours=0.023 | epsilon=0.115
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:55 PM > ep 1582 done. total_steps=81313 | reward=1.0 | episode_steps=52 | hours=0.023 | epsilon=0.115
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:55 PM > ep 1583 done. total_steps=81316 | reward=1.0 | episode_steps=3 | hours=0.023 | epsilon=0.115
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:55 PM > ep 1584 done. total_steps=81325 | reward=1.0 | episode_steps=9 | hours=0.023 | epsilon=0.115
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:55 PM > ep 1585 done. total_steps=81362 | reward=1.0 | episode_steps=37 | hours=0.023 | epsilon=0.115
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:55 PM > ep 1586 done. total_steps=81400 | reward=1.0 | episode_steps=38 | hours=0.023 | epsilon=0.115
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:55 PM > ep 1587 done. total_steps=81447 | reward=1.0 | episode_steps=47 | hours=0.023 | epsilon=0.115
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:55 PM > ep 1588 done. total_steps=81499 | reward=1.0 | episode_steps=52 | hours=0.023 | epsilon=0.115
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:55 PM > ep 1589 done. total_steps=81515 | reward=1.0 | episode_steps=16 | hours=0.023 | epsilon=0.115
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:55 PM > ep 1590 done. total_steps=81547 | reward=1.0 | episode_steps=32 | hours=0.023 | epsilon=0.115
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:55 PM > ep 1591 done. total_steps=81566 | reward=1.0 | episode_steps=19 | hours=0.023 | epsilon=0.115
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:55 PM > ep 1592 done. total_steps=81571 | reward=1.0 | episode_steps=5 | hours=0.023 | epsilon=0.115
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:55 PM > ep 1593 done. total_steps=81603 | reward=1.0 | episode_steps=32 | hours=0.023 | epsilon=0.115
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:55 PM > ep 1594 done. total_steps=81625 | reward=1.0 | episode_steps=22 | hours=0.023 | epsilon=0.115
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:55 PM > ep 1595 done. total_steps=81661 | reward=1.0 | episode_steps=36 | hours=0.023 | epsilon=0.115
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:55 PM > ep 1596 done. total_steps=81688 | reward=1.0 | episode_steps=27 | hours=0.023 | epsilon=0.115
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:55 PM > ep 1597 done. total_steps=81725 | reward=1.0 | episode_steps=37 | hours=0.023 | epsilon=0.115
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:55 PM > ep 1598 done. total_steps=81788 | reward=1.0 | episode_steps=63 | hours=0.023 | epsilon=0.115
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:55 PM > ep 1599 done. total_steps=81816 | reward=1.0 | episode_steps=28 | hours=0.023 | epsilon=0.115
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:55 PM > ep 1600 done. total_steps=81837 | reward=1.0 | episode_steps=21 | hours=0.023 | epsilon=0.115
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:55 PM > ep 1601 done. total_steps=81859 | reward=1.0 | episode_steps=22 | hours=0.023 | epsilon=0.115
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:55 PM > ep 1602 done. total_steps=81866 | reward=1.0 | episode_steps=7 | hours=0.023 | epsilon=0.115
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:55 PM > ep 1603 done. total_steps=81876 | reward=1.0 | episode_steps=10 | hours=0.023 | epsilon=0.115
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:55 PM > ep 1604 done. total_steps=81890 | reward=1.0 | episode_steps=14 | hours=0.023 | epsilon=0.115
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:55 PM > ep 1605 done. total_steps=81898 | reward=1.0 | episode_steps=8 | hours=0.023 | epsilon=0.115
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:55 PM > ep 1606 done. total_steps=81901 | reward=1.0 | episode_steps=3 | hours=0.023 | epsilon=0.115
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:55 PM > ep 1607 done. total_steps=81909 | reward=1.0 | episode_steps=8 | hours=0.023 | epsilon=0.115
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:55 PM > ep 1608 done. total_steps=81938 | reward=1.0 | episode_steps=29 | hours=0.023 | epsilon=0.115
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:55 PM > ep 1609 done. total_steps=81968 | reward=1.0 | episode_steps=30 | hours=0.023 | epsilon=0.115
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:55 PM > ep 1610 done. total_steps=81973 | reward=1.0 | episode_steps=5 | hours=0.023 | epsilon=0.115
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:55 PM > ep 1611 done. total_steps=81992 | reward=1.0 | episode_steps=19 | hours=0.023 | epsilon=0.115
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:55 PM > ep 1612 done. total_steps=82005 | reward=1.0 | episode_steps=13 | hours=0.023 | epsilon=0.115
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:55 PM > ep 1613 done. total_steps=82022 | reward=1.0 | episode_steps=17 | hours=0.023 | epsilon=0.115
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:55 PM > ep 1614 done. total_steps=82030 | reward=1.0 | episode_steps=8 | hours=0.023 | epsilon=0.115
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:55 PM > ep 1615 done. total_steps=82049 | reward=1.0 | episode_steps=19 | hours=0.023 | epsilon=0.115
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:55 PM > ep 1616 done. total_steps=82158 | reward=1.0 | episode_steps=109 | hours=0.023 | epsilon=0.115
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:55 PM > ep 1617 done. total_steps=82180 | reward=1.0 | episode_steps=22 | hours=0.023 | epsilon=0.115
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:55 PM > ep 1618 done. total_steps=82188 | reward=1.0 | episode_steps=8 | hours=0.023 | epsilon=0.115
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:55 PM > ep 1619 done. total_steps=82215 | reward=1.0 | episode_steps=27 | hours=0.023 | epsilon=0.115
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:55 PM > ep 1620 done. total_steps=82217 | reward=1.0 | episode_steps=2 | hours=0.023 | epsilon=0.115
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:55 PM > ep 1621 done. total_steps=82240 | reward=1.0 | episode_steps=23 | hours=0.023 | epsilon=0.115
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:55 PM > ep 1622 done. total_steps=82257 | reward=1.0 | episode_steps=17 | hours=0.023 | epsilon=0.115
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:55 PM > ep 1623 done. total_steps=82260 | reward=1.0 | episode_steps=3 | hours=0.023 | epsilon=0.115
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:55 PM > ep 1624 done. total_steps=82283 | reward=1.0 | episode_steps=23 | hours=0.023 | epsilon=0.115
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:55 PM > ep 1625 done. total_steps=82306 | reward=1.0 | episode_steps=23 | hours=0.023 | epsilon=0.115
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:55 PM > ep 1626 done. total_steps=82336 | reward=1.0 | episode_steps=30 | hours=0.023 | epsilon=0.115
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:55 PM > ep 1627 done. total_steps=82355 | reward=1.0 | episode_steps=19 | hours=0.023 | epsilon=0.115
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:55 PM > ep 1628 done. total_steps=82383 | reward=1.0 | episode_steps=28 | hours=0.023 | epsilon=0.115
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:55 PM > ep 1629 done. total_steps=82388 | reward=1.0 | episode_steps=5 | hours=0.023 | epsilon=0.115
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:55 PM > ep 1630 done. total_steps=82409 | reward=1.0 | episode_steps=21 | hours=0.023 | epsilon=0.115
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1631 done. total_steps=82464 | reward=1.0 | episode_steps=55 | hours=0.023 | epsilon=0.115
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1632 done. total_steps=82484 | reward=1.0 | episode_steps=20 | hours=0.023 | epsilon=0.115
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1633 done. total_steps=82507 | reward=1.0 | episode_steps=23 | hours=0.023 | epsilon=0.115
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1634 done. total_steps=82575 | reward=1.0 | episode_steps=68 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1635 done. total_steps=82612 | reward=1.0 | episode_steps=37 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1636 done. total_steps=82661 | reward=1.0 | episode_steps=49 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1637 done. total_steps=82669 | reward=1.0 | episode_steps=8 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1638 done. total_steps=82696 | reward=1.0 | episode_steps=27 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1639 done. total_steps=82707 | reward=1.0 | episode_steps=11 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1640 done. total_steps=82716 | reward=1.0 | episode_steps=9 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1641 done. total_steps=82739 | reward=1.0 | episode_steps=23 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1642 done. total_steps=82740 | reward=1.0 | episode_steps=1 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1643 done. total_steps=82745 | reward=1.0 | episode_steps=5 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1644 done. total_steps=82757 | reward=1.0 | episode_steps=12 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1645 done. total_steps=82793 | reward=1.0 | episode_steps=36 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1646 done. total_steps=82833 | reward=1.0 | episode_steps=40 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1647 done. total_steps=82844 | reward=1.0 | episode_steps=11 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1648 done. total_steps=82861 | reward=1.0 | episode_steps=17 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1649 done. total_steps=82885 | reward=1.0 | episode_steps=24 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1650 done. total_steps=82904 | reward=1.0 | episode_steps=19 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1651 done. total_steps=82918 | reward=1.0 | episode_steps=14 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1652 done. total_steps=82920 | reward=1.0 | episode_steps=2 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1653 done. total_steps=82928 | reward=1.0 | episode_steps=8 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1654 done. total_steps=82947 | reward=1.0 | episode_steps=19 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1655 done. total_steps=82962 | reward=1.0 | episode_steps=15 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1656 done. total_steps=82985 | reward=1.0 | episode_steps=23 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1657 done. total_steps=82999 | reward=1.0 | episode_steps=14 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1658 done. total_steps=83033 | reward=1.0 | episode_steps=34 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1659 done. total_steps=83040 | reward=1.0 | episode_steps=7 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1660 done. total_steps=83077 | reward=1.0 | episode_steps=37 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1661 done. total_steps=83105 | reward=1.0 | episode_steps=28 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1662 done. total_steps=83125 | reward=1.0 | episode_steps=20 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1663 done. total_steps=83158 | reward=1.0 | episode_steps=33 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1664 done. total_steps=83159 | reward=1.0 | episode_steps=1 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1665 done. total_steps=83184 | reward=1.0 | episode_steps=25 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1666 done. total_steps=83207 | reward=1.0 | episode_steps=23 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1667 done. total_steps=83216 | reward=1.0 | episode_steps=9 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1668 done. total_steps=83221 | reward=1.0 | episode_steps=5 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1669 done. total_steps=83226 | reward=1.0 | episode_steps=5 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1670 done. total_steps=83230 | reward=1.0 | episode_steps=4 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1671 done. total_steps=83258 | reward=1.0 | episode_steps=28 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1672 done. total_steps=83273 | reward=1.0 | episode_steps=15 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1673 done. total_steps=83282 | reward=1.0 | episode_steps=9 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1674 done. total_steps=83302 | reward=1.0 | episode_steps=20 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1675 done. total_steps=83345 | reward=1.0 | episode_steps=43 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1676 done. total_steps=83370 | reward=1.0 | episode_steps=25 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1677 done. total_steps=83382 | reward=1.0 | episode_steps=12 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1678 done. total_steps=83394 | reward=1.0 | episode_steps=12 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1679 done. total_steps=83431 | reward=1.0 | episode_steps=37 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1680 done. total_steps=83461 | reward=1.0 | episode_steps=30 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1681 done. total_steps=83479 | reward=1.0 | episode_steps=18 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1682 done. total_steps=83493 | reward=1.0 | episode_steps=14 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1683 done. total_steps=83508 | reward=1.0 | episode_steps=15 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1684 done. total_steps=83509 | reward=1.0 | episode_steps=1 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1685 done. total_steps=83551 | reward=1.0 | episode_steps=42 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1686 done. total_steps=83571 | reward=1.0 | episode_steps=20 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1687 done. total_steps=83595 | reward=1.0 | episode_steps=24 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1688 done. total_steps=83610 | reward=1.0 | episode_steps=15 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1689 done. total_steps=83618 | reward=1.0 | episode_steps=8 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1690 done. total_steps=83619 | reward=1.0 | episode_steps=1 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1691 done. total_steps=83634 | reward=1.0 | episode_steps=15 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1692 done. total_steps=83646 | reward=1.0 | episode_steps=12 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1693 done. total_steps=83666 | reward=1.0 | episode_steps=20 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1694 done. total_steps=83698 | reward=1.0 | episode_steps=32 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1695 done. total_steps=83710 | reward=1.0 | episode_steps=12 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1696 done. total_steps=83730 | reward=1.0 | episode_steps=20 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:56 PM > ep 1697 done. total_steps=83764 | reward=1.0 | episode_steps=34 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1698 done. total_steps=83769 | reward=1.0 | episode_steps=5 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1699 done. total_steps=83802 | reward=1.0 | episode_steps=33 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1700 done. total_steps=83808 | reward=1.0 | episode_steps=6 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1701 done. total_steps=83833 | reward=1.0 | episode_steps=25 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1702 done. total_steps=83857 | reward=1.0 | episode_steps=24 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1703 done. total_steps=83882 | reward=1.0 | episode_steps=25 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1704 done. total_steps=83926 | reward=1.0 | episode_steps=44 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1705 done. total_steps=83949 | reward=1.0 | episode_steps=23 | hours=0.023 | epsilon=0.114
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1706 done. total_steps=83997 | reward=1.0 | episode_steps=48 | hours=0.023 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1707 done. total_steps=84016 | reward=1.0 | episode_steps=19 | hours=0.023 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1708 done. total_steps=84065 | reward=1.0 | episode_steps=49 | hours=0.023 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1709 done. total_steps=84083 | reward=1.0 | episode_steps=18 | hours=0.023 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1710 done. total_steps=84093 | reward=1.0 | episode_steps=10 | hours=0.023 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1711 done. total_steps=84118 | reward=1.0 | episode_steps=25 | hours=0.023 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1712 done. total_steps=84153 | reward=1.0 | episode_steps=35 | hours=0.023 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1713 done. total_steps=84164 | reward=1.0 | episode_steps=11 | hours=0.023 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1714 done. total_steps=84189 | reward=1.0 | episode_steps=25 | hours=0.023 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1715 done. total_steps=84204 | reward=1.0 | episode_steps=15 | hours=0.023 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1716 done. total_steps=84208 | reward=1.0 | episode_steps=4 | hours=0.023 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1717 done. total_steps=84260 | reward=1.0 | episode_steps=52 | hours=0.023 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1718 done. total_steps=84290 | reward=1.0 | episode_steps=30 | hours=0.023 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1719 done. total_steps=84302 | reward=1.0 | episode_steps=12 | hours=0.023 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1720 done. total_steps=84327 | reward=1.0 | episode_steps=25 | hours=0.023 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1721 done. total_steps=84336 | reward=1.0 | episode_steps=9 | hours=0.023 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1722 done. total_steps=84349 | reward=1.0 | episode_steps=13 | hours=0.023 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1723 done. total_steps=84354 | reward=1.0 | episode_steps=5 | hours=0.023 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1724 done. total_steps=84370 | reward=1.0 | episode_steps=16 | hours=0.023 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1725 done. total_steps=84395 | reward=1.0 | episode_steps=25 | hours=0.023 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1726 done. total_steps=84417 | reward=1.0 | episode_steps=22 | hours=0.023 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1727 done. total_steps=84437 | reward=1.0 | episode_steps=20 | hours=0.023 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1728 done. total_steps=84501 | reward=1.0 | episode_steps=64 | hours=0.023 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1729 done. total_steps=84540 | reward=1.0 | episode_steps=39 | hours=0.023 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1730 done. total_steps=84586 | reward=1.0 | episode_steps=46 | hours=0.023 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1731 done. total_steps=84622 | reward=1.0 | episode_steps=36 | hours=0.024 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1732 done. total_steps=84646 | reward=1.0 | episode_steps=24 | hours=0.024 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1733 done. total_steps=84664 | reward=1.0 | episode_steps=18 | hours=0.024 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1734 done. total_steps=84684 | reward=1.0 | episode_steps=20 | hours=0.024 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1735 done. total_steps=84697 | reward=1.0 | episode_steps=13 | hours=0.024 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1736 done. total_steps=84719 | reward=1.0 | episode_steps=22 | hours=0.024 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1737 done. total_steps=84740 | reward=1.0 | episode_steps=21 | hours=0.024 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1738 done. total_steps=84754 | reward=1.0 | episode_steps=14 | hours=0.024 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1739 done. total_steps=84785 | reward=1.0 | episode_steps=31 | hours=0.024 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1740 done. total_steps=84798 | reward=1.0 | episode_steps=13 | hours=0.024 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1741 done. total_steps=84831 | reward=1.0 | episode_steps=33 | hours=0.024 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1742 done. total_steps=84858 | reward=1.0 | episode_steps=27 | hours=0.024 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1743 done. total_steps=84866 | reward=1.0 | episode_steps=8 | hours=0.024 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1744 done. total_steps=84884 | reward=1.0 | episode_steps=18 | hours=0.024 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1745 done. total_steps=84907 | reward=1.0 | episode_steps=23 | hours=0.024 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1746 done. total_steps=84935 | reward=1.0 | episode_steps=28 | hours=0.024 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1747 done. total_steps=84976 | reward=1.0 | episode_steps=41 | hours=0.024 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1748 done. total_steps=84987 | reward=1.0 | episode_steps=11 | hours=0.024 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1749 done. total_steps=84991 | reward=1.0 | episode_steps=4 | hours=0.024 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1750 done. total_steps=84999 | reward=1.0 | episode_steps=8 | hours=0.024 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1751 done. total_steps=85012 | reward=1.0 | episode_steps=13 | hours=0.024 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1752 done. total_steps=85037 | reward=1.0 | episode_steps=25 | hours=0.024 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1753 done. total_steps=85058 | reward=1.0 | episode_steps=21 | hours=0.024 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1754 done. total_steps=85068 | reward=1.0 | episode_steps=10 | hours=0.024 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1755 done. total_steps=85089 | reward=1.0 | episode_steps=21 | hours=0.024 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1756 done. total_steps=85123 | reward=1.0 | episode_steps=34 | hours=0.024 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1757 done. total_steps=85125 | reward=1.0 | episode_steps=2 | hours=0.024 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1758 done. total_steps=85134 | reward=1.0 | episode_steps=9 | hours=0.024 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1759 done. total_steps=85147 | reward=1.0 | episode_steps=13 | hours=0.024 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:57 PM > ep 1760 done. total_steps=85182 | reward=1.0 | episode_steps=35 | hours=0.024 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1761 done. total_steps=85188 | reward=1.0 | episode_steps=6 | hours=0.024 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1762 done. total_steps=85238 | reward=1.0 | episode_steps=50 | hours=0.024 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1763 done. total_steps=85256 | reward=1.0 | episode_steps=18 | hours=0.024 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1764 done. total_steps=85263 | reward=1.0 | episode_steps=7 | hours=0.024 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1765 done. total_steps=85301 | reward=1.0 | episode_steps=38 | hours=0.024 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1766 done. total_steps=85306 | reward=1.0 | episode_steps=5 | hours=0.024 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1767 done. total_steps=85308 | reward=1.0 | episode_steps=2 | hours=0.024 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1768 done. total_steps=85354 | reward=1.0 | episode_steps=46 | hours=0.024 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1769 done. total_steps=85356 | reward=1.0 | episode_steps=2 | hours=0.024 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1770 done. total_steps=85375 | reward=1.0 | episode_steps=19 | hours=0.024 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1771 done. total_steps=85393 | reward=1.0 | episode_steps=18 | hours=0.024 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1772 done. total_steps=85410 | reward=1.0 | episode_steps=17 | hours=0.024 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1773 done. total_steps=85433 | reward=1.0 | episode_steps=23 | hours=0.024 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1774 done. total_steps=85461 | reward=1.0 | episode_steps=28 | hours=0.024 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1775 done. total_steps=85465 | reward=1.0 | episode_steps=4 | hours=0.024 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1776 done. total_steps=85473 | reward=1.0 | episode_steps=8 | hours=0.024 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1777 done. total_steps=85482 | reward=1.0 | episode_steps=9 | hours=0.024 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1778 done. total_steps=85487 | reward=1.0 | episode_steps=5 | hours=0.024 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1779 done. total_steps=85522 | reward=1.0 | episode_steps=35 | hours=0.024 | epsilon=0.113
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1780 done. total_steps=85549 | reward=1.0 | episode_steps=27 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1781 done. total_steps=85594 | reward=1.0 | episode_steps=45 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1782 done. total_steps=85610 | reward=1.0 | episode_steps=16 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1783 done. total_steps=85619 | reward=1.0 | episode_steps=9 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1784 done. total_steps=85632 | reward=1.0 | episode_steps=13 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1785 done. total_steps=85654 | reward=1.0 | episode_steps=22 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1786 done. total_steps=85681 | reward=1.0 | episode_steps=27 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1787 done. total_steps=85683 | reward=1.0 | episode_steps=2 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1788 done. total_steps=85697 | reward=1.0 | episode_steps=14 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1789 done. total_steps=85725 | reward=1.0 | episode_steps=28 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1790 done. total_steps=85729 | reward=1.0 | episode_steps=4 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1791 done. total_steps=85752 | reward=1.0 | episode_steps=23 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1792 done. total_steps=85773 | reward=1.0 | episode_steps=21 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1793 done. total_steps=85802 | reward=1.0 | episode_steps=29 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1794 done. total_steps=85817 | reward=1.0 | episode_steps=15 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1795 done. total_steps=85837 | reward=1.0 | episode_steps=20 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1796 done. total_steps=85855 | reward=1.0 | episode_steps=18 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1797 done. total_steps=85870 | reward=1.0 | episode_steps=15 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1798 done. total_steps=85911 | reward=1.0 | episode_steps=41 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1799 done. total_steps=85925 | reward=1.0 | episode_steps=14 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1800 done. total_steps=85962 | reward=1.0 | episode_steps=37 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1801 done. total_steps=85966 | reward=1.0 | episode_steps=4 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1802 done. total_steps=85995 | reward=1.0 | episode_steps=29 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1803 done. total_steps=86004 | reward=1.0 | episode_steps=9 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1804 done. total_steps=86017 | reward=1.0 | episode_steps=13 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1805 done. total_steps=86041 | reward=1.0 | episode_steps=24 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1806 done. total_steps=86064 | reward=1.0 | episode_steps=23 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1807 done. total_steps=86067 | reward=1.0 | episode_steps=3 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1808 done. total_steps=86080 | reward=1.0 | episode_steps=13 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1809 done. total_steps=86084 | reward=1.0 | episode_steps=4 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1810 done. total_steps=86132 | reward=1.0 | episode_steps=48 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1811 done. total_steps=86134 | reward=1.0 | episode_steps=2 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1812 done. total_steps=86138 | reward=1.0 | episode_steps=4 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1813 done. total_steps=86170 | reward=1.0 | episode_steps=32 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1814 done. total_steps=86205 | reward=1.0 | episode_steps=35 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1815 done. total_steps=86231 | reward=1.0 | episode_steps=26 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1816 done. total_steps=86282 | reward=1.0 | episode_steps=51 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1817 done. total_steps=86308 | reward=1.0 | episode_steps=26 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1818 done. total_steps=86315 | reward=1.0 | episode_steps=7 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1819 done. total_steps=86323 | reward=1.0 | episode_steps=8 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1820 done. total_steps=86349 | reward=1.0 | episode_steps=26 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1821 done. total_steps=86351 | reward=1.0 | episode_steps=2 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1822 done. total_steps=86364 | reward=1.0 | episode_steps=13 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1823 done. total_steps=86385 | reward=1.0 | episode_steps=21 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1824 done. total_steps=86401 | reward=1.0 | episode_steps=16 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1825 done. total_steps=86440 | reward=1.0 | episode_steps=39 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1826 done. total_steps=86455 | reward=1.0 | episode_steps=15 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1827 done. total_steps=86488 | reward=1.0 | episode_steps=33 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1828 done. total_steps=86493 | reward=1.0 | episode_steps=5 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1829 done. total_steps=86494 | reward=1.0 | episode_steps=1 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1830 done. total_steps=86526 | reward=1.0 | episode_steps=32 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1831 done. total_steps=86541 | reward=1.0 | episode_steps=15 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1832 done. total_steps=86555 | reward=1.0 | episode_steps=14 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1833 done. total_steps=86568 | reward=1.0 | episode_steps=13 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1834 done. total_steps=86579 | reward=1.0 | episode_steps=11 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1835 done. total_steps=86594 | reward=1.0 | episode_steps=15 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:58 PM > ep 1836 done. total_steps=86620 | reward=1.0 | episode_steps=26 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1837 done. total_steps=86628 | reward=1.0 | episode_steps=8 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1838 done. total_steps=86636 | reward=1.0 | episode_steps=8 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1839 done. total_steps=86655 | reward=1.0 | episode_steps=19 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1840 done. total_steps=86687 | reward=1.0 | episode_steps=32 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1841 done. total_steps=86704 | reward=1.0 | episode_steps=17 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1842 done. total_steps=86719 | reward=1.0 | episode_steps=15 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1843 done. total_steps=86774 | reward=1.0 | episode_steps=55 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1844 done. total_steps=86776 | reward=1.0 | episode_steps=2 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1845 done. total_steps=86783 | reward=1.0 | episode_steps=7 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1846 done. total_steps=86793 | reward=1.0 | episode_steps=10 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1847 done. total_steps=86824 | reward=1.0 | episode_steps=31 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1848 done. total_steps=86849 | reward=1.0 | episode_steps=25 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1849 done. total_steps=86851 | reward=1.0 | episode_steps=2 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1850 done. total_steps=86879 | reward=1.0 | episode_steps=28 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1851 done. total_steps=86882 | reward=1.0 | episode_steps=3 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1852 done. total_steps=86897 | reward=1.0 | episode_steps=15 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1853 done. total_steps=86921 | reward=1.0 | episode_steps=24 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1854 done. total_steps=86926 | reward=1.0 | episode_steps=5 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1855 done. total_steps=86956 | reward=1.0 | episode_steps=30 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1856 done. total_steps=86986 | reward=1.0 | episode_steps=30 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1857 done. total_steps=87008 | reward=1.0 | episode_steps=22 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1858 done. total_steps=87035 | reward=1.0 | episode_steps=27 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1859 done. total_steps=87054 | reward=1.0 | episode_steps=19 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1860 done. total_steps=87060 | reward=1.0 | episode_steps=6 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1861 done. total_steps=87104 | reward=1.0 | episode_steps=44 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1862 done. total_steps=87166 | reward=1.0 | episode_steps=62 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1863 done. total_steps=87199 | reward=1.0 | episode_steps=33 | hours=0.024 | epsilon=0.112
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1864 done. total_steps=87217 | reward=1.0 | episode_steps=18 | hours=0.024 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1865 done. total_steps=87235 | reward=1.0 | episode_steps=18 | hours=0.024 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1866 done. total_steps=87269 | reward=1.0 | episode_steps=34 | hours=0.024 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1867 done. total_steps=87293 | reward=1.0 | episode_steps=24 | hours=0.024 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1868 done. total_steps=87305 | reward=1.0 | episode_steps=12 | hours=0.024 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1869 done. total_steps=87331 | reward=1.0 | episode_steps=26 | hours=0.024 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1870 done. total_steps=87345 | reward=1.0 | episode_steps=14 | hours=0.024 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1871 done. total_steps=87383 | reward=1.0 | episode_steps=38 | hours=0.024 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1872 done. total_steps=87391 | reward=1.0 | episode_steps=8 | hours=0.024 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1873 done. total_steps=87419 | reward=1.0 | episode_steps=28 | hours=0.024 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1874 done. total_steps=87480 | reward=1.0 | episode_steps=61 | hours=0.024 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1875 done. total_steps=87535 | reward=1.0 | episode_steps=55 | hours=0.024 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1876 done. total_steps=87547 | reward=1.0 | episode_steps=12 | hours=0.024 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1877 done. total_steps=87560 | reward=1.0 | episode_steps=13 | hours=0.024 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1878 done. total_steps=87578 | reward=1.0 | episode_steps=18 | hours=0.024 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1879 done. total_steps=87601 | reward=1.0 | episode_steps=23 | hours=0.024 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1880 done. total_steps=87626 | reward=1.0 | episode_steps=25 | hours=0.024 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1881 done. total_steps=87645 | reward=1.0 | episode_steps=19 | hours=0.024 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1882 done. total_steps=87691 | reward=1.0 | episode_steps=46 | hours=0.024 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1883 done. total_steps=87712 | reward=1.0 | episode_steps=21 | hours=0.024 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1884 done. total_steps=87724 | reward=1.0 | episode_steps=12 | hours=0.024 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1885 done. total_steps=87732 | reward=1.0 | episode_steps=8 | hours=0.024 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1886 done. total_steps=87738 | reward=1.0 | episode_steps=6 | hours=0.024 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1887 done. total_steps=87744 | reward=1.0 | episode_steps=6 | hours=0.024 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1888 done. total_steps=87757 | reward=1.0 | episode_steps=13 | hours=0.024 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1889 done. total_steps=87794 | reward=1.0 | episode_steps=37 | hours=0.024 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1890 done. total_steps=87826 | reward=1.0 | episode_steps=32 | hours=0.024 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1891 done. total_steps=87842 | reward=1.0 | episode_steps=16 | hours=0.024 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1892 done. total_steps=87846 | reward=1.0 | episode_steps=4 | hours=0.024 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1893 done. total_steps=87867 | reward=1.0 | episode_steps=21 | hours=0.024 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1894 done. total_steps=87888 | reward=1.0 | episode_steps=21 | hours=0.024 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1895 done. total_steps=87903 | reward=1.0 | episode_steps=15 | hours=0.024 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1896 done. total_steps=87926 | reward=1.0 | episode_steps=23 | hours=0.024 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1897 done. total_steps=87945 | reward=1.0 | episode_steps=19 | hours=0.024 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1898 done. total_steps=87975 | reward=1.0 | episode_steps=30 | hours=0.024 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1899 done. total_steps=88018 | reward=1.0 | episode_steps=43 | hours=0.024 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1900 done. total_steps=88021 | reward=1.0 | episode_steps=3 | hours=0.024 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1901 done. total_steps=88040 | reward=1.0 | episode_steps=19 | hours=0.024 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:30:59 PM > ep 1902 done. total_steps=88057 | reward=1.0 | episode_steps=17 | hours=0.024 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1903 done. total_steps=88102 | reward=1.0 | episode_steps=45 | hours=0.024 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1904 done. total_steps=88130 | reward=1.0 | episode_steps=28 | hours=0.024 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1905 done. total_steps=88144 | reward=1.0 | episode_steps=14 | hours=0.024 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1906 done. total_steps=88148 | reward=1.0 | episode_steps=4 | hours=0.024 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1907 done. total_steps=88180 | reward=1.0 | episode_steps=32 | hours=0.024 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1908 done. total_steps=88184 | reward=1.0 | episode_steps=4 | hours=0.024 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1909 done. total_steps=88188 | reward=1.0 | episode_steps=4 | hours=0.024 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1910 done. total_steps=88192 | reward=1.0 | episode_steps=4 | hours=0.024 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1911 done. total_steps=88239 | reward=1.0 | episode_steps=47 | hours=0.025 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1912 done. total_steps=88271 | reward=1.0 | episode_steps=32 | hours=0.025 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1913 done. total_steps=88279 | reward=1.0 | episode_steps=8 | hours=0.025 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1914 done. total_steps=88281 | reward=1.0 | episode_steps=2 | hours=0.025 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1915 done. total_steps=88289 | reward=1.0 | episode_steps=8 | hours=0.025 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1916 done. total_steps=88330 | reward=1.0 | episode_steps=41 | hours=0.025 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1917 done. total_steps=88357 | reward=1.0 | episode_steps=27 | hours=0.025 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1918 done. total_steps=88359 | reward=1.0 | episode_steps=2 | hours=0.025 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1919 done. total_steps=88376 | reward=1.0 | episode_steps=17 | hours=0.025 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1920 done. total_steps=88409 | reward=1.0 | episode_steps=33 | hours=0.025 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1921 done. total_steps=88414 | reward=1.0 | episode_steps=5 | hours=0.025 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1922 done. total_steps=88431 | reward=1.0 | episode_steps=17 | hours=0.025 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1923 done. total_steps=88456 | reward=1.0 | episode_steps=25 | hours=0.025 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1924 done. total_steps=88476 | reward=1.0 | episode_steps=20 | hours=0.025 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1925 done. total_steps=88482 | reward=1.0 | episode_steps=6 | hours=0.025 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1926 done. total_steps=88516 | reward=1.0 | episode_steps=34 | hours=0.025 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1927 done. total_steps=88540 | reward=1.0 | episode_steps=24 | hours=0.025 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1928 done. total_steps=88561 | reward=1.0 | episode_steps=21 | hours=0.025 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1929 done. total_steps=88576 | reward=1.0 | episode_steps=15 | hours=0.025 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1930 done. total_steps=88594 | reward=1.0 | episode_steps=18 | hours=0.025 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1931 done. total_steps=88633 | reward=1.0 | episode_steps=39 | hours=0.025 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1932 done. total_steps=88653 | reward=1.0 | episode_steps=20 | hours=0.025 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1933 done. total_steps=88680 | reward=1.0 | episode_steps=27 | hours=0.025 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1934 done. total_steps=88688 | reward=1.0 | episode_steps=8 | hours=0.025 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1935 done. total_steps=88698 | reward=1.0 | episode_steps=10 | hours=0.025 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1936 done. total_steps=88715 | reward=1.0 | episode_steps=17 | hours=0.025 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1937 done. total_steps=88765 | reward=1.0 | episode_steps=50 | hours=0.025 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1938 done. total_steps=88773 | reward=1.0 | episode_steps=8 | hours=0.025 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1939 done. total_steps=88809 | reward=1.0 | episode_steps=36 | hours=0.025 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1940 done. total_steps=88833 | reward=1.0 | episode_steps=24 | hours=0.025 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1941 done. total_steps=88844 | reward=1.0 | episode_steps=11 | hours=0.025 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1942 done. total_steps=88876 | reward=1.0 | episode_steps=32 | hours=0.025 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1943 done. total_steps=88915 | reward=1.0 | episode_steps=39 | hours=0.025 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1944 done. total_steps=88963 | reward=1.0 | episode_steps=48 | hours=0.025 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1945 done. total_steps=88965 | reward=1.0 | episode_steps=2 | hours=0.025 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1946 done. total_steps=88972 | reward=1.0 | episode_steps=7 | hours=0.025 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1947 done. total_steps=88975 | reward=1.0 | episode_steps=3 | hours=0.025 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1948 done. total_steps=88997 | reward=1.0 | episode_steps=22 | hours=0.025 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1949 done. total_steps=89006 | reward=1.0 | episode_steps=9 | hours=0.025 | epsilon=0.111
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1950 done. total_steps=89037 | reward=1.0 | episode_steps=31 | hours=0.025 | epsilon=0.110
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1951 done. total_steps=89085 | reward=1.0 | episode_steps=48 | hours=0.025 | epsilon=0.110
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1952 done. total_steps=89106 | reward=1.0 | episode_steps=21 | hours=0.025 | epsilon=0.110
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1953 done. total_steps=89144 | reward=1.0 | episode_steps=38 | hours=0.025 | epsilon=0.110
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1954 done. total_steps=89157 | reward=1.0 | episode_steps=13 | hours=0.025 | epsilon=0.110
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1955 done. total_steps=89184 | reward=1.0 | episode_steps=27 | hours=0.025 | epsilon=0.110
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1956 done. total_steps=89197 | reward=1.0 | episode_steps=13 | hours=0.025 | epsilon=0.110
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1957 done. total_steps=89206 | reward=1.0 | episode_steps=9 | hours=0.025 | epsilon=0.110
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1958 done. total_steps=89215 | reward=1.0 | episode_steps=9 | hours=0.025 | epsilon=0.110
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1959 done. total_steps=89221 | reward=1.0 | episode_steps=6 | hours=0.025 | epsilon=0.110
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1960 done. total_steps=89247 | reward=1.0 | episode_steps=26 | hours=0.025 | epsilon=0.110
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1961 done. total_steps=89255 | reward=1.0 | episode_steps=8 | hours=0.025 | epsilon=0.110
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1962 done. total_steps=89270 | reward=1.0 | episode_steps=15 | hours=0.025 | epsilon=0.110
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1963 done. total_steps=89284 | reward=1.0 | episode_steps=14 | hours=0.025 | epsilon=0.110
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1964 done. total_steps=89303 | reward=1.0 | episode_steps=19 | hours=0.025 | epsilon=0.110
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1965 done. total_steps=89305 | reward=1.0 | episode_steps=2 | hours=0.025 | epsilon=0.110
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1966 done. total_steps=89395 | reward=1.0 | episode_steps=90 | hours=0.025 | epsilon=0.110
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1967 done. total_steps=89411 | reward=1.0 | episode_steps=16 | hours=0.025 | epsilon=0.110
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1968 done. total_steps=89428 | reward=1.0 | episode_steps=17 | hours=0.025 | epsilon=0.110
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:00 PM > ep 1969 done. total_steps=89491 | reward=1.0 | episode_steps=63 | hours=0.025 | epsilon=0.110
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:01 PM > ep 1970 done. total_steps=89566 | reward=1.0 | episode_steps=75 | hours=0.025 | epsilon=0.110
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:01 PM > ep 1971 done. total_steps=89613 | reward=1.0 | episode_steps=47 | hours=0.025 | epsilon=0.110
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:01 PM > ep 1972 done. total_steps=89623 | reward=1.0 | episode_steps=10 | hours=0.025 | epsilon=0.110
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:01 PM > ep 1973 done. total_steps=89643 | reward=1.0 | episode_steps=20 | hours=0.025 | epsilon=0.110
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:01 PM > ep 1974 done. total_steps=89655 | reward=1.0 | episode_steps=12 | hours=0.025 | epsilon=0.110
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:01 PM > ep 1975 done. total_steps=89669 | reward=1.0 | episode_steps=14 | hours=0.025 | epsilon=0.110
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:01 PM > ep 1976 done. total_steps=89678 | reward=1.0 | episode_steps=9 | hours=0.025 | epsilon=0.110
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:01 PM > ep 1977 done. total_steps=89725 | reward=1.0 | episode_steps=47 | hours=0.025 | epsilon=0.110
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:01 PM > ep 1978 done. total_steps=89748 | reward=1.0 | episode_steps=23 | hours=0.025 | epsilon=0.110
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:01 PM > ep 1979 done. total_steps=89760 | reward=1.0 | episode_steps=12 | hours=0.025 | epsilon=0.110
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:01 PM > ep 1980 done. total_steps=89787 | reward=1.0 | episode_steps=27 | hours=0.025 | epsilon=0.110
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:01 PM > ep 1981 done. total_steps=89800 | reward=1.0 | episode_steps=13 | hours=0.025 | epsilon=0.110
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:01 PM > ep 1982 done. total_steps=89836 | reward=1.0 | episode_steps=36 | hours=0.025 | epsilon=0.110
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:01 PM > ep 1983 done. total_steps=89841 | reward=1.0 | episode_steps=5 | hours=0.025 | epsilon=0.110
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:01 PM > ep 1984 done. total_steps=89861 | reward=1.0 | episode_steps=20 | hours=0.025 | epsilon=0.110
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:01 PM > ep 1985 done. total_steps=89865 | reward=1.0 | episode_steps=4 | hours=0.025 | epsilon=0.110
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:01 PM > ep 1986 done. total_steps=89889 | reward=1.0 | episode_steps=24 | hours=0.025 | epsilon=0.110
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:01 PM > ep 1987 done. total_steps=89922 | reward=1.0 | episode_steps=33 | hours=0.025 | epsilon=0.110
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:01 PM > ep 1988 done. total_steps=89939 | reward=1.0 | episode_steps=17 | hours=0.025 | epsilon=0.110
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:01 PM > ep 1989 done. total_steps=89946 | reward=1.0 | episode_steps=7 | hours=0.025 | epsilon=0.110
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:01 PM > ep 1990 done. total_steps=89977 | reward=1.0 | episode_steps=31 | hours=0.025 | epsilon=0.110
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:01 PM > ep 1991 done. total_steps=89985 | reward=1.0 | episode_steps=8 | hours=0.025 | epsilon=0.110
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:01 PM > ep 1992 done. total_steps=90007 | reward=1.0 | episode_steps=22 | hours=0.025 | epsilon=0.110
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:01 PM > ep 1993 done. total_steps=90008 | reward=1.0 | episode_steps=1 | hours=0.025 | epsilon=0.110
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:01 PM > ep 1994 done. total_steps=90030 | reward=1.0 | episode_steps=22 | hours=0.025 | epsilon=0.110
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:01 PM > ep 1995 done. total_steps=90044 | reward=1.0 | episode_steps=14 | hours=0.025 | epsilon=0.110
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:01 PM > ep 1996 done. total_steps=90067 | reward=1.0 | episode_steps=23 | hours=0.025 | epsilon=0.110
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:01 PM > ep 1997 done. total_steps=90095 | reward=1.0 | episode_steps=28 | hours=0.025 | epsilon=0.110
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:01 PM > ep 1998 done. total_steps=90103 | reward=1.0 | episode_steps=8 | hours=0.025 | epsilon=0.110
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:01 PM > ep 1999 done. total_steps=90112 | reward=1.0 | episode_steps=9 | hours=0.025 | epsilon=0.110
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:01 PM > ep 2000 done. total_steps=90128 | reward=1.0 | episode_steps=16 | hours=0.025 | epsilon=0.110
  - Option 0: avg len = 0.00, count = 1
2025/07/28 11:31:01 PM > ep 2001 done. total_steps=90133 | reward=1.0 | episode_steps=5 | hours=0.025 | epsilon=0.110
  - Option 0: avg len = 0.00, count = 1
